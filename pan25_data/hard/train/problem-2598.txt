In general, be courteous to others.
Debate/discuss/argue the merits of ideas, don't attack people.
Personal insults, shill or troll accusations, hate speech, any suggestion or support of harm, violence, or death, and other rule violations can result in a permanent ban.
I am a bot, and this action was performed automatically.
Please if you have any questions or concerns.
This is my concern.
From the Watts Uprising to BLM, southern Californian law enforcement has a history of inappropriate, disproportionate, escalatory response to civil rights demonstration.
The robots are remote controlled and at the whim of the biases held by the person at the controls.
As for what the difference is, we still have to risk our lives for political demonstrations, but now, cops no longer risk their lives for clashing with us.
The difference is far easier suppression.
This highlights something I was already going to say.
As with all of your examples, the AI were programmed with bias rather than being coded specifically against it.
The flaw, as you said, is the training data, and that came from us.
We aren't teaching the AI what bias is and how to remain objective.
The software simply learns what it would need to learn to most efficiently persist in our biased culture.
That means we're the source of the flaw in the software.