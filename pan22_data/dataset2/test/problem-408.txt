If you are doing a lot of video encoding, 3d rendering, or distributed source code builds then the more cores the better.  You will see a marked difference in performance for these types of application as you move from 1 to 2 to 4 to 8 cores.
Otherwise running standard applications really won't benefit from more cores. Even games really won't exploit multiple cores that much.  IMO, you are better off spending the money on a better graphics card.
It depends. If you're doing things that will use every core heavily 4 cores is better (video editing, rendering etc). Most people will find two fast cores better at the moment because not many applications are written to take full use of 4 cores
Note that the latest i7 processors can actually increase the clock-speed on the active cores when not all of them are needed; for example, if you have a quad-core at 2.4GHz, but the software only needs 2 cores to run, then it may automatically get clocked up to 2.8GHz (not an actual figure, just an example).
For everyday use and programs that aren't multi-core optimized a fast dual-core will beat a slower quad-core.
For some applications, it's very easy to take advantage of multiple cores. But some other applications will never benefit from them, while the others might benefit if the developers optimize them (which is very difficult).
And the latest generation of the i7 I think can clock up 3 or 4 bins if only one or two cores are needed. As such, it may not end up staying as much of a trade-off as it currently is...