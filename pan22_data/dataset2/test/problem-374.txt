An example of an approximation algorithm that converges to the exact solution would be the Ellipsoid algorithm for solving LPs - if the coefficients are rationals, then one can compute a minimum distance between two vertices of the feasible polytope. Now, the ellipsoid algorithm computes repeatedly a smaller and smaller elliposoid that must contain the optimal solution. Once the elliposoid is small enough to contain only such a single vertex, you essentially found the optimal vertex. This is why LP is weakly polynomial.
As for an example closer to your outline - consider Matousek's algorithm for finding the smallest disk containing $k$ points in the plane. The algorithm first finds a 2-approixmation (in the radius), break the plane into appropriate grid, and the solves the problem inside each grid cluster exactly, using a slow algorithm.   
Finally, going further a field - many algorithm that follows the alteration technique (take a random sample - and then do some fixups to get what you want) falls into such a framework. One cute example is the algorithm for computing the median using random sampling (see the book by Motwani and Raghavan). There are many such example - arguably many of the randomized incremental algorithms in Computational Geometry falls into this framework.