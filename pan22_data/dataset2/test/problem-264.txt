My questions are: is this a reasonable approach?  If so, is there an app out there that will do the job of the "reverse proxies"? (Squid?  IIS itself?)
The goal is 1) to maintain only a single web service, rather than one per domain, and 2) to decouple domain/web site management from the business logic in the web service.  That is, if we know that context will always be specified with a key in the HTTP header, then we don't have to worry about domains changing or the specific content of Request.Headers["HOST"].
Secondly, passing extra headers and identifying traffic by that is the standard and accepted way to identify traffic handled by a load balancer. For example, that's how load balancers are usually configured to inform web servers that traffic is coming in over SSL (as SSL can't be proxied at that level).
Finally, I think you may be overcomplicating your problem. Realistically how often do domain names change compared to the content behind them?! That's not really how the web is meant to work... There's nothing wrong with your application serving content based on domain name in the HTTP Host header, it's very common practice.
In this system, the "reverse proxies" (for lack of a better term) add an HTTP header to the incoming requests before they hit the web service.  Otherwise, the proxies are entirely transparent to the request and response.
I'm trying to design a system that allows for multiple public endpoints that funnel into a single web service.  The web service must be able to determine which endpoint was the intended destination of the request.  Here's a little sample configuration that might fit the bill:
Firstly, your HTTP Host field should be preserved by your reverse proxy as it passes the request through. If it's not, then your proxy is wrongly (and weirdly!) configured.