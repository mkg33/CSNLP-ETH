We also have developers who build software expecting sub-five-second synchrony between servers, developers who implicitly rely upon AD time for sync, and who dodn't bother to write error-checking or handling routines for non-sync cases, and who assert that subsequent failures are the fault of the admins for not maintaining network time to the standard they were imagining..
I've done all of the options (Local, UTC, arbitrary but consistent) and prefer the "local time to the home office for all machines" as that's where the sysadmins and users were, even though the machines were scattered all over the world.
I work for a very large hosting company, and we have datacenters worldwide.  We generally set machine time to local datacenter time, and then use the timezone where all our support personnel are located as the universal time that things are converted to when using tools, etc.
We have machines physically located in one timezone that are set for 3 hours ahead because of the application they support.
Jokes aside, it's basically saying use only UTC means not bothering with Daylight Saving Time (DST), and the bugs that this brings about.
Policy here says all machines are timzoned to their local timezone (i.e. physical location). The only thing tricky is correlating event log entries (windows machiens) as the time is give nlocal - most other logfiles write the time in UTC anyway.