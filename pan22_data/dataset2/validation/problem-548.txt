Since you probably initialize your weights randomly, you might want to change many of them in the beginning of training but you might want to disturb less and less weights as they become more trained. That's why you decrease the radius.
This formula is just a particular policy of change of the radius with each iteration. In this case it is exponential. You can choose another policy or keep the radius constant or decrease it slightly (not exponentially) which may be reasonable if you use some domain knowledge when initializing the weights. Also, you can keep the learning rate constant if you like. The radius of the neighborhood and the learning rate are hyper-parameters. It is up to you how to choose them.
The radius r_ij is the radius of the neighborhood of the winner. Only those neurons that are closer than r_ij to the winner are allowed to update. 
The formulas that you show here say that this radius is not constant but decreases with each iteration. Initially you take a large radius, and then make it smaller and smaller with each iteration. 