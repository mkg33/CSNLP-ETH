In addition to the other recomendations I like to use Fiddler to see exactly how long individual requests are taking and how much badwidth is used.  It runs from the client so it shows me how long each request takes from that persepctive.  
Seems to me you need to know network connections for each process, the amount of traffic for each socket connection, the response time for each socket and a way to visualize the data.
Can't hurt to perform actual load testing from multiple locations as well. Run a local load test, and then run one from various locations outside of your data center. The local tests should give you a good baseline of what to expect at LAN/local conditions. Then you can compare that to what you get externally, and you can see what sort of loss you're getting on the networking end. Obviously, the external tests are going to have higher load times, but you have to determine what's acceptable in that realm. 
To see if it's the DNS server, you can try to bypass the DNS server.  You can do that by adding the relevant host names to your hosts file.  If, when you have the addresses in the hosts file, the web server seems to be responding much faster, then investigate the DNS further.  If site performance still sucks, the problem is most likely elsewhere.
More advanced; You can also query the DNS directly with nslookup or dig.  Make sure you query your web site domain's authoritative DNS servers directly to see their response time, as opposed to the response time of the local DNS server, which may have a cached copy of the entries.