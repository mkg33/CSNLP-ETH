One approach in projects I've used in the past is to manage this via a set of different phyics "states" which an object could be in. Examples might be: Grounded, Airbourne etc.
For example, imagine the case of a player character who appears in midair, above the floor. THe inital state is set to Airbourne and the physics system applies gravity to the character to start them falling.
I think you may need to look further than simple collision detection to make this happen. Due to the discrete nature of a simulation such as this, it's hard to achieve a smooth "flooring" of one   object onto a surface as it will constantly collide, then be adjusted, then collide, then be adjusted again.
Now, the physics system knows the player is grounded, so can use different techniques to track the floor, rather than relying on the hitbox. Depending on your game, you might have a defined "floor" plane which you can query the height of at the current location. You might be able to ray-cast downwards (a short distance) to ensure you are still near the ground, and then transition back to 'Airbourne' when not.
Eventually, the AABB hitbox detection system detects a collision between the player physics hitbox and the floor hitbox. At this point the physics state transitions to Grounded and the position is adjusted to ensure there is no collision (as you discuss).
In this way, you run a different set of phyics rules depending on the state your object is currently in, and use hitbox detection differently in each, and to help transition between the two.
There are many approaches to this, but the principal is that simple hitboxes are probably not sufficient for "smoothly" adhering one object to another where movement is possible. Use them to detect collisions, and use that information to inform transitions in your physics system to control character movement.