Although I haven't implemented it yet, I'm planning on moving all of my log-generating machines to rsyslog, and implementing a bastion-type server which will function as the collector of syslogs. From there, I think the free version of Splunk can do everything I need to pull out information. 
Then on the loghost we have some custom scripts that are similar to logcheck that basically watch the incoming logs for anything suspicious.
I use a central syslog host.  Each edge system sends *.debug to the central loghost.  The central syslog host runs syslog-ng, and has rules to split logs so that each machine generates its own files named for that day.  It also dumps everything into a single file, against which I run a descendant of logcheck.sh.
Each of my application servers runs a small perl script to send their logs to syslog, which then forwards on to the loghost (perl script below).
Once a day I run a log compacter, which zips up any logs older than 7 days, and deletes anything older than 28 days.  Between the two, it gives logs an expected life of 35 days on the server, which means that all logs should make it to monthly backups, where they can be recovered for up to two years.
I have 20-30 Linux servers and a few Windows boxes (most of them virtualized). We utilize a lot of Perl and Bash scripts to do most of our automated jobs and I'm trying to standardize their logging.
I've got about 30 servers, and I just use straight up syslog to send all the logs to a single logging server.  For backup, all of the machines are also configured to store their own logs locally for a few days, using logrotate to take care of the rotation and deletion of old logs.
Here is my logging perl script.  It works by piping the program's output into it, and then it syslogs the output and spits it back out so you can send it elsewhere (I send to multilog).  You can also give it the -q option to just go to syslog.
We also have all of the email from every host going to one place, so that if any program complains that way, we get all the messages.  This could theoretically go to a single mailbox that a program could act on and analyze.
I've seen other tools like swatch and logcheck, but I'm not quite sure how all these pieces fit together...  Any recommendations would be greatly appreciated!
I've been looking at log4perl and log4sh for logging of scripts and syslog-ng to get all the logs on a centralized logging server. I've also read up on splunk, even though is sounds like the enterprise edition is pretty pricey and I might go over the free license limit with all my servers.