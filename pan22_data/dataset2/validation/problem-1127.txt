You see that await is 119.61 while svctm is 2.44 and %util is 100.20. Note that the avrqu-sz is large, quite large at 141.31. So, the IOs are waiting in the block layer before being serviced and we see a high value of avgqu-sz also meaning that there are pending IOs also meaning to go to block layer. Again, an indication that we are not seeing a sequential stream of IOs but random chunks and that is why, svctm is perfectly fine while await and avgqu-sz are high.
Here's my suspicion of what is happening, though I don't know enough about ImageMagick to confirm it.  By limiting the amount of memory to 512 bytes, in order to process the image ImageMagick is forced to use the disk as an intermediary storage method since it cannot use memory.  As a result, it ends up consuming a huge amount of I/O throughput as it pages chunks in and out, causing the system to lock up.
With this command I get about the same real time as when not using limit and I have more or less the same IO activities than without the limit options.
And btw,good job with the blktrace output. You might also want to go ahead and make a pdf using seekwatcher utility.
You set 256B for the maximum memory and 512B for the file mapping in memory. Thus instead of having nice big chunk of buffer read, you read the size of FS block (or even less if you have a 4K hard disk). This is something that would generate a lots of unnecessary IOs.
Also, can you please tell what is the throughput of the disk, in disk vendor's term, IOPS. So that I can also tell whether you are saturating your disks.
I have run your exact command line (although with a different picture I presume ;-) ) with and without the limit options. And I understood the problem: the limit options unit are in bytes. What does it mean?
So, it boils down to how the application is issuing IO. I don't think you can control too much of that about. So, try without limiting the convert command and see whether you can get a stream of sequential IO.
From the arguments you have to ImageMagick, you look to be desiring a 200x200 TIFF file... yet your iotop output shows a 70MB/s write out to your RAID array and an absurdly high number of I/O transactions per second.
You haven't shown a comparative blktrace without the --limit option but I would assume that when used with limit, the convert command isn't doing random IO or at least the randomness reduces to some extent.
Why are you setting the limits so low - in fact, why do you have them at all?  Setting them higher will reduce the amount of paging that ImageMagick has to do significantly.  If you don't trust the images coming in and you are attempting to keep the images from consuming too much resources, put a cap on the size of the images you permit conversion of, set the memory limit to, say, 2-4X the cap you specify, limit the number of simultaneous conversions, and for extra paranoia, limit the command execution time to prevent an intentionally malformed image from cycling forever.
sdb3              0.00  1138.00  0.00 410.00     0.00 8700.00    42.44   141.31  119.61   2.44 100.20
When the Q2Q goes high, it means that there are time gap between the successive requests coming to the device queue from the application. Application issues an IO, it doesn't issue the next IO from the next sector of the disk, disk head goes to seek somewhere else and when it finds the proper one sector, application issues the next IO. This kind of IO is called random IO. Random IO increases the Q2Q time or time between requests sent to the block layer. 