In the good old days your program was responsible for doing everything that needed to be done during the execution of your program, either by you doing it yourself or by adding library code others wrote to your program.   The only thing running beside that in the computer was the code to read in your compiled program - if you were lucky.   Some computers had to had code entered through switches before being able to do more (the original "bootstrap" process), or even your whole program entered this way.
I experimented with a Microkernel capable of running a Java Virtual Machine, but found later that the sweet spot for that is Docker.
Kernels, in addition to mediating shared access to RAM and hardware, also perform a loader function.  
Finally the terminal program means that your program doesn't need to know how to draw a window, nor how to talk to the kernel graphics card driver, nor all of the complexity to do with dealing with screen buffers and display timing and actually wiggling the data lines to the display. 
Doing I/O in user-mode (without the kernel) is not possible, if you access I/O ports or registers for devices, or addresses connected to devices (one or both needed to perform any I/O), these trigger an exception in the same way.
In typical desktop OSes, the kernel itself is an executable. (Windows has ntoskrnl.exe; Linux has vmlinux, etc.)  If you needed a kernel in order for an executable to run, then those OSes could not exist.
Say you have a terminal program running on a desktop window manager, running on your kernel which in turn is running on your hardware.
If you load this executable somehow from an operating system somehow (i.e. if it allows raw code to be loaded and executed), it will still be in user mode.  If your code accesses things that are prohibited in user mode, as opposed to kernel mode, such as unallocated memory or I/O device addresses/registers, it will crash with privilege or segment violations (again, exceptions go to kernel mode and are handled there) and still won't work.
If your compiler produces a file that's meant to be processed by an operating system loader, and that loader is not there, it won't work.
The kernel does not process every instruction in a program.  It just does the system calls and switches between running programs to share the CPU.
These executables also reference libraries (Windows .dll or Linux shared object .so files) - their code has to be included.
What you need a kernel for is to do the things a kernel does. Allow multiple executables to run at once, referee between them, abstract the hardware, etc. Most programs aren't capable of doing that stuff themselves competently, and you wouldn't want them to even if they could. In the days of DOS -- which could barely be called an operating system itself -- games often used the OS as little more than a loader, and directly accessed the hardware much like a kernel would.  But you often had to know what brands and models of hardware were in your machine before you bought a game. Many games only supported certain families of video and sound cards, and ran very poorly on competing brands if they worked at all.  That's the kind of thing you get when the program controls the hardware directly rather than through the abstraction typically provided via the kernel.)
Your program "needs" the kernel in just the same way it needs the standard C libraries in order to use the printf command in the first place.
The actual code of your program runs on the CPU, but the branches that code makes to print something on screen go through the code for the C printf function, through various other systems and interpreters, each of which do their own processing to work out just how hello world! actually gets printed on your screen.
And that is where we are today.  Your programs run full speed but whenever they need something managed by the operating system they call helper routines provided by the operating system, and that code is not needed and not present in the user programs themselves.  This included writing to the display, saving files, accessing the network, etc.
Sure.  You need to convince the OS to somehow run your raw code without processing any metadata.  If your code calls kernel APIs, it still won't work.
The kernel is "just" more code. It's just that that code is a layer that lives between the lowest parts of your system and the actual hardware.
Effectively everything you do that needs hardware access, be it display, blocks of memory, bits of files or anything like that has to go through some device driver in the kernel to work out exactly how to talk to the relevant device. Be it a filesystem driver on top of a SATA hard disk controller driver which itself is sitting on top of a PCIe bridge device. 
The kernel knows how to tie all these devices together and presents a relatively simple interface for programs to do things without having to know about how to do all of these things themselves. 
All this resulted in a large amount of helper code being moved out of the individual programs and into the "operating system", with a standardized way of invoking the helper code from user programs.  
Essentially, only system calls go to the kernel.  Anything to do with I/O or memory allocation/deallocation typically eventually results in a system call.  Some instructiosn can only be executed in kernel mode and will cause the CPU to trigger an exception.  Exceptions cause a switch to kernel mode and a jump to kernel code.
It was quickly found that it was nice to have code running capable of loading and executing program.   Later it was found that computers were powerful enough to support running several programs at the same time by having the CPU switch between them, especially if the hardware could help, but with the added complexity of the programs not steppings on each others toes (for instance, how to handle multiple programs trying to send data to the printer at once?).
Doing memory allocation in user-mode (without the kernel) is not possible, if you access memory you don't have permission to access, the MMU, previously programmed by the kernel, notices and causes a CPU-level "segmentation fault" exception, which triggers the kernel, and the kernel kills the program.
Desktop window managers provide a layer that means that programs don't have to know how to draw windows and play well with other programs trying to display things at the same time.
Many "executable formats", like ELF or PE, have metadata in the executable file in addition to the code, and its the loader's job to process that.  Read the gory details about Microsoft's PE format for more information.
Microkernels have been written that provide just what is needed for a given program to run without a full operating system.  This has some advantages for the experienced users while giving away most others.   You may want to read the Wikipedia page about it - https://en.wikipedia.org/wiki/Microkernel - if you want to know more.