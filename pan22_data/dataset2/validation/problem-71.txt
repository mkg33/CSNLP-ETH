Exceptions that I've encountered are situations where you have lots of small writes mixed with large writes. One example that comes to mind is a busy windows file server with users doing stupid things like running active PST files on the server. Another would be a linux pop3 server with mailboxes in Maildir format.
It's a bit of a yes, no answer. Useful in certain circumstances but it's less of an issue than it was with FAT or regular HFS. All filesystems will fragment but newer ones are more resistant to fragmenting so badly.
HFS+ does fragment, all filesystems do. However, it doesn't appear to suffer from it, at least not to the extent that NTFS / FAT32 do.
Fragmenting still happens and you can see performance drop because of it, especially in video editing systems or a workflow that requires the ability to read or write large files quickly to the disk. For your standard user - a near non-issue.
A caveat-- I stopped noticing performance drops from file fragmentation about 5 years ago, at least as far as local files were concerned. SATA bandwidth and a 7200RPM HDD make the issue pretty much un-noticeable, IMO.
Speaking for Mac OS X specifically HFS+ does a decent enough job of trying to keep things from being fragmented compared to older systems but it still happens just not on the same scale. The OS itself also defrags "small" (20MB or smaller) files on the fly since 10.3 (Panther).
This is a religious issue. IMO, fragmentation is only an issue for specific workloads, and it hasn't been terribly relevant since NT4.