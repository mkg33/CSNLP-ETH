DCE vs DTE. Ethernet (10base-T and 100base-T) has a TX pair and an RX pair; TX has to go to RX and v.v. When connecting like kind devices -- hub to hub, computer to computer, a crossover cable is necessary because they have the same pinout; a straight cable would connect TX to TX, etc.
Note the difference to optical fiber: since this hasn't been used for analog signaling, fiber uses a crossover in every connection - plenum and patch. Usually, you've got an odd number of cable segments, so receiver and transmitter are crossed as required.
There are both cross and straight connections. In the past it was important to use specifically one or another - depending if you connect two devices directly or via hub/switch. Today most NICs and switches do auto discovery of the cable type and act accordingly 
Originally RJ connectors were designed for telephone standards. One design feature was you could put a smaller plug in a larger socket and it would connect to the first pairs. To achieve this the first pair was on the center pins, the second pair on the pins straddling the center, the third pair straddling those and so-on.
Most modern networking gear supports "auto-mdix", which means they can logically swap their tx/rx pairs. (old hubs/switches had a switch that would physically swap the pairs.) Gigabit (and beyond) technology uses all four pairs for both TX and RX.
10BASE-T implementations chose to use this layout and chose to use the Second and Third pairs. Presumably the second and third pairs were chosen in an attempt to allow coexistence with basic voice service on the first pair.
Unfortunately this was not good for high speed data. The splitting and straddling of pairs was bad for signal integrity and this got worse as the pair count grew. However there was a desire for backwards compatibility with basic phone applications. This resulted in a compromise pair layout. The first pair was in the center, the second pair straddled the center, but the third and fourth pairs did not straddle any other pairs instead being placed with one pair down each side.
However, connecting two network devices requires the transmitter on the one side to talk to the receiver on the other side. To avoid additional crossover cables, the specification called for one pinout on the "host" side (MDI for PC NICs, routers, ...) and a pinout with an internal signal crossover on the "network" or concentrator side (MDI-X for repeater hubs, switches). If you now wanted to connect to PCs (MDI to MDI) or a switch and a hub (MDI-X to MDI-X) you still needed a crossover cable.
Later auto-MDIx came along allowing automatic switching, so it did not matter if you used a crossover or straight-through cable.
I am astonished why RJ45 8-Pin connection was configured from the beginning as the connection is a little wired while Straight Connection is comparatively easy to understand and connect.
Today, nearly all ports support automatic pair-selection (Auto MDI-X) that you can mostly forget about crossover cables.
Historically, the first twisted-pair Ethernet, 10BASE-T, was designed to use the already commonly deployed voice-grade cabling (Cat-3) with straight-through pinout. (10BASE-T's predecessor StarLAN wasn't offically Ethernet)
Ok, that explains the pin allocations but what about crossovers? Well 10Base-T and 100Base-TX use one pair in each direction. For correct operation the transmitter at one end must be connected to the receiver of the other. That means we need to cross-over transmit and receive somewhere. Most of the time this was done inside the equipment, network cards used "MDI" pinout while hubs used MDIx pinout. So they could be connected with a straight cable. From time to time though it was nessacery to connect a MDI port to a MDI port or a MDIx port to a MDIx port, so a crossover cable was needed.