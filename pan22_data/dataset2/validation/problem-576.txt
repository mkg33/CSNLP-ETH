The previous ones to this question are all worthy answers, but they are all colored by large-scale thinking. If you have only a single host, providing web sites whose failure will not immediately kill kittens, you may want to think somewhat smaller. I would suggest the following:
I would like to add: cleanups of old users, old cron tasks, etc. Passwords renewals. Evolution of system configuration (looking at monitoring history) (and this includes evolution of monitoring and backups) with the life changes of the server. Security audits. Custom reports (i.e. detailed usage of services, shared resources, security reports). And...
You ask for scripts. Maybe there are generic pre-packaged scripts, but it is more about DIY (Do It Yourself). So first you learn or read how your system works (this includes distro specific REAMEs, man pages, policies and compilation options), then yo think how your system should behave, and then you write custom scripts (cron, custom commands, etc) to manage the combination of O.S. + desired behavior/results/reports/change-management/rollbacks/reactions/etc.
However, the essence of systems maintenance remains the same: kill each issue that occurs dead so that it can never occur again. This is an important point, because it means that there should be no "regular" maintenance.
And as well as the backups, the monitoring system + customizations, should be validated where possible, simulating failures, attacks, etc.
Just wondering what are a regular maintenance you need to perform on your Linux server? Are there any scripts that let you do the maintenance?
and a lot of others .. of course it is supposed that system is already hardened (at least with default SElinux targeted policy),
Maintenance is done by monitoring. If you have an machine exposed to outside access you have to have some checking tools: 
I've seen firewalls survive 500 days of uptime (yes, that is a BAD maintenace, because there are about 10/15 kernel upgrades a year, so big uptimes, use to be equal to vulnerable kernel) without any human maintenance. It's just a good config on partitions, syslog and no major configuration changes.
Also, available generic tools (monit, nagios, cacti, zabbix, etc) can be extended with your scripting skills and available third party plugins.
Custom scripts are better, when you can validate them and clean bugs, on a pre-production server(s), environment, directory, database, etc.
I have a server that host few websites, I haven't done any maintenance for about 2 month other than looking at a couple logs and compressing them. 
In example: do you need only to know "if partition is full", or do you need too to control disk temperature, free inodes, files and folders rights, checksums, S.M.A.R.T. status, bad sectors, filesystem checks, and estimated life cycle of physical hardware?
Use logwatch or similar system that aggregates your logs and mails you a summary. Read the summary at least every other day. Use a tool that crunches your weblogs (e.g. analog) into a readable summary. If you want to be a bit more ambitious, use a cloud service to monitor your sites.
Restore backups randomly (without needing to do it). Also always include a copy of the  MBR (Master Boot Record) if you do not use an automated deployment system to restore the whole server.
Among the first issues you have when you scale up is that something breaks and you don't know it. This must never occur again. Then you get a full-scale monitoring solution. Also, having seen the issue occur on one host, you want to prevent it occurring on any other host. That's when you get a configuration management system.
Patch your OS to get the latest bugfixes and security updates.  This is the single most important step you can take.  Beyond that, you need to have monitoring in place to tell you the state of your system over time.  I have to disagree with the point above that monitoring is not maintenance.  You need to get a baseline understanding of your system and how it runs to see when things are not working or need maintenance in the first place.  The only way to really do this is to graph everything.  We use a combination of Nagios, cacti, and ganglia for this.
would be great to do performance monitoring with nagios,zabbix and others .. (to keep on eye on out of ordinary events and status of the machine)