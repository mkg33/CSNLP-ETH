I think the reason they aren't is because of the potential to cause confusion.  If you have a character that looks like a "?" but has a different unicode code - how will you tell the difference?
The reason is probably because it would be too hard to deal with files with those characters in them in the old command.com shell, e.g. ? also means any one character, * also means any file, etc.
You can use those characters now yourself. But I'm assuming you mean to have the operating system automatically transliterate between an ASCII question mark, for example, and a lookalike such as ï¹– (SMALL QUESTION MARK - UFE56). I really don't think that's satisfactory, especially since Linux and others, where the only invalid characters for filenames are slash (/) and null (ASCII 0), accept those characters readily.
How would you explain it to someone?  "You can't have a question-mark in your filename, but you can have a thing-that-looks-like-a-question-mark-but-isn't, and to type it you only need to use this 5-key combination."?
There wouldn't be Unicode equivalents for those characters, and if there was an equivalent, it still wouldn't solve that problem: the existing ASCII ? and * would still have to work as wildcards, otherwise everyone would have to re-write their scripts.
Rather than teach everyone how to handle those special cases, they disallowed it, making it easier to script.