Neither of these have queuing or job scheduling, although you could run them via cron or at if you wanted to.
Ah!  It looks like the GNU version of parallel (not the one I had installed) does do this. No load balancing, and I haven't tried it out to see what it does with each stdout and stderr, but this is precisely what I wanted. 
Unfortunately I've written a script that gives status updates, has configurable output settings, and incorporates some simple load balancing, so I'll be sticking with it for now.
clusterssh is another tool that might be worth looking into.  It's more interactive in that it will open and tile terminal windows for each host.  You can also run commands in each terminal separate from each other or in all (or some) at once.  For example, running top on 12 systems at a time then chasing down a process in just one of them.
parallel means to start the same command on an collection of hosts (running in parallel) ... if you want to do different things on different hosts that is an sequential process 
I've also seen a few talks for rshall (which despite holding RSH in the name, uses ssh natively) at the local Linuxfests, it's perl based and can use an external source for querying host lists, but it expects certain host information in specific formats.
You really should look into one of the many clustering technologies out there.  Try looking at Apache Hadoop.  I recently read a great article that you may find interesting on the subject too about setting up a 10,000-core cluster to do parallel computing:  http://goo.gl/A8hgX