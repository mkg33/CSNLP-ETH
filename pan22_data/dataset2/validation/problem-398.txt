The blank could be filled by both hot and cold hence the similarity would be higher. This concept is called Paradigmatic relations.
Word2vec does not capture similarity based on antonyms and synonyms. Word2vec would give a higher similarity if the two words have the similar context. Eg 
What is the best way to figure out the semantic similarity of words? Word2Vec is okay, but not ideal:
So what is the problem? The issue lies in word sense ambiguity. Whenever the word itself has two different meaning in two different context, the word vector will tend to really be away from either context. Python ~ Boa (both snakes) and Python - Java (both programming languages)..
Word2vec is a good starting point for most scenarios. It does capture semantics by way of prediction using CBOW method. It allows translations (as most repeated example I can put here again), V(King) - V(Queen) ~~ V(men) - V(women) and so on. 
If you are interested to capture relations such as hypernyms, hyponyms, synonyms, antonym you would have to use any wordnet based similarity measure. There are many similarity measures based on wordnet. You may check this link http://ws4jdemo.appspot.com/
For the very specific purpose of "synonyms" if you want Wordnet would be ideal place. It captures explicit relationship of two words rather than implicit relation based on usage and occurrences. 