No, but it is possible that there is another caching device between you and S3.  Like Microsoft's ISA server, which has caching of web traffic and I've seen it do this kind of thing many times.
This second method allows you to use aggressive caching on the S3 file and avoid wasted transfers. But it requires you to modify every web page that links to the file every time you change the contents of the file.
If i add a random version number to the url (?version=randomIntByTime) Chrome will finally save the latest version of the file. It is frustrating to write extra code for Chrome.
Yes it does. I am having the same issue even if i am not using S3 as storage. I have a Symfony2 app that serves the contents of a local file for download. The url is always the same because i am getting the contents of the file in PHP and send them to the browser. If i modify the content of the local file, Firefox and IE will receive the latest file version BUT chrome won't. I tried to set cache control headers but it's useless, Chrome just ignores them.
See Lower your Amazon S3 Bill for more on both techniques, though you're trying to get the opposite effect.