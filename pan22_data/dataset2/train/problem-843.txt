With respect to how many VM's you can run from a single NAS, there is no magic answer to this question.  It will depend upon a number of factors, including the NAS configuration and your client workload profile, both of which can vary significantly from deployment to deployement.
Frankly these NAS are nice to share and store office documents, but forget them for anything performance related. If you want a NAS with good performance, go for a well built server platform with a NAS OS like Openfiler, a good RAID card and fast drives. Or even better, ask a specialist. Don't buy a cheap WSS2003 NAS, they suck horribly too and perform quite poorly.
While I'm all for NAS based solutions (LeftHandStorage, Netgear, Drobo, Thecus, QNAP, etc. etc.) I'd first ask what is "real-world" environment to you? How many concurrent VMs do you plan on running, what OSes, what roles (email, web, file), blah blah blah.
If you are looking to build some low cost, reliable storage for your XenServer cluster, take a look at NexentaStor.  You can install this storage OS on any x86 hardware, which will keep your costs low.
I myself built some NASes for Xen storage (building NAS is my job). With 30 to 40 VMs, as good as they are they're quite overloaded with only eight 1TB drives. The NAS machines are dual CPU Opteron, 8GB RAM, 3Ware9650, 8x1TB RAID 6+ spare, specially optimized Debian system, iscsi enterprise target, DRBD for High Availability. That gives you an idea of what you may need.
Or am I better off spending more on a DAS Fiberchannel shelf and plugging it into a DL380 with Openfiler?
I'm looking for a low-cost NAS/SAN/iSCSI target shelf to host VM's in a production real-world environment.
Will the Thecus N8800 or the QNAP TS-809U provide sufficient enough performance to host multiple Virtual Machines? (XenServer)
The best way to determine the best configuration is via workload profiling determined via performance testing, upon which you can make reasonable sizing and capacity planning estimates.
I don't have any experience with OpenFiler (yet) but I'm sure that it would suffice for all your storage needs. 
Second if this "real-world" production environment needs high availability, would you risk using SATA disks vs. SCSI or SAS (assuming both models you listed are SATA)? I'd sleep better at night with SCSI or SAS.
From the information you've given, if you have the opportunity for FC in an HP DL380, I wouldn't hesitate for FC. If you can afford it, maybe two FC controllers for failover, but the pure bandwidth alone from FC is too good to pass up and the DL380s can hold up to 12 disks (I think) which is more than either one of those NAS devices. 
We are serving more than 100 VMs on the HP EVA FC SAN. I have also just installed a Thecus n16000V NAS with 11 3TB SAS disks in a RAID 6 configuration. The latter is price wise much cheaper than a real FC based SAN, but performance seems to be quite good so far. Currently I have some Samba shares and some iSCSI volumes. From personal experience so far, I can report over 1gbit/s effective bandwidth. Which is quite good for this kind of storage device. Should you use Thecus NAS, you should also upgrade firmware with the latest version, as current one still has some issues with RAM consumption. Other NAS devices from Qnap and Synology are also good.