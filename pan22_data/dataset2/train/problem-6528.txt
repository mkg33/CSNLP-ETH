There is a different kind of CI tools out there, the gating-commits ones, which actually perform the technical integration, run the QA verifications on the result and, only on success of the verification, they also merge the result into origin. They effectively do the entire software integration work and are thus capable of guaranteeing no QA regressions in the end result.
With the rise of infrastructure as code you could of course say okay I have git to put my Dockerfiles for example but this makes somehow no sense.
To extend others' answers, CI allows to have a "single place of truth" how the software builds and runs in terms of system environment dependencies.
Merging code changes is definitely handled by Git and its tools.  But Continuous Integration also includes testing and building the software. The development teams are provided with constant feedback on the status of their branch(es) and whether they are failing tests, builds, etc.
Jenkins provides the tools to enable this feedback.  By creating a CI "pipeline" in Jenkins the developer gain much better insight into the build, beyond what simple Git merges and stashes provide.
Jenkins won't technically do the integration steps itself, AFAIK it is not capable of doing that. Its operation is only triggered after the technical integration steps are completed, typically by the developers (in your case after you git commit and git push your changes to origin).
Many open source projects on GitHub verify validity of pull requests through CI untegration and do double, even triple checks, that is even just one CI system appears not enough to achive high quality.