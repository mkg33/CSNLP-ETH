It is very easy to use if you are familiar with SQL, you can run SQL-like queries against the raw log files and it is very fast (as fast as your drive allows), and you can easily group by columns, generate charts and more.
Simple and effective (equivalent to grep and wc -l), but it's not the fastest for a lot of domains or regular runs. If this is a regularly-run report, you'll probably want to use something that will parse them all in one pass and depending on report duration keep log data/summary data in some sort of index.
We have a number of legacy domain names that are setup as a site in IIS7. This site then forwards those domain names to the new domain name. The logs of the legacy sites store the name of the legacy domain that had been referenced.
We would like to run a report that shows the raw number of times each of the legacy domains have been hit. We can install new software to capture this info or we can parse the current IIS7 logs to do this.
http://www.microsoft.com/downloads/details.aspx?FamilyID=890cd06b-abf8-4c25-91b2-f8d975cf8c07&displaylang=en
I did a blog on some samples at: http://blogs.msdn.com/b/carlosag/archive/2010/03/25/analyze-your-iis-log-files-favorite-log-parser-queries.aspx
It would depend on how you do the forwarding and logging. If you return status code 301 or 302 for redirects and only for those domains and have that logged you can just count those. Another option would be to log the host header (this can be enabled in w3c logging) and just query that.