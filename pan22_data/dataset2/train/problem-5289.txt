Video games are a particularly poor performers on emulation or virtualization due to the 2D and 3D video performance, which is an area often lacking in speed-ups of various competing VM or emulation solutions. In many cases the 3D graphics are rendered in software, and are not as heavily optimized as processor and OS emulation / virutalization portions. This is slowly changing, VMware has improved their graphics acceleration in certain cases.
Diablo II is probably done the same way. It was programmed to run at a certain speed according to time not processor's speed. You might be able to speed it up using emulation technology, but I'm not too sure how to go about doing that.
While Moore's Law is typically seen to collate the doubling of transistors to a doubling of CPU computation or processing power, this doesn't scale to the entire system, not even to hardware performance (RAM size and speed, Hard drives).
one method is to use a processor emulator (such as qemu*, bochs, spim, PearPC) to emulate one processor on another system is a complex task. 
I'm surprised to have to mention the Megahertz (Clock Rate) Myth to a Mac user. Short form: You cannot use CPU clock rates as a comparative guide to CPU / system performance. 
Let's start with the question title and description being very misleading. You do not clearly state that you are using some form of emulation to run Diablo II (released in 2000 for Mac OS on PowerPC, and Windows on x86) on your Mac Book Pro, which I presume is running its native OS X, since you do not include anything to suggest otherwise.
These tasks are complex, with on-the-fly translation of native instruction sets for emulators, to JIT or dynamic translation of memory and processor mapping to simulate a virtual computer that is isolated or different from the "host" system, including Operating System and its kernel. For example an app running via PearPC is quoted as running 40 times slower than a native running application.
Another method is using a platform virtualizer (such as Xen, VMware, Parallels) that runs a isolated virtual computer system including simulating or mapping hardware features (I/O).
Most of the time, games are programmed so that they can specify how fast something runs. This is why if we loaded up Doom classic on a core i7, we don't see monsters moving at light speed and killing us before we can react. 
So I don't think you should be surprised that playing an older video game via emulation or virtualization is still slow on your faster CPU. Unfortunately, the situation was not clear from your question.
*) qemu and several others are both a processor emulator, and a machine virtualizer depending on circumstance (i.e. host environment).
Edit: Sorry! What I meant by the first line is that they are programmed to specify whether or not they use the processor cycle or the clock cycle.
You're comparing a 450MHz chip with a 2.26GHz dual core chip. Why do you think that the former is faster?