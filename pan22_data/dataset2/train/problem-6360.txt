Firstly, some advice on backups in general: you cannot rely on a backup until you have tested and verified that your restore process works. There are a few methods for testing backups:
If you only want a data backup and don't care too much about being able to restore a bootable OS, you can back up files only with the tar command. This means you'll still have your data, but you'll have to reinstall an OS from scratch and manually recover the data (and any installed applications).
My first thought on seeing this is that you should never be specifying a count when backing up a drive. If you wanted to back up a specific partition, you should use a partition block device (/dev/sdXN where N is a number). Otherwise, you should just let dd take the whole drive; by specifying a count you risk (in fact, almost guarantee) that you'll be discarding data and possibly corrupting the filesystem.
This is more or less what you have already attempted. You have the right idea with gzip: hopefully it'll compress any unused space (very compressible) to nothing. You just need to drop the count from your command.
I generally would not consider checking uncompressed size with WinZip to be particularly useful. However, the results you obtained could indicate that you have supplied an incorrect count , which brings us to...
Unfortunately, this will not necessarily work out because deleted files may still exist on disk and will not appear as empty to gzip. Therefore, you should clear unused space first. Your backup process becomes:
Unfortunately, that's not how filesystems work. Most filesystems do not guarantee that all data will be stored towards the beginning of the drive.
Some tools exist, like partclone, that are smart enough to recognise and only back up used blocks. The Arch wiki has some examples on usage with gzip, and the manual has some examples down the bottom. This effectively replaces dd in your pipeline.