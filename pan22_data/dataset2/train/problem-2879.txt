Ideally, I would be able to do this without editing the source of the web server, as the specific server could change. Is there a way for me to directly measure time between a request coming in on a port and the response that is ultimately returned by the machine?
I was looking for generalized interfaces to incoming packets, but I couldn't find any tools other than iptables, which didn't really seem to be the right tool.
So, I'm currently working on a project in which I spin up a set docker image on a number of different machines and configurations. This image basically contains a web server that accepts a number of different, but similar requests to a single port. For this situation, it would be great to measure the typical response time of a specific port across the types of requests.
I feel like this relatively simple level of analytics should be pretty easy to achieve and there must be some tool that achieves this, but I haven't found anything yet. If I looked through the code of iptables I'm sure I could implement something in pure C, but I can't help but think there's a better way to do this.