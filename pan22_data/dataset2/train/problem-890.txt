If you are trying to figure out how to design a way to store the data permanently because you don't currently have a structure, then this is the method I use. Import the file into a staging table (not the final permanent table, I highly recommend you do that anyway, so you can clean the data before moving it to its final location) that has everything defined as varchar(max) or nvarchar(max). Now you can examine each field and see what is in in, look for the max lentgth of each field, check to see if numeric fields contain only numbers etc.  Then you will know from the data what types of fields you need in the production table.  Since this is only the first file, I would tend to create my final table with slightly larger fields than the data indicates, so it doesn't fail on the second file you get. After you have some history, you can tighten them.
If you use SSIS instead of bcp, there is a data profiling task you can use to see what the data is really like.
Well we tend not to care what the originators table structure is, but only if it meets our requirements (which we send to them). 