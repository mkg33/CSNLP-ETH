I've read up on the mdadm extending drive setup, and it makes sense, but I imagine I would use one of the drives as a full backup while I move things over, then add that drive back into the array once things are up and running on three of the 1TB drives, so there's some complication in going that route as well... I'm just not sure which is safer/recommended.
As far as I know, the mdadm "grow" mode does not currently support adding more devices to an existing RAID5, so, unfortunately, you can't use your second option. Or rather, if you do go with the second option, you will end up with a 3-device RAID5 on 1TB drives, with a 1TB drive left over as a spare. (I believe you could configure that extra drive as a hot spare.)
While there are options to move the data over without creating a new array, there is not much point in doing so, the file systems will be offline during the migration either way.
I just purchased and installed four 1TB drives, and the intention is to move off of the old drives and onto the new ones. I have enough SATA ports and power connectors to power all seven of my drives at once, so I've kept the old RAID running while I figure out what to do with the new drives.
I have a server with three 500GB drives, with most of my data in a RAID5 configuration spanning the three of them.
If you have the budget for it, you might as well take the plunge and invest in a hardware RAID solution; sensible ones should start in the $500 price range and include RAID6 support and a battery back up unit. Be aware that the products from a pretty large company in this segment do not allow shrinking units, so you either stay clear of them, or lose some flexibility compared to Linux software RAID, but the additional performance of a battery-buffered write cache is well worth it, especially if you use a journalling file system.
Changing an existing RAID is always asking for trouble, also how old are your 3 500GB drives? If they are more than 3 years old it would be a good idea to remove them from production anyways as they are getting to the end of there lives and you might have more issues with them than you want anyways, re-purpose them in to a low priority dive somewhere else.
Create a whole new array with the new drives, it's not worth the risk or hassle to mess with old drives.  Consider carefully the type of raid you are setting up. RAID5 on drives that large leads to very long rebuild times during which you are vulnerable to a second drive failure and complete data loss.  There are strategies to reduce this risk, such as using RAID6 where you can survive losing two of the drives.
My question is: Should I create a whole new array on the 1TB drives, then move everything over and reconfigure linux to boot from the new md arrays? Or should I just expand the array, swapping out each of the three 500GBs with the 1TB, then adding the final drive?
As the drives in your set are likely going to be somewhat similar (although ideally from different production batches), I would expect them to fail close to each other. With a RAID5 with one failed drive, you have no redundancy left if a single drive fails, and the first thing you do at this point is put all your drives through the extra stress of a rebuild.
In agreement with Phil Hollenback, I think you should move to a RAID6 setup with LVM (the only reason I post this as an answer is that I may not yet comment on this site), but I think he understressed how RAID5 is a bad idea.
Also consider running LVM on top of your new raid array as this will give you options for growing or migrating filesystems in the future.
Using LVM allows you to keep your downtime small in case you ever want or need to migrate again. I think a logical "next step" for your server, in case you do not want to use the opportunity now, would be a dedicated RAID controller card, which would then appear as a single device to the kernel, so you would need to move the data again at that point, and LVM can do that while the file systems are mounted (with some caveats for the root filesystem).
If your goal is to convert a 3-device mdadm RAID5 array into a 4-device array, I believe your only choice right now is your first option: Create a second array with the four 1TB drives, then copy all your data over from the first array.