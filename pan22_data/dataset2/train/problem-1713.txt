I'm setting up VMs networking using bridges. Whole network is configured using 9000 MTU on Linux machines and Linux bridges and 9116 l2mtu on router (I think Linux doesn't expose this setting via ip command). Now I'm reading about jumbo frames in Windows and I noticed it has dropdown MTU menu so I can't just type whatever I want. "9k" MTU seems to be announced as "9014" bytes. I'd be reaaaally sad if it was actual MTU but then I noticed L2 header is 14B long so I guess it sounds like too big coincidence - so does Windows count MTU like l2mtu in Linux? or real jumbo size in windows is 9014+14 = 9028?...
Here's a screenshot of one of the packets with image data when I set the packet size in the camera to 8000 bytes:
To answer your question as good as possible: I think that Linux refers to the size of the IP packet while Windows and my Intel driver refers to the size of the whole Ethernet packet.
Notice: Wikipedia mentions a 4 byte FCS (Frame Check Sequence) after the Ethernet header. However, this was not observed in the captured packets.
Today I wanted to know what the Packet Size in Basler GigE Vision camera means. You can set a MTU there which is applied when the image data is transmitted.
The driver of the Intel Network Card in my computer supports Jumbo Frames of 4088 and 9014 bytes, so I wanted to know which value I have to set in the camera to get the maximum frame size.
For details and a comparison about Standard and Jumbo Frames, have a look at Wikipedia: Jumbo Frame and Wikipedia: Maximum transmission unit.