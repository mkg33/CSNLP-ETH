This would happen is acroread died before it sent any output. Without finding out why it died, you don't have chance of fixing it. Given it's closed source, the only thing you can do is try using strace to see what it's doing when it dies. 
I don't know much of anything about printing, but I definitely think it's lp that's causing the problem, not cat, acroread or pipes in general. (Though, if you suspect acroread you can try pdf2ps, a utility that comes with xpdf).
This thread discusses some diagnostics for being unable to print a large file (though I suspect printing many small files in quick succession can cause the same ailments) --
This will make acroread a lot slower, but hopefully will make it fail at lower loads, so it should be quicker to see what is causing the problem. Note this uses $$ to use the process id of the script. If you call this more than once from the same script, you'll need to find some other way of using different files.
I assume that since you're using the STDOUT/STDIN version of -toPostScript that you're piping to the output of acroread to lp (not shown in the question?). I have a feeling you're hitting a spooling issue -- either you're filling up the spool entirely (which causes lp to barf) or hitting some other kind of limit.