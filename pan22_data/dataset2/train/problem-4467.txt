I want to establish what are the main features (or non-linear combination of them) that determine the price.
I would definitively go for a tree-based approach. Since you already know that there are correlated variables, I would advocate for conditional Random Forests (which solve many drawbacks of the standard random forests implementation). Check: 
And references therein. At least in R there are complementary packages (https://cran.r-project.org/web/packages/pdp/index.html) that allow plotting the impact of each predictor variable over the target variable (house prices). That complements the variable importance ranking pretty well.
I want to identify the main important relationship among the features and the prices.  I don't need a predictor. For example, at the end I will discover that the price depends principally by #rooms/perimeter and #neighbours^2.
I was thinking to apply Kernel methods, in combination with regression or PCA. But I don't know a lot about kernel methods.
Im not familiar with many methods for feature importance but you could try random forest. Explained in:
I have a set of houses with different features (# rooms, perimeter, # neighbours, etc...), almost 15, and a price value for each house. The features are also quite correlated (i.e. perimeter is often correlated with #rooms).
In a linear case, for instance, I can compute a Lasso regression and see the importance of each feature through the coefficients.
For example, the # of neighbours can have a quadratic impact (increase the price if #neighbours < 10, and decrease the price if > 10).
As far as I know, kernel methods cannot deal with categorical variables (don't now whether it is the case). In addition, you will have to use indirect methods to evaluate the variable importance. This could work, although I havent tested it yet:
Giam, X., Olden, J.D., 2015. A new R2-based metric to shed greater insight on variable importance in artificial neural networks. Ecol. Modell. 313, 307â€“313. http://dx.doi.org/10.1016/j.ecolmodel.2015.06.034