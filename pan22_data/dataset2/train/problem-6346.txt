This situation can lead to some problem: With these filter sizes, usually the convolution operation is not perfect with a padding of 2 (common padding) and some edges of the input_field get lost in the process...
1) Suppose input_field is all zero except for one entry at index idx. An odd filter size will return data with a peak centered around idx, an even filter size won't - consider the case of a uniform filter with size 2. Most people want to preserve the locations of peaks when they filter.
Question2: Is it actually a problem to omit a small part of the input_field during the convolution ? Why so/not ?
2) All of the input_field is relevant for the convolution, but the edges of output_field cannot be computed accurately since the necessary data is not contained in input_field. If I want to compute an answer for the first element of output_field, the filter must be centered on the first element of input_field. But then there are filter elements that don't correspond to any available element of input_field. There are various tricks to get a guess for the edges of output_field.
For an odd-sized filter, all the previous layer pixels would be symmetrically around the output pixel. Without this symmetry, we will have to account for distortions across the layers which happens when using an even-sized kernel. Therefore, even-sized kernel filters are mostly skipped to promote implementation simplicity. If you think of convolution as an interpolation from the given pixels to a center pixel, we cannot interpolate to a center pixel using an even-sized filter.