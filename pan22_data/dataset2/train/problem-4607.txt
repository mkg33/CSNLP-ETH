As for the provider-to-provider transfer, I'd expect speeds of at least one megabyte per second.  Transferring 55 GB would take well under a day.  But then you haven't told us exactly how cheap your providers are.  If your new provider offers shell access, you can use wget or ftp to download the files from your old server.
This of course is unencrypted over the public internet, so don't do this if you are worried about the data you're tranferring.
Failing that, you should be able to scp it.  This should be the same speed as the rsync as it uses the same transport but you'll have to restart if the connection drops.
You could just call them and explain the situation. More than likely they well allow you to transfer everything you need at full speed to get yourself started. You're paying money to host your data there, they should be flexible about actually getting your data there.
Also, it sounds like you don't have a backup, which is a disaster waiting to occur. If your transfer process will create an extra physical copy of your data (like an external HDD), please consider updating that copy when your data changes. If your transfer process will occur over the net, please consider something like Amazon S3 (or Rackspace, or Azure, or whatever) both as an intermediate destination and as an ongoing backup. Low-cost hosting providers probably offer no guarantees about backing up your data - assuming they even try to do that, which may be too optimistic - and even if they do make the occasional backup, getting you up & running again may not be a big priority if they encounter some sort of tragedy. 
If shell access is available at both ends, and if you have access to netcat (nc) the fastest way to transfer 55G of data is via netcat and tar.  Here's how:
You also may want to consider sneakernet. Depending on where they're located, whether they would be able to perform part of the service, whether you'd be given physical access if they won't and other factors, you may be able to use an external USB drive to do the transfer. It could certainly be much faster than weeks or months. They may like it as well since it would keep that traffic off their lines. Fedex would be happy to participate, if needed.
Also, 55G using rsync over ssh (if that's available) won't be unbearably slow, and you'll get the benefit that interrupted transmissions are resumed.
I wouldn't worry about 55G - that's really a very small amount of data by today's standards - it won't cause any problems to your new supplier.
If you end up doing the transfer over the network, consider the virtual certainty that a process which takes days or weeks will be interrupted and restarted. For that reason, I am inclined towards an approach such as rsync and away from an approach such as tar piped into netcat. If you are planning to make one big tarfile to copy, don't forget that this will approximately double your current storage usage during the transfer, on both ends, and that there's a good chance your dataset will change while the transfer is occurring, so you'll need some mechanism to update the remote copy with the changes.
If I had 55 GB of data on a server somewhere that was at all important to me, I would use my DSL line to download it all overnight, as many nights as it takes, to make sure I have a backup that I control.  Particularly if the server is with a low-cost provider.  Though the provider may make backups, what happens to those backups if the provider goes out of business?