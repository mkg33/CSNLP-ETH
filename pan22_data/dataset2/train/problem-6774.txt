The "clock speed", therefore, is a (very) rough measure of the rate at which the CPU can perform instructions. The higher the clock rate, the faster it can process. However, there are several physical limitations to this approach, not the least of which is the second law of thermodynamics which states that no system can be perfectly energy-efficient. Some of the energy input is lost as heat, and heat can very quickly cause the delicate circuitry of the CPU to swell and short-circuit, or in the extreme even melt down. There are also physical limits to the frequency at which you can vibrate the electrons in conductive materials; at some point you're trying to vibrate them faster than the electrons can physically jump between atoms. Lastly, there's a point of diminishing returns to making the CPU go faster, when other limits inherent in other components of the computer are maxed out. When the CPU is waiting for bits of data to be received from the hard disk or a network connection, it can't proceed with any instruction that needs them, and so 
CPUs have, as their "heart", a quartz oscillator or other very precise timing mechanism called the CPU clock (not to be confused with the "system clock" that maintains the current time using a different system). This clock sends out pulses of voltage into the circuitry of the CPU, which, along with voltage on I/O circuits representing the bits of data to be processed, allows the computer to do its work. Each pulse allows one set of input bits to be processed into a set of output bits as the result of some operation. 
Instead, designers of modern CPUs have backed off the clock speed in favor of making a single clock pulse do more. More efficient "pipelines" to retrieve data needed for instructions, and now more cores built onto the same CPU chip (I believe the current gold standard for workstations is 8 cores), allow designers to multiply the work done by a single pulse and so continue to increase processing power in terms of instructions per second. However, this approach requires programmers to tap into the CPU's full potential by allowing their program to be executed by multiple cores simultaneously, and this "divide and conquer" design to the program can only take you so far in many cases. This is known as the "parallel problem", and is the Next Big Thing for CPU designers and language architects alike to solve.