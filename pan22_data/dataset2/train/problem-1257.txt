It is a very commonly used metric for identifying similar words. Nltk already has an implementation for the edit distance metric, which can be invoked in the following way:
The closest would be like Jan has mentioned inhis answer, the Levenstein's distance (also popularly called the edit distance).
The algorithm to compute these distances is not cheap however. If you need to do this on a big scale there are ways to use cosine similarity on bi-gram vectors that are a lot faster and easy to distribute if you need to find matches for a lot of words at once. They are however only an approximation to this distance.
However it feels a bit strange to apply something like Soundex to results from a speech-to-text recognition engine.  First you throw away information about how the words are pronounced, then you try to add it back again.  It would be better to combine these two phases.
If your dictionary is not too big a common approach is to take the Levenshtein distance, which basically counts how many changes you have to make to get from one word to another. Changes include changing a character, removing a character or adding a character. An example from Wikipedia:
Hence, I expect the state of the art technology in this area to do that, and be some form of adaptive classification, e.g. based on neural networks.  Google does return recent research on Speech Recognition with Neural Networks.
The idea is to compare not the words themselves but approximations of how they are pronounced.  To what extent this actually improves the quality of the results I don't know.