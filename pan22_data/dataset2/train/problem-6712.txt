I was having the exact same issue on my ext4 system and just wanted to post my solution for future reference.  When my drive initially filled out, I deleted a bunch of logs out of /var/log.  That cleared up a couple GB, but within a few days I ran out of space again, and du -h and "mount --bind / /mnt" did not point to the culprit.  What finally got it was when I ran lsof.
The lsof output can be a bit overwhelming, especially if you have a busy system (it was over 1000 lines long on mine).  If you grep for "deleted" in the lsof output, it should help to pinpoint the problem process.
you can check what is in the folder behind the mountpoint without having to unmount the disk/partitions (which can be nice if for example you would have to unmount /usr). Just do a
Make sure all folders "behind" your mountpoints are empty. Out of experience i'd say most probably you hide some data behind a mountpoint.
When I had deleted the messages log file, the rsyslog service still kept it open, but hidden.  Running a "touch /var/log/messages;service rsyslog restart" cleared up the problem and my disk space was reclaimed.
There could be a couple of problems: (1) a process has a large file or number of files open that have been deleted, or (2) you might have some type of filesystem problem remedied by an fsck of the drive.  However, this can only be done when the drive is not mounted.  Several Linux provide a method of FULL fsck of the root file at boot time by: