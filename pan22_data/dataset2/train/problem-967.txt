You'll need basic utilities, decisions regarding where things live in the system, a mechanism for installing and updating software, and conventions/standards (such as the directory where programs go) to tie this together.
Keep in mind that Linux is technically only the kernel, which is a single part of a working and useful system.  
This image is 100% accurate to my knowledge and is a timeline of all linux distributions and shows where they came from.  These days there are only a very small handful, less than six, distributions that can trace their roots back to the beginning.  According to this map there are only 2, Redhat and Debian, not even my beloved Slackware was an original.
One major thing that is usually distro-specific is the package manager or method which software is maintained, tested, and distributed.  Derived distributions usually are compatible with their "upstream" package managers.  Nothing is stopping you from manual program installation on any Linux distro, though.
Most of the GNU versions of classic utilities are often considered basic by many distros and thus is why Debian, for example, calls it GNU/Linux.  With just about everything else though, there are a lot of choices.  And since Linux, the GNU utilities, and many things that run under Linux are free software, anyone can create a new distribution anytime they want.  Including derive from an existing distro if that distro has not included anything copyrighted or proprietary.
When a distribution was typically created in the early days the kernel was bundled with the system level commands and a subset of user applications and server components.  This is still true today but many of the new distributions don't want to repeat the effort of getting everything to play nice together so they take a base distribution such as Debian, CentOS, Slackware and add or subtract user applications such as GNOME, KDE, LXDE, etc.  They may also write custom menus and inject their own logos and backgrounds into the distribution(SUSE, PCLinux, etc).  They may go farther and create distribution specific applications such as package managers or custom front-ends.
Linux is just the core part that gives you access to the computer's hardware.  Layered upon that is typically the GNU C Library, upon which is layered all the commands and software you're used to using (including whatever graphical user interface).
Expanding on the above answers.  Linux is just the kernel, most of the system level commands(gcc, grep, bison) were originally written by the GNU project, most of the user level applications(XFCE, Apache, XMMS) are written by third parties.
Typically this means that you'll install software the same way using the same package manager, and the locations of executables and configuration files will be in the same place.
So when you say for instance Ubuntu is based on Debian you are technically correct but these days it would be better to say, especially in the case of Ubuntu, that it is derived from Debian as changes to Debian may or may not find their way into Ubuntu.
Images and logos are frequently something that is trademarked/copyrighted and usually cannot be directly used in a derivative distro unless you obey terms and conditions of whoever owns that.  The same software usually can be if it's GPL or GPL-like licensed.
What happens in a world where the software is not locked down by some company, different groups put together a different sets of software all based on the two primary components: the Linux kernel and the GNU C Library.  Those two are pretty much found in every system.
This should help visualize what I am talking about a little, it shows how several established distributions have been forked into others.  While not 100% accurate it gives an idea.
Colloquially, we call all these operating systems "Linux" or "Linux-based" and they're all very similar due to an agreement upon various standards.