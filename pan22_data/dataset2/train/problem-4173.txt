By default K-Means assign a particular data point(or say sample) to that centroid which is having minimum Euclidean distance.
Just a general question that I'm trying to mentally visualize. I'm fairly new to using k-means clustering and have used it before on two variables, which creates a 2-D plot of points. I also know, although I haven't done it before, that you can plot a k-means cluster with three variables utilizing the x, y, and z axes. But now I'm currently in a position where I have four variables, normalized by their z-scores, in which I'm not sure how to use the k-means clustering appropriately. Should I be using a k-means cluster in this circumstance?
If you want to find the optimal number of centroids, the elbow method is still the best. You iterate the algorithm changing the value of k each time, and record how much error the clustering is producing; once you're done you plot the error levels against each k value and check the optimal k visually. There is plenty of tutorial on it, you can start here for example.
You can use k-Means clustering in all the dimensions you need. This technique is based on a k number of centroids that self-adjust to the data and "cluster" them. The k centroids can be defined in any number of dimensions.