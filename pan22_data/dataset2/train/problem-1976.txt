Honestly... there's several ways to attack this.  I have a few servers where I need to copy files that are in constant use... so I schedule a "maintenance window" of a few minutes where I can lock the files... create a snapshot (using dm-snapshot), bring the server back online and then do whatever with the snapshot'ed copy of the file.  This allows me to have a stable version of the file... and bring the service back online with minimal down-time.  Afterwards... I can remove the snapshot without affecting the live server.  In your case... you can copy the 6gb snapshot'd file at your own pace as-needed.... without worry about the live-version of the file messing up the copy process.
/dev/urandom is selected to avoid any boost from compression. SCP should tell you interactively what the speed is. Basic math should allow extrapolation of files sizes to 6 gig.
You can use the *nix utility "Pipe Viewer" to watch these processes. It will provide you with a progress bar and estimated time of transfer.
I have to copy a relatively big file (6GB) to another server. To enforce consistency, I have to 'lock' this file and not use it during the transfer. I obviously want to minimize this downtime, but before this, I also want to estimate the time it will take to do so.