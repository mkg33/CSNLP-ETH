If necessary (to appease the sysadmins) continue to run two servers at your primary data center, but do put at least one more outside.
I wanted to solve this as our Amazon EC2 resolving nameserver is unreachable for many of our workers. This causes big delays in our processes and even downtime in some cases because we rely on resolution. I wanted a good failover to Google / Level3 nameservers in case Amazon's went down again. And fall back ASAP, because then Amazon will resolve hostnames to local addresses where applicable, resolving in lower latency for instance to instance communication.
I take the maximum load from all my edge routers, add them all together, and then divide by 0.65...that is the minimum bandwidth that we must have at each datacenter. I put that rule into place about 5 years ago, with some documents to justify it I gathered from CCO and about the internet, and it has never failed us. However, you must check those stats at least quarterly. We had our traffic increase almost 3 fold between November and February last year and I was not prepared for it. That bright side is that the situation did allow me to generate some very clear hard data that says at 72% load on our WAN circuit, we start dropping packets. No additional justification has ever been required of me for more bandwidth.
If your primary datacenter is down, nobody will be able to reach those servers anyways, but often the errors from that are more intelligible than the errors from unreachable DNS servers.  "couldn't contact server" or "connection timed out" instead of "couldn't find server" or "no such server".  For instance, most SMTP servers will queue up mail for a week if they see the server in DNS but just can't reach it; if they can't find it in DNS at all they may immediately refuse to even try to deliver it to your domain.
As to the load conversation that KPWINC mentioned, that is 100% correct. If your smallest datacenter can't handle 100% of your load, then you are likely boned anyway because your outage is going to occur when you least want it =)
Yes, there's some chance that clients may experience very modest DNS resolution delays when there's an outage, but they'll only be a second or two, and once the client's own DNS servers have learned that one of the servers is down they'll use the remaining servers in preference to the failed one.
For authoritative DNS servers, the "clients" will be other DNS servers which have caching and plenty of intelligence.  They'll tend to try multiple servers at once if the first one is at all slow, and will tend to prefer the one that gives them faster replies.  Downtime for one data center in that case would have a very slight performance impact.
Unfortunately the Linux DNS resolver doesn't seem to have direct support for detecting and doing failovers for DNS servers. It keeps feeding requests to your primary resolving nameserver, waits for a configured timeout, attempts again, etc. 
As long as each of your datacenters is on different circuits (ideally with different upstream providers far up into the cloud), you can setup pretty reliable DNS with just the two datacenters. You simply need to make sure your registrar of choice populates the appropriate glue records to the big servers in the sky. 
For recursive DNS servers, the clients are your local clients that probably have the DNS servers listed in DHCP.  They'll try their servers in the listed order every time, with a painfully long (several seconds) timeout before moving from the first server to the second server.
There is a really great, albeit quite technical "Best Practices" document that may prove useful when combating your sysadmin.   http://www.cisco.com/web/about/security/intelligence/dns-bcp.html
Many other "Best Practices" document recommend separating your primary and secondary nameservers not only by IP block, but by physical location.  In fact, RFC 2182 recomends that secondary DNS services be geographically separated. For many companies, this means renting a server in another datacenter, or subscribing to a hosted DNS provider such as ZoneEdit or UltraDNS.
If he/she doesn't recognize the validity of articles written by Cisco, then you might as well stop arguing with the sysadmin - go up a level of management.
I realized from reading your description that it's not clear whether you mean authoritative DNS for outsiders to find your servers, or recursive DNS servers for your local clients.  The behavior of those two is very different.
Secondary DNS being geographically and network-separated is a good thing.  You might be able to trade secondary DNS with a friendly company, and there's plenty of DNS providers you can pay to do it for you.  Some registrars have secondary DNS as a service, too.
This setup has been effective enough to give us roughly 5 9's of uptime over the last 6 or 7 years, even with the occasional server downtime for updates, etc. If you're willing to spend a few additional dollars, you can look at outsourced hosting of the zone with someone like ultradns...
The recursive servers that query your authoritative servers will notice very rapidly if either site is unresponsive.
This often means up to 30s delays for any request. Without first trying the secondary as long as the primary is down.