This does not seem a Data Science problem. However there are very nice tools to do exactly that, checkout: logstash, flume and fluentd. Actually if you want to be able to filter in fast and "smart" way checkout Kibana from the guys of ElastichSearch (http://www.elasticsearch.org/overview/kibana). Those tools are enough to solve your problem in a very efficient way.
I was thinking about using string kernels, but it is intended for clustering ... and cluseting is not applicable here (I don't know the number of different types of messages and eventhough, it would be too much).
You can mark these nodes and for every new string parse/traverse the graph until you reach those areas.
P.S: For those who programs, this can be easier to understand. Let's say that the code contains as logs printf("blabla %s", "xxx") -> I would like to have "blabla" and "xxx" seperatated
The different log files have their own layout and own content; I successfully grouped them together, only one step remaining...
What I would like to do is to separate the indentification text from the value text (for example: "Loaded file XXX" becomes (identification: "Loaded file", value: "XXX")). Unfortunately, this example is simple, and in real world there are different layouts and sometimes multiple values.
Indeed, the log "messages" are the best information. I don't have the comprehensive list of all those messages, and it's a bad idea to hard code based on those because that list can change every day.