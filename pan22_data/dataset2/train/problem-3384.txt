 - If applicable you could have application servers in different countries, either talking to a database in Europe (possibly slower than you have now if it's db heavy) or synchronised databases in each country (more complex but faster). A master DB in Europe with a read replica in the USA may work.
I don't see how the proxy server will help, if all the pages have to be sent from Europe. It's just another hop with no benefits. You already have static resources on a CDN in the USA. If it's only one page hit of up to 180ms and all other resources are cached I think that's probably ok, it's if there's multiple hits on your server that it could be an issue - Ajax counts.
The WebApp server who send the dynamic content out are located in Switzerland, the average page size is around 14KB (3-5KB after GZip).
I have a set target for experience of under 1 second for my app to service a client. Whatever needs to happen to make that target is my job.
70% of the traffic is from North America. Our network latency time is between 105 - 185 ms to the USA (just-ping.com) mostly measured from data centers I think, means a home user will have higher latency. 
Would it be a good solution to place a proxy server on east and west coast of the USA in a data center with a good latency (100ms) to us and to serve the dynamic content from WebAPP server to our visitors from the USA from there? Means the proxy server will forward the request to us and send the answer back. 
If you have many cachable contents, it will be much better in terms of response time and bandwidth usage to use a proxy server between your web server and your clients.
IF 70% of the traffic is in US then it would make great sense to place the app server here. From that point using some HA delivery system would be advisable.
The proxy server will server the pages/objects very quickly without contacting the original servers while the cached objects are not expired. Moving the proxy server(s) closer to the client will improve the response time in most cases.