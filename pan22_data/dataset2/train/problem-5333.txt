Besides this, there are now two more functions, namely get_modes and get_mode_indexes. The first one will return you the list of modes (not metamodes!), i.e. all centers of all clusters in all data subsets (that were clustered individually).
I'm happy to hear that it runs without errors. Since the time when the question was asked I have fixed some more issues there and also wrote a paper about it, which can be used as a documentation for clarity (the paper is referenced on github).
the cluster_metamodes is an array containing resulting "modes of modes" or metamodes. In other words, this is an list with centers of the clusters. How to use it further depends solely on you. For example, you can calculate a distance from each record to all metamodes, using any of the distance functions provided:
The second one will return you a list with corresponding mode ID (which is globally unique) for each original record.
If you would have 100 records in your data and run pyspark-kmetamodes with 5 partitions, partition size 20 and n_modes = 2, it will result in: