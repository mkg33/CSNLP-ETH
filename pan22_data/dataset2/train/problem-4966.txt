Going off on a slight tangent for a minute ... on what would happen with this scenario is Sybase ASE ...
I'd want to go back and (re)investigate the root issue (recompilation locks on the child proc) and see if there's a way to reduce (eliminate?) said compilation locks. [Unfortunately my SQL Server knowledge on these issues is ... NULL ... so would be interested in input from some SQL Server compiler experts.]
SQL Server does indeed use row locking, but it also uses page locking, and table locking.  Of course, you might be able to mitigate that via good indexing, but this still looks like an anti-pattern to me.  
As for the idea of using a single permanent table with @@SPID to differentiate rows between sessions ... been there, seen that ... yuck; recurring issues:
Session ID's are reused frequently; as soon as a user connection logs out, that session ID is available to be used again, and is likely to be used by the next session attempting to connect.
A bit more rambling than can fit in a comment block ... and want to highlight a comment the OP made in response to Ray's answer:
If the stored procedure is the only method used to access the affected tables, you could investigate using an application lock, via sp_getapplock to essentially serialize access to the relevant parts.  Docs for sp_getapplock are here.  Erik Darling has an interesting post about it here.
I would require the vendor to explain why the system experienced "heavy compile locks" and how that degraded performance.  Remember, anytime you look you will find "heavy locks" of some sort.  That does not necessarily mean the locks are a problem.
Yes, I do see risks.  It is naive to count on SQL using Row Locking.  For example, I'm pretty sure inserts and deletes will use page locks at least.  SQL Engine chooses the lock type based on several factors and none of those factors include "their opinion".
Additionally, the transaction model and error processing could be big issues.  If your system experiences deadlocks or input data quality issues then the standard error processing can result in the session being terminated without the qryTransactions table being properly reset.
To make it work at least semi-reliably, you'd need a login trigger that purges prior rows from the table with the same @@SPID.  If you do that, you're likely to see a lot of locking on the table using the @@SPID column.
Table Variables are very useful in some situations but they do have limitations and performance issues.  I prefer temp tables in most circumstances. Particularly when the table will hold more than a few dozen rows.