Rendering it with some depth of field at 512x512, you'd think the reflection in the sphere is perfectly sharp:
And we can see the exact same blur on the checker pattern. It's as simple as that: you don't see the blur because it's too small.
Now, we don't have such a camera, but we have something even better: software! So I built this simple setup with two perfectly sharp checkered planes, a sphere and a camera with some depth of field:
There's no visible blur for the same reason you often don't see blur in very wide angle lenses: the circle of confusion is much smaller than a pixel. But it is still there. An extreme example of this is fisheye lenses.
A question has come up recently in Blender SE, remarking on the absence of blur due to depth of field in reflections in a spherical surface. This is a real-life effect.. can anyone come up with a nice explanation of it?
Because the ball doesn't "see" the world through an imperfect lens system, whereas your camera in that case does. If you were to introduce an imperfect visual system around it, with a resulting blurring point spread function, you will get a blurry reflection.
If you had a camera with infinite resolution, such that you could zoom into the reflection on the ball, you would eventually see the blur. And it would be exactly the same blur as if you had aimed a flat mirror at the part of the scene you're looking at through the ball.