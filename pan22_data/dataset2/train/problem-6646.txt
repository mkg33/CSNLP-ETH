First and foremost, you get repeatability.  You can create a Dockerfile, debug in a container on your developer machine, run tests on a continuous integration server, and then in your final product, and you know it will behave the same in all those environments.  No forgetting a dependency that a developer had installed on their machine.  Also, your developers don't have to use Ubuntu at their desk.  Important to keep us Arch Linux users happy :-)
If you use a microservices model, Docker also provides sandboxes that can limit the amount of damage attackers can do in the event of an exploit.  Instead of gaining control over an entire machine, they are only gaining control over one container.
The main downside is you need the host OS and some sort of orchestration.  There are lots of choices for that, but don't underestimate the amount of work it takes to evaluate one, put it in place, and maintain it.
I've worked with Docker a long time.  The platform independence is nice, but it's not what I consider most useful about Docker.
Second, for your upgrade scenario, you can have multiple versions pulled to a machine at once.  If you do a docker pull myapp:2.0 while 1.0 is running, you can swap to 2.0 extremely quickly.  Much faster than doing a full OS upgrade would normally take.  If you use an orchestrator with multiple instances of microservices, you can even do rolling upgrades that don't interrupt service at all.