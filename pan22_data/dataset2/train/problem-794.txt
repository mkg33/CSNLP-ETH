To reach the servers over the internet, I plan to use a site to site VPN.  (This part is only relevant as far as hardware selection goes).
If you need to actually route 200mbps of traffic, then you're going to need a 3560 or something to route between the segments of the other cross connects landing in your cage vs the servers in your cage.
I am certainly not married to either of these configs, and I am totally open to any ideas.  My knowledge (and I use the term loosely) is largely from books so I welcome any advice / insight.
The first is a fairly traditional setup but my concern is performance. The second is somewhat unorthodox in that the vendors are directly connected to the layer 3 switch without passing through a firewall.  Based on my understanding however, a layer 3 switch will perform substantially better as it will do hardware (ASIC) vs. software switching.  (Note that number 2 is a little over the budget, but not unworkable (double negative, ugh))
A little more detail - the networks the servers need to reach are inside of the data center, and are "trusted".  Connections to these networks will be achieved through intra data center cross connects.  It is kind of like a manufacturing line where we receive data from one vendor (burst-able up to 200 Mbits), churn through it on the servers, and then send out data to another vendor (bursts up to 20 Mbits).  This series of events is very latency sensitive, so much so that it is common practice not to use NAT or a firewall on these segments (or so I hear).
Since this is my first time dealing with a data center, I am not sure what the IP space is going to look like.  I suspect I will retain a block(s) of public IPs, vlan them to individual interfaces for the vendor connections and the servers (which will not reachable from the wan side of course) and setup routing on the switch.  
3) None at all - routers and switches (plain ones, not new-fangled 'security' or 'enhanced' ones) don't care about public vs private IPs.
I have been tasked with setting up a fairly straightforward rack in a data center (we do not even need a whole rack, but this is the smallest allotment available).  In a nutshell, 4 to 6 servers need to be able to reach 2 (maybe 3) vendors.  The servers needs to be reachable over the internet.
2) As long as you're not pushing the limits of the forwarding performance of the router,  you're talking really <1 ms
The general idea is that the ASA acts as a firewall and VPN device and the 3560 does all the heavy lifting.
The term "layer 3 switch" is really just a router that happens to be optimized for LAN networks - it doesn't mean anything these days.