You can configure your DNS entries for the website using DNS Round Robin to point to multiple host IPs. Raise a seperate elastic IP for each front-end instance. On the DNS side, it's just a case of adding a second entry for the same hostname, with the alternative IP. Set the TTL on each entry quite low (5-60 seconds).
However, EC2 instances aren't durable and you shouldn't treat them as such.  Meaning, that they can up and disappear like a fart in the wind and your application has to be tolerant of that.  RR DNS could be a source of pain for you because its not smart enough to deal with fault-tolerance/high-availability.  If one of your web servers were to die, the user would be stuck trying to connect to the dead machine until the TTL lapsed on the record.  The previously mentioned trick of setting a ridiculously low TTL won't work.  Downstream caching DNS servers won't honor a TTL that low.  You'd be lucky to get away with a TTL of one hour.  Many users might be stuck trying to connect to the same dead web server for 24 hours or longer.
I'd recommend that you look into HAProxy. Reddit.com uses HAproxy on EC2 to load-balance about 200 million pageviews/mo. across several dozen web server instances.  I'm sure it'll handle your app as well.
You can use your EIP with the elastic load balancing as April has mentioned; however, when I was evaluating this it had some deficiencies that made it less than ideal for my deployment.
The Apache2 configuration makes use of mod_balancer to balance the requests amongst the backend server instances, which is never less than 3 instances. The database runs on it's own separate EC2 instance that the backend systems can connect to.
You could replace the Apache2 configuration on my front-end systems with HAProxy. I did look at that but needed to do much more intelligent routing than I thought practical with HAProxy, but someday I may go back and re-evaluate that position.
In this configuration I'm handling over a half dozen heavily hit sites that count their hits in the tens of millions per month. The threaded front-end Apache2 servers show almost no load as they merely act as the go-between while the real work is done on the backend servers. I've noticed considerable speed performance increase from when we were running on traditional dedicated servers in co-located datacenters.
You can use round-robin DNS, as previously mentioned.  And if you're looking for a quick and easy solution, that's probably what I'd recommend as well.  
I have 2 Elastic IPs that are assigned to a couple of EC2 instances that serve as my front-end web servers. This are simply running threaded Apache2 servers which handle the load balancing to my application servers behind them. These two EIPs are then put in standard DNS round-robin.
I have a web app that lives on two AWS instances - one instance hosts the site, and the other hosts the actual database (MySQL). The instance hosting the site has an elastic IP pointing to it, which is tied to my domain name.
Obviously, one of the major benefits of AWS is being able to run a bunch of instances at once when things get busy, and AWS even offers automated solutions to do that. Great. But if I have my domain pointing at one IP, and that IP tied to one instance, how do I spread out the traffic among many instances? Do I have the primary machine act as a load balancer? If so, is there a commonly used load balancing solution for use with LAMP?