This behaviour depends on your browser. If you use Chrome, for example, you might find the Timing graph shows the same behaviour, but that things are 'stalled' for a while; this is likely due to [Chrome's] limit of 6 concurrent connections per origin.
It is common to use a content server to serve up static content.  This can set appropriate caching headers so that the browser can cache the content.  This reduces rendering time on subsequent page loads.  Some sites will set very long expiry times and use new file names for updated content.
Time the request spent waiting before it could be sent. This time is inclusive of any time spent in proxy negotiation. Additionally, this time will include when the browser is waiting for an already established connection to become available for re-use, obeying Chrome's maximum six TCP connection per origin rule.
While this does not help with initial load times, it should increase subsequent load times.  It also reduces load on your server which will help on that end as well.
While there is relatively little you can do to reliably increase load time, it is possible to improve rendering times.  (There are good reasons that browsers limit the number of connections they open.)   Including sizing data for graphical elements allows the page to render before the graphic has been down loaded.  Loading script components not required for rendering asynchronously can also help.
What you're asking is HTTP/2 behavior where operations are asynchronous and there's real multiplexing going on.
This can depend on KeepAlive settings. If set - server will attempt to use as few connections as possible (on concert with browser). However while doing so communication becomes "synchronous" so there's a "I ask for A and won't be asking for B until A is here". Also Server should be sending items in the order requests been received and not in the order it was able to process those requests. This is a limitation of HTTP/1.1 