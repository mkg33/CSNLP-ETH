It's funny, if you type a Google search for "why doesn't SQL Server" the most common auto-completion is "release memory."
What you seem to expect is more flexible behavior, where you can have free memory part of the time. For what purpose? Is this like shrinking a database file to free up disk space that you can't use for other purposes because the database file is going to grow again?
If you want to do this manually, then you should set a lower limit on SQL Server's max server memory setting, and restart the service. Now SQL Server won't use 28GB even if it needs it. But this seems to be artificially limiting SQL Server. 
If you really want the OS to take the memory back from SQL Server, take a big 20 GB file and copy it over the network. SQL Server will release the memory as the OS needs it. But I would watch a variety of performance counters while this is going on, and see how the performance of your BULK INSERT changes if you run it again either while the copy is going on or immediately after.