... However, when it comes to more modern programs (or ones without an installer) that have a lot of additional files, I like to place them in their own directory within /bin.
While the Filesystem Hierarchy Standard does provide some guidance. I've found that most distributions like to install packages into /usr/share. 
Because of this, I've adopted the practice of installing any application not installed via package manager (rpm / apt-get / emerge) in /usr/local. This allows me to keep applications and libraries that aren't managed via package management separate from those that are.  
Agreeing with James Polley's answer, but in fact the default directory makes a lot of sense unless you need to share the application between multiple accounts.  I, for instance, needed to install Eclipse 3.0 (obsolete) in order to do Flex work under Linux, and I put it in $HOME/eclipse3.
I would have thought that the default location is /bin, it is where pretty much everything gets installed by default if using apt-get or similar...
I come from a Windows and .net background.  One of the promises of .net was that most apps could be installed by using Windows xcopy.  I look for the same thing in Linux.  Where available, I choose the tarball over the RPM or yum, etc. so I can deploy to /apps with cp -r and add the app to my nfs server for future deployments.
I like to use /apps for most add-on apps that I install on multiple servers.  I keep a copy of the folder in /installs/apps on my nfs server.  When I create any new linux server I mount the installs folder and copy /apps and I have many different common apps on the new server.  I delete those entries I don't need for this new server and I'm done.  Well, maybe I need to run a script or three for setting environment variables or path statements but that's pretty much what it takes to set up many new servers.