Multiple DNS records for the name name should round-robin balance across them. But the clients do what they want with this, and so there is little control about which they pick or how long the result is cached.
A manual active passive doesn't do any automatic decisions on where things go. Update DNS to point to your secondary system, that's about it. 
There probably are relatively fragile single points of failure behind the load balancers to worry about first. Try to get things such that you can unplug any power, network, or storage cable without major service disruption. Or destroy any single VM, if cloud is your thing.
To split the traffic between two load balancers, doesn't there have to be a third load balancer to peform the splitting? Wouldn't this counter the idea of having two load balancers to prevent a single point of failure?
Anycast traffic will go to the closet by network routing. Which may be between just two sites advertising the IP, or dozens if you are a big CDN.  All you need is IP routing, not any one device. (Assuming your IP network is free from SPOFs!) But you don't control where each request goes on the Internet, so best suited for stateless protocols like DNS.
Enterprisy global site load balancing products claim you can put one application delivery controller in one data center, and a second in another, and balance across both. A third is more like another node in a cluster, than a separate load balancer device chained in front of yet more load balancers.