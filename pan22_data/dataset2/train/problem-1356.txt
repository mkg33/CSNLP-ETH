We run multiple server instances of the above, with an actual hardware load balancer in front that talks to all the httpds.  To deal with the single point of failure that the hardware load balancer is, we replicate this entire setup at a different datacenter, then use DNS games to load balance people geographically using Dynect (which also has the ability to shift load over to the other datacenter during failure).
on a single server, run one httpd and two instances of the tomcat on different ports.  We use mod_jk to talk to the tomcats over ajp and configure mod_jk to load balance between the two (or in some cases, an active/passive failover and let mod_jk figure out when to failover).
In your setup, you're handling the case of a single tomcat server dying, but not the front end  httpd.  You might be better building a pair of front end httpd servers that use heartbeat/corosync/pacemaker to handle front-end failover.  It won't be "instant failover", but it'll be close to it.  Most people can tolerate a few seconds as things switch around.
Part of the reason we run two instances of tomcat on each server is so that we can more easily apply software updates to an application without affecting our ability to handle peak load.  Yes, this makes us have 2x the RAM requirement, but that's much cheaper than having to double the number of systems to operate the way we operate.