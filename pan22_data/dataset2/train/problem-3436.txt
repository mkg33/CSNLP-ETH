More precisely, you apply each one of the 512 dense neurons to each of the 32x32 positions, using the 3 colour values at each position as input. That's why you have 512*3 (weights) + 512 (biases) = 2048 parameters.
What you can do instead, if you are trying to compare the performance of a network with out convolutions to one with convolutions, is flatten the images: https://keras.io/layers/core/#flatten 
It was written before Keras (or Tensor-flow, MXNet, anything) so it does not have Keras examples. But, between the Keras documentation, this book, and this forum, you should be able to grasp Deep Learning.
When I studied DNNs in school, we used this online textbook: http://neuralnetworksanddeeplearning.com/chap1.html
Right. What are the attributes of your input layer? Unless I am mistaken, you have not flattened your image at all. So you have sent a 32 x 32 image directly to a dense layer, and not a convolutional layer. (As a side note, it could be that you are following a very bad tutorial, as this is not what good tutorials do). 
As a consequence, for each neuron in each position you generate an output, and that's why you have 512 outputs for each position, i.e., 32x32x512.