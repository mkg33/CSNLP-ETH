So, after you have instantiated it, just .transform each your upcoming mail_id and use results in upstream applications ( like online learning, for instance ).
Also take a look at this: http://www.win-vector.com/blog/2012/07/modeling-trick-impact-coding-of-categorical-variables-with-many-levels/
The better would be to take logs, where your ids coappear, and learn item2vec style model ( https://arxiv.org/pdf/1603.04259v2.pdf ). This will deliver much denser ( and meaningful ) representation of mail_ids than FeatureHasher would do.
After doing a lot of analysis on my data I have found that I cannot drop this feature set from my model so I have to convert it to something meaningful. Can anyone please explain me how to do this efficiently? Thanks in advance.
  Obviously n_features is some knob to tune. But this has its flip side: the cardinality of mail ids is apriori high, so unless you have very limited amount of users you will need enormous n_features to minimize collisions.
I have a huge data set with one of the columns named 'mail_id'. The mail_id is given in a very creepy format as shown below: