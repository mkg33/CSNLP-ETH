I keep everything related to managing systems in a software control repository. Here's my typical workflow when updating configuration on one or more systems. I start from my local workstation.
Its a fancy wrapper to rsync and and shell scripts.  This has very little upfront learning and works well however as you grow it can get a little cludgy.
If your really want to have GUI - that we usually don't have on servers - you have to install the X environment and the connect to it with VNC. In such cases we connect to the VNC server thru an ssh tunnel that adds more security to it.
All of our software is deployed via RPM. Each EC2 instance type is described by a kickstart file (which lists the RPMs to be installed...). The kickstart setup means a working machine of each instance type can be built from scratch in about 10 minutes.
You may also consider using Midnight Commander (mc) on the ssh console that can speed up file operations. To install use the yum install mc or apt-get install mc command. Afterwards you can start it by typing mc on the terminal. It also has a built in viewer and editor that's more straightforward than vim.
We then have a program that invokes anaconda (the Red Hat installer) to take a kickstart file, install the system into a directory, then bundle up the directory and push it to S3 as an Amazon Machine Image. This is all one step, so I just type:
Since a machine can be completely rebuilt, uploaded and running in about 40 minutes, it's easier to build new machine images than perform sysadmin on the actual (throwaway) EC2 instances. Therefore, no sysadmin is actually performed on EC2 instances.
When all else fails, I log into systems with SSH. I did manual system administration for many many years, this is old hat.
For packages native to the platform, I use the standard package management tool like APT or YUM. For source installs (something.tar.gz) I generally download via wget.
You could try something like capistrano but if that's not quite enough for what your after then it sounds like you are a candidate for some sort of configuration management.
I do a lot of work in EC2, primarily testing environments and changes. As a result of my tools and workflow, I spend more time working on things I actually care about and less on dealing with individual files and thinking about specific configurations.
I don't do much manual system administration anymore. I view my infrastructure as a programmable entity, and treat it as such, by configuring systems with tools that automate configuration management, EC2 node maintenance, etc. Tools in my toolbox:
Use WinSCP client to connect via sftp, that you can also use to edit the files on you windows machine (by double clicking on them) as if it was on your local machine. You can also use it to copy/move files around remotely.
Puppet, reductivelabs.com/products/puppet/ ,is a real stand out in this field but may be a little overkill for you unless you have plans of becoming bigger and then its worth the hard work up front.
If you are using ubuntu: we are considering using landscape for this, its a commercial product by the ubuntu (canonical) team and will be intergrated with ec2 commands.
I do bundle up an AMI when I've got a node built the way I need for a specific function. For example, if I'm building a Rails app server, I'll get all the prerequisite packages installed to save time on build.