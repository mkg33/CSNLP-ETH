At the end you get a picture preserving the similarity of the original data with some degree of precision. Not more, but not less.
From the arts, look at Marshal Ney at Retreat in Russia. This massive oversimplification of the Napoleonic wars nevertheless conveys great meaning and allows people with even the most ignorant knowledge of the war to understand the brutality, the climate, the landscape, the death, and decorum that permeated the invasion of Russia.
Similarly, t-SNE projects your data down to a space, where items are near each other if they minimize some KL divergence. This isn't the original feature space anymore. (Correct me if I'm wrong, but I don't even think there is a large effort by the ML community to use t-SNE to aid classification; that's a different problem than data visualization though.)
But is this "pretty picture" actually meaningful? What possible insights can someone grab by trying to visualize this embedded space?
Observing (2D) pictures of our world (3D) is a usual practice. A visualization method provides only different “glasses” to see a high dimensional space.
Taking a slightly different approach than the other great answers here, the "pretty picture" is worth a thousand words. Ultimately, you will need to convey your findings to someone who is not as statistically literate, or who simply does not have the time, interest, or whatever, to grasp the full situation. That doesn't mean we cannot help the person to understand, at least a general concept or a piece of the reality. This is what books like Freakonomics do - there's little to no math, no data sets, and yet the findings are still presented.
I ask because the projection down to this embedded space is usually meaningless. For example, if you project your data down to principal components generated by PCA, those principal components (eiganvectors) don't correspond to features in the dataset; they're their own feature space. 
There are many techniques for visualizing high dimension datasets, such as T-SNE, isomap, PCA, supervised PCA, etc. And we go through the motions of projecting the data down to a 2D or 3D space, so we have a "pretty pictures". Some of these embedding (manifold learning) methods are described here.
Based on the statements and the discussions, I think there is an important point to distinct. A transformation to a lower dimensional space may reduce the information, which is something different from making the information meaningless. Let me use a following analogy:
Ultimately the charts are simply communication, and for better or worse, human communication is often times focused on conflation, simplification, and brevity.
A good thing to “trust” a visualization method is to understand the internals. My favourite example is the MDS  . It is easy possible to implement this method at your own using some optimization tool (e.g. R optim). So you can see how the method words, you may measure the error of the result etc.
Here is the basic idea. The authors apply PCA to many spectra (e.g., 10,000) from a telescope. Each spectrum has ~1000 attributes. Since this data set has large dimensions, it's difficult to visualize it. However, the first 4 components from PCA reveal much physics about the spectra (see sections 4.1-4.4 in the paper above). 
There is at least one example in astrophysics where you project your data down to principal components generated by PCA and those principal components correspond to much physical insight about the galaxies. For detail, see the last figure in http://www.astroml.org/sklearn_tutorial/dimensionality_reduction.html#id2 