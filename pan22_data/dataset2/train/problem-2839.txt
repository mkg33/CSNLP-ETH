So you end up with an array of EntityID indexed based index.  So when you want to lookup an entity, you simply go to that index, compare the version values between the stored reference and the value in the array and if they match, the index is still valid.  If they differ, the reference is stale and you can thus assume that entity has since been destroyed and react accordingly.
The benefit here is during processing of components, I can simply iterate the second array and avoid any lookup performance bottlenecks.  Worse case scenario, I take several constant time lookup hits when I fetch a component by entity id which seems reasonable.
My personal choice is to use this approach mainly for cataloging entity ids and validating whether they're still valid at runtime and then store the components in their own separate pools per type. 
For this to work, my component pool relies on two arrays to manage its memory.  The first array is a simple sparsely populating array where the index from the entity ID holds the offset index in the second array that is maintained as a densely populated array of component types.
I would recommend you to always assign a fresh ID to a new entity. Very strange bugs can happen if you try to refer to an entity by ID, but that entity got destroyed and replaced by something completely different in the meantime. 
I would suggest however to make the queue use a first-in, first-out strategy.  This avoids the concern with version numbers being incremented too high for a single slot, except in situations where you create and destroy a single entity repeatedly in a row.
In this use case, you can have approximately 16.7 million different entities in your pool.  Each entity will be assigned 255 different version values before they roll over, skipping 0 as a sentinel value.
The other benefit is that now your entityIdArray is also a sparse array but contiguous.  The lookup is constant time either way, so that should not impact performance, if at all. 
If you want to use object pooling (which usually makes most sense for objects with a large memory footprint and little dynamic allocation), keep separate indexes which are only relevant for the pool itself. 
Rather than treat your Entity's ID as a single 32-bit value, split that value into two parts, one which represents the index slot in your array and another that represents an ever increasing, potentially rolling over version value.
Note I use a hash table to keep track of all "destroyed" ID so I can use it again. This way, all the entity index will be as continuous as possible, so I can store components in a pool and refer them through index without wasting much memory. Another choice I can think is at component pools create a separated "index" array to keep track of entity and store all entity continuous. Which why do you prefer? Or do you have a better solution to this problem?