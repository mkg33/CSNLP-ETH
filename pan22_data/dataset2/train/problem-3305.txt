But if that is what's happened then surely there should be a red indicator light telling me to change one of the drives, and there isn't.
As for the lack of a red light...  Again you are assuming the enclosure is working properly. It could be a hardware fault, or the LED doesn't work. Have you tried inserting a new disk and rebuilding the array?
Of course, you can always contact ICYDOCK for support. They should be able to help you, or give you some advice. 
A colleague has an ICYRaid MB662U3-2S (https://www.icydock.com/goods.php?id=160) configured in RAID-1 with two WD40EFRX drives. It was set up nearly four years ago, and last Friday it became inaccessible.  He says it is the first time this has happened. There were no red indicator lights lit on the enclosure. He brought it to the office and I removed each drive individually (with the power off), put them in a simple USB dock, and Windows showed the sole partition as RAW on both. I ran the short self-test from GSmartControl, and they both passed. However, both disks do have a single error logged: the left disk at 8558 hours, and the right disk at 31226 hours. The short self-test is timestamped 8471 hours on the left disk (seems very odd for this to be less than the 8558 of the error) and 33527 hours on the right disk.
The only other potentially relevant fact is that the failure coincided with the update to Windows 10 1903. I'm hesitant to mention this because I don't see how it could be related, but then the whole reason for asking here is because there is plenty I don't know ;-)
While I am not familiar with this model, low end RAID enclosures are notorious for failures. They are cheap, as they are built on a budget. I would not trust them with important data. 
Anyway, I'd like to know if there's anything I can do to recover the data, or if the disks will have to go off to a specialist. And then, out of interest, how could this have happened? According the user manual (https://www.icydock.com/Installation%20Guide/mb662u3-2s_manual.pdf)