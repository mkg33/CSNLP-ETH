Also, your internet connection as a whole might be adversely affected, because you'll be transferring much more data total.  Your torrenting, downloading, updating, etc. might be affected.
Proxy pipelining is a little bit different, but it's basically the same issue.  You'll place more strain on the proxy (bad if it's a public proxying service, ok if the proxy is your personal computer or only servicing a small number of people anyway).
Take a look at this article by Asa Dotzler (a Mozilla dev). The downside to this is that not all websites will display correctly, and that while you see some content much faster than you normally would, overall the page takes longer to display.
I personally have been using the FireFox extension FasterFox and it has made a marked improvement in my browser experience.  I'm not 100% sure what all it changes, but it is a very easy process since it is a simple add-on.
The downside to pipelining is that is puts additional strain on the webserver you're requesting pages from. Just one person doing this isn't a big problem, but lots of people use this tweak. This is definitely a large contributor to the "Slashdot effect" where a smaller site will crash upon being linked to by a very popular site (like Slashdot, Digg, Reddit, etc etc). A ton of people are directed to that site, and if even 25% of them are pipelining than the server strain starts to increase almost exponentially.
A long time ago, I also found on another site a note which mentioned that changing the network settings also makes more requests than normal to the web server, and has led to websites banning people who use this hack because of the strain it puts on their servers.
If you really need the speed boost then you can probably set your pipelining values to something like 2 or 3, but really you don't need pipelining on at all.  Those extra requests are wasted data in the end (server-side), because it will end up sending you multiple copies of your data.
Also, the numbers in those instructions are too high. Firefox caps the number of simultaneous HTTP requests anyway. I recall reading that the maximum was something like 8 or 16, but I could be wrong.  
Basically, when you set your pipelining data (non-proxy) to something like 50 (which is overkill), you are using the server-side connection speed of 50 different people.  There's no downside for you, but the places you are going to will suffer.
The main problem here is pipelining.  (That nglayout.initialpaint.delay is how fast Firefox displays data it has already received.)
It's probably overkill, but a friend of mine copies his ~/.mozilla to a tmpfs, runs Firefox on that directory, and copies it back every couple minutes in case the kernel panics.