Backup Exec have quite the hefty system requirements for running deduplication, you should be aware of this. If I recall correctly it's 1GB of RAM per 1TB of data in the backup cycle.
The normal setup for using B2D against deduplicated storage systems (or BE's deduplication engine) is to run 1 full backup, and then "incremental forever". This is the preffered method to utilize the deduplication to it's full potential, but it might not suit every datacenter out there.
You should notice the deduplication effect after the full backup has run with the option enabled. This will basicaly be your "base" data as described above, where every incremental backup will deduplicate against the full backup.
I don't see any need to use the existing B2D files. Why not just point your next full backup against a folder on the B2D storage called "dedupe" or something like that?
Deduplication comes in many flavours. I can't remember right now wich one BE uses, but they all create checksums of data blocks and then compare it to a database to see if it's already been stored somewhere else.