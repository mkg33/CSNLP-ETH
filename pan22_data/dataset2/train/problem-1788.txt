But having "half" your users wait 30 seconds is unacceptable, so you will probably want to update your TTL records to be a few minutes, not a few days or weeks so that in case of an outage, you can rapidly remove the down server from your DNS.  Others have alluded to this in their responses.
By design, when you answer a DNS request you also provide a Time To Live (TTL) for the response you hand out. In other words, you're telling other DNS servers and caches "you may store this answer and use it for x minutes before checking back with me". The drawbacks come from this:
I would recommend that you either A, select a datacenter that is multihomed on its own AS, or B, host your name servers in a public cloud. It is REALLY unlikely that EC2, or HP, or IBM will go down. Just a thought. While DNS works as a fix, it is a simply just a fix to a poor design in the network foundation in this case. 
A very small minority of web sites use multi-datacenter setups, with 'geo-balancing' between datacenters.
Another option, depending on your environment, is to use a combination with IPSLA, PBR and FHRP to accomplish your redundancy needs. 
By 'DNS failover' I take it you mean DNS Round Robin combined with some monitoring, i.e. publishing multiple IP addresses for a DNS hostname, and removing a dead address when monitoring detects that a server is down. This can be workable for small, less trafficked websites.
2) If one of your nameservers (or one of your two geographies entirely) goes down which is serving your round-robin domain, and if the primary one of them goes down, I vaguely recall you can run into other issues trying to remove that downed nameserver from DNS if you have not set your SOA TTL/expiration for the nameserver to a sufficiently low value also.  I could have the technical details wrong here, but there is more than just one TTL setting that you need to get right to really defend against single points of failure.
3) If you publish web APIs, REST services, etc, those are typically not called by browsers, and thus in my opinion DNS failover starts to show real flaws.  This may be why some say, as you put it "it is not recommended".  Here's why I say that.  First, the apps that consume those URLs typically are not browsers, so they lack the 30-second failover properties/logic of common browsers.  Second, whether or not the second DNS entry is called or even DNS is re-polled depends very much on the low-level programming details of networking libraries in the programming languages used by these API/REST clients, plus exactly how they are called by the API/REST client app.  (Under they covers, does the library call get_addr, and when?  If sockets hang or close, does the app re-open new sockets? Is there some sort of timeout logic? etc etc)
The alternative is a BGP based failover system.  It's not simple to set up, but it should be bullet proof.  Set up site A in one location, site B in a second all with local IP addresses, then get a class C or other block of ip's that are portable and set up redirection from the portable IP's to the local IP's.
1) Browsers will failover from a non-working IP to a working IP after 30 seconds (last time I checked) if both are considered active in whatever cached DNS is available to your clients. This is basically a good thing.  
I ran DNS RR failover on a production moderate-trafficked but business-critical website (across two geographies) for many years.