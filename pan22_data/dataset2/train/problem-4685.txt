No. Besides using double disc scpace, you also use couble memory if you access identical data from 2 copies of a table. And as memory is what is the most efficient buffer, you at least theoretically reduce system effectiveness. Theoeretically because a proper server may just not care - if you have half a terabyte ram and the duplicate table is 100kb then all impact is purely theoretical.
I am thinking about 2 possibilities that I want to use in my project. So there are 2 projects, with different databases each. So Project P1, has Database D1, and Table T1. Project P2, has Database D2.
To add a bit to TomTom's comment: The optimizer has full access to meta-data etc regardless of whether the data is in one database or several databases. And the optimizer or execution engine is on constrained to one database. As long at it is in the same instance! If you talk about cross-instance queries (using linked servers, for instance), then you will definitely hurt!
For Project P2, I need to select the data at Table T1 quite often. Is it better to create a replicate of T1 inside Database D2 (name it T2), and do SELECT * from T2 instead of doing SELECT * FROM [D1].[T1] ?