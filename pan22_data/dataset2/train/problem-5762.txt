Suppose I have classifiers C_1 ... C_n that are disjoint in the sense that no two will return true on the same input (e.g. the nodes in a decision tree).  I want to build a new classifier that is the union of some subset of these (e.g. I want to decide on which leaves of a decision tree to give a positive classification).  Of course, in doing so there will be a trade off between sensitivity and positive predictive value.  So I would like to see a ROC curve.  In principle I could do this by enumerating all subsets of the classifiers and computing the resulting sensitivity and PPV.  However, this is prohibitively expensive if n is more than 30 or so.  On the other hand, there are almost certainly some combinations that are not Pareto optimal, so there might be some branch and bound strategy, or something, that avoids most of the computation in many cases.
I would like advice about whether this approach is likely to be fruitful and whether there is any work or if you have any ideas about efficiently computing the ROC curve in the situation above.