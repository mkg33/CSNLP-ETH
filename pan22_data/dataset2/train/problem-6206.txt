You could replace the echo with an ssh command into root to start the service, but that seems a bit risky. It may have security implications. It may not be reliable. I would suggest that you should probably have some kind of proper cluster/failover software to do this. There is MySQL MMM, which we used to use some, but I understand that has gone out of favor.
Assuming you will have sshkey auth for password less login for root user to the remote machine, you can run the following command -
But leaving aside the legitimacy of the question, using mysql or mysqladmin to monitor the state of the service entails exposing the credentials to connect to the database - which is not a very good idea from a security viewpoint. It also creates complications around resource management (when you get to max connections, it may look like your service is down)
You could modify that config to set a primary and a backup instead of having them both be backup (in the event that you'd want automated failback once the primary node recovered).
ssh remotemysql "if [ 'ps -efww | grep mysql| grep -v grep' ]; then echo "server is up" ; else echo "server is down"; fi"
The cronjob will be checking the remote server for a live (or not) mysql every minute. I can write the cron job myself, but i need help with the shell script that checks if a remote mysql is up or down. The response after a check if up or down is not important. But the check is important.
I want a bash shell script that i can run using a cron job to check if mysql on a remote server is running. If it is, then do nothing, other start the server. 
As @khaled said in the comment thread of your question, it'd be much more reliable to implement keepalived. It's not nearly as scary as you may think it is. keepalived will manage the floating IP, and you tell it to run a script in the event of a failover. Here's an article specifically on how to configure keepalived with mysql:
This fills me with trepidation. I can't imagine why anyone would think this is a good way to manage a service. Mysql ships with startup scripts which will integrate with systemd and sysvinit which are the standard ways to start up a service in a Linux/Unix system. Systemd has built in capability to restart a failed service - but I have never seen a default config exercising this option for very obvious reasons, and if there were a good reason for doing so, it could be invoked with a respawn from the inittab on a sysV system. If this relates to running a per-user instance of the DBMS (in the way Kmail does) then the triggerring should be controlled by the user session, not by cron.