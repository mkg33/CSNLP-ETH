If you want to stick to NN, I'd say a regular multilayer perceptron might do the job. If you are open to other options, I would try decision trees for this particular problem.
Also, make sure that you have a reasonable amount of data before using a deep learning approach. They usually have many parameters to train, and if you don't have enough data points, this might be difficult to do.
You could use one-hot encoding. There are plenty of implementations out there (i.e. scikit-learn), or you could do it yourself. 
I have the following dataset that I was thinking of using RNN/LSTM for classifying the protocol. Data contains features from packet capture that has only two provided fields: OUI of the MAC address of the device and the inter-arrival time (IAT) of the packets for a specific protocol. 
For example, the labeled data for http and ntp from the point-of-view of a specific device type is provided below:
This is just an example, it's better to create a deeper architecture and add regularization (e.g. l1/l2 weight penalty or drop-out) to prevent over-fitting.
You can convert the categorical value of OUI using a LabelEncoder. It looks like you have two features (OUI and IAT) and a fixed number of classes / outputs. You could use an MLP classifier to solve this problem. In Keras:
It looks like you have two features and a binary output. RNN/LSTM are useful with variable-length input, otherwise, they are a bit overkill.