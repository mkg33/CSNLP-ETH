you can use Fabric. Fabric is a Python (2.5-2.7) library and command-line tool for streamlining the use of SSH for application deployment or systems administration tasks.
use webmin,,,and use its webmin cluster feature, in which you can add all systems to one webmin console and issue them any command or control all of them from one place.
mCollective is a very nice framework where you can run commands over a series of hosts (in parallels) using facter as filter. 
You might like it better or you might hate it.  There are only three reasons I'm mentioning it here:
That's all there is to it.  For example in the nested completed loop you can gather a list of all those which returned some particular exit status or to scan for specific error messages, and set up follow-up jobs to handle those.  (The jobs will be run concurrently, default of 100 jobs at any time, until each is completed; so a simple command on a few hundred hosts usually completes in a few seconds and a very complex shell script in a single long command string ... say fifty lines or so ... can complete over a few thousand hosts in about 10 minutes ... about 10K hosts per hour in my environment, with many of those located intercontinentally).
My own parallel ssh wrapper: classh is an alternative to the various Parallel and cluster ssh tools out there.
So this might be something you can use as an ad hoc measure until you have your puppet configuration implemented and well testing ... and it's also quite handing for performing little ad hoc surveys of your hosts to see which ones are deviating from your standards in various little ways.
The apt-get upgrade command is interactive. To make it run quietly, you can add the option -q=2 as shown above.
To be honest, I did not try it myself, but I think you just need to create a new module that include such an exec definition.