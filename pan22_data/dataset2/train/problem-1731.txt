*Optimizations: Modern OSs are aware of the relationship of LPs to cores and will try, for example, to use just one LP out of each core, until more than number_of_cores threads want to run; the two LP of a core are considered equivalent as far as cache investment is concerned; etc. 
From the time an LP context-switches to a thread, to the time it switches to some other thread, the LP is considered to be used 100% by that thread. The OS has no way to know whether a thread in an LP is using 10% of the core, or 90% of the core, or stalled completely because of something the thread in the other LP is doing. The OS just thinks it's running. 
If you have HT enabled you have two logical processors per core. If you have it disabled, you have just one. (This lets us talk about how the scheduler works without constantly qualifying what we mean by a "CPU".) Either way, a logical processor is seen by the OS as a processor, and except for some attempts at scheduling optimizations* the OS doesn't do anything else by, for, or because of hyperthreading. 
Nor does HT implement anything like thread priorities. So if two threads are trying to run in the two LPs on one core, and one is set in the OS to a higher priority than the other, the core can't do anything about that - there's no way it can even know. The core will treat the two threads as having the same priority and will assign microarchitecture resources accordingly. 
But what about HT enabled processors? How is the time counted? If the thread just waits for the processor pipe to free up in case of HT race - is it counted as time spent in CPU? Or if the thread could take like 10% advantage of HT it will count 10% of actual CPU run time?
I am trying to estimate the amount of work a multithreaded application takes. That is quite a simple task with real cpu/cores as I can just take the CPU time from proc and that will be an estimation of how much of the CPU an application takes.