I've had a need for verifying integrity of backups/mirrors which contain a large number of files and ended up writing a command-line program called MassHash.  It's written in Python.  A GTK+ Launcher is also available.  You may want to check it out...
As a specific case, lets say you want to copy some files from directory1 to directory2 and then you want to verify a successful copy using an md5 comparison.
You could create MD5 sums of every single files, order these checksums alphabetically and has them (with or without newlines). Since MD5 is cryptographic, it should work just fine with hashes of hashes.
which will create a reference file containing an md5 sum for each file in directory1. Once this is done, all you have to do is cd to directory2 and type:
After the process is complete, you will get a summary such as 'So and so many files didn't match up' or something like that.
the idea is you hash all the files cut out the hashes one per line, sort them and hash that yielding a single hash. this doesn't depend on the names of the files.
And you should consider that adding some file to one dir will completely change the result, even if it was just a .directory of .DS_Store file.
If you'd like to see what's different (if anything) between two directories, rsync would be a good fit. 
The program md5sum fetches each path from the md5sum.txt file, computes the md5sum of that file in the destination folder and then compares it with the sum it has stored in the file. 