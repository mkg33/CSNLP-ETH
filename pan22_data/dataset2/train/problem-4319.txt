This may not explain your read speeds (your disks may not be doing the full 2200 iops when you're performing a sequential read), but it may at least help explain your write performance.
It's hard to pin storage vendors down on iops for spinning disks, but for a 7200RPM drive, 80-120 iops is quite believable. Considering that you've probably lost a couple of disks to NetApp's RAID-DP and/or spares, 2,200 iops is close to what you could expect from 22 disks performing around 100 iops each.
As mentioned above, the NetApp had one virtual interface backed by four physical NICs. The host has two NICs and I had configured MPIO through the MS iSCSI Initiator so that there was a path from each NIC to the one virtual interface. The results were the throughput above - writes made sense at close to 200 MB or the speed of two NICs, but the reads were half that or the speed of one NIC.
Upon closer inspection, our SAN guy noticed that traffic was only flowing through one of the physical NICs for the reads. I'm not sure if there was a configuration mistake on our end, but there were two things we tried and both got us our throughput. One was to change from one virtual interface backed by four NICs to two virtual interfaces, each backed by two NIC's. Then map one host NIC to one virtual interface. The other thing we tried was to use "aliasing" on the SAN side to present multiple virtual interfaces. (I'm not a SAN guy, so hopefully I said that correctly.)
My take-away is that we just needed the SAN to present more than one interface so the Initiator truly saw multiple paths. Here is our throughput now:
Disk writes are actually going to memory (NVRAM) on the filer, to be flushed to disk later - on an idle filer, these will be incredibly fast, and iops of 20,000 are quite believable (you'll see similar speeds from most SSDs).
Reads, on the other hand, need to come from disk unless they already happen to be in the filer's read cache (which, unlike writes, are on volatile memory).