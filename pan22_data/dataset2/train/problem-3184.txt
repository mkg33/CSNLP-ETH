The trick for rapid Gaussian blurring with GLSL is to take advantage of the fact that the GPU provides linear interpolation in hardware. Therefore, you can effectively sample four 2D pixels with a single prefetch or eight 3D voxels. By deciding where to sample you can weight the output. The definitive reference is  Sigg and Hadwiger's "Fast Third-Order Texture Filtering"  which you can find online.
Yes, you can implement Gaussian blur in one pass, by sampling all n^2 pixels in the kernel (for kernel width n).  It's usually faster to run it on the rows and columns in two passes, since then you have O(n) pixels to sample rather than O(n^2).  This is not an approximation, since Gaussian blur is mathematically separable.
However, you can also use this trick to approximate a Gaussian with a tight kernel in a single pass.  In the example below I emulate the 3D kernel with the top slice = [1 2 1; 2 4 2; 1 2 1]; middle slice = [2 4 2; 4 8 4; 2 4 2]; bottom slice  = [1 2 1; 2 4 2; 1 2 1]. By sampling +/-0.5 voxels in each dimension you do this with just 8 texture fetches rather than 27. I am demonstrating this in GLSL as a MRIcroGL shader file - just drop save the script below as "a.txt" and place it into MRIcroGL's "Shader" folder. When you relaunch the program you will see your ray cast image blurred. Clicking the "doBlur" checkbox toggles the blurring on and off. Using my integrated Intel GPU in my laptop and the "chris_t1" image that comes with MRIcroGL I get 70fps without blurring (1 texture fetch) and 21fps with blurring (8 fetches). Most of the code is just a classic ray caster, the "doBlur" conditional encapsulates your question.   
For a readable explanation find the web page "Efficient Gaussian blur with linear sampling". As noted, since the Gaussian blur is separable with wide kernels it is most efficient to do one pass per dimension. 
I have been thinking of implementing gaussian blur as convolution (in fact, it is the convolution, the examples above are just aproximations):