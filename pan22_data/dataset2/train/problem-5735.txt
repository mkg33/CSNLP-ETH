I have personally noticed that using the basic algorithm (with weights based on depth differences between high and low res depth values) is far from perfect in situations where high res and low res are blended, say for example an high res object inside a low res effect.
One interesting approach that hasn't been used yet (at least, to my knowledge) would be to leverage MSAA. The idea is that you take your full-resolution depth buffer, and then alias it (or convert it, if the API doesn't allow you to do so) as a 4xMSAA depth buffer with half the width and height. You could then render your low-resolution transparents to a half-resolution render target with 4xMSAA, using your "4xMSAA" depth buffer for depth testing. Then to upscale, for each high-resolution pixel you would access the corresponding subsample from your low-resolution MSAA render target, and blend it on top. This would give you full-resolution depth testing, but half-resolution shading (with framebuffer bandwidth somewhere in between full-res and half-res due to compression). The catch here is that you need programmable MSAA sample points to do this, since you'll want to use an ordered grid sampling pattern for your low-resolution rendering instead of the typical rotated grid pattern. Newer GPU's (Maxwell from Nvidia, GCN from AMD) support doing this through vendor extensions in D3D11 and OpenGL, and it can be done natively on consoles.
It is a well known "standard" to use bilateral upscaling when it comes to comes to combine a low resolution target and an higher res one. 
At SIGGRAPH 2013, Bungie presented a new approach for handling very-low-resolution particles using what they called a "variance depth map". You can find the slides here in PDF and PPTX format. 
Nearest-depth filtering is an alternative to bilaterial filtering that was specifically developed for upsampling low-resolution transparent rendering. It's a bit simpler than bilateral sampling, in that it only requires one sample from your low-resolution texture. However it can still have issues, particularly with high-frequency geometry that isn't well-represented in your low-resolution depth buffer.
I am well aware that there is no way to eliminate completely these problems, but is there a way to improve bilateral upsampling to partially improve on one of the two points above? 