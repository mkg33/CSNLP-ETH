If you'd like a book-length introduction, but something that's gentler than a text like Nielsen and Chuang, I would recommend Quantum Computing for Computer Scientists by Yanofsky and Mannucci.
Besides his standard text with Chuang, Michael Nielsen has a series of video lectures on Youtube called Quantum Computing for the Determined which so far gives an overview of the computational model.
If you're fairly advanced, you might start with the de Wolf-Drucker survey of quantum methods for classical problems.
You're probably already aware of this, but on his blog, Scott Aaronson has links to number of his course lectures on quantum computing, as well as links to QC primers by others (just scroll down the right side-bar to find these).
And on the more entertaining side of things, "A Shortcut Through Time: The Path to the Quantum Computer" by George Johnson.
However it depends in what area you would like to work.
The videos are very watchable for anyone with a little understanding of computer science and linear algebra.
There are areas of the field that really need a knowledge on quantum mechanics, however as instance the area I work on, type theory and lambda calculus, I do not need it, I can do it just knowing some of the computational models for it.
If you have a strong math background this book might seem too basic, but I found it quite useful.
They spend a fair amount of time reviewing the mathematical prerequisites before diving into the QC itself.
It's a good way to understand quantum techniques before you get to quantum problems.
I don't think you need to learn quantum mechanics.
First, you will need to understand quantum physics.