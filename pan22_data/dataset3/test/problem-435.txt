), special charecters (exclamations), emoji unicodes etc.
This means that the tags might be too similar and that their occurrence depends on many similar feature values which makes it difficult for your training algorithm to extract discriminative features.
On a final note: This might well be the first attempt to solving this particular problem (on this data set and this set of labels), so the number you get is not necessarily bad or sub-par, because it might simply be a difficult task.
Also, it might be the case that either the tag set you propose or the data set you have are too similar.
I am quite new to machine learning and data science in general.
I think your dataset may have class imbalance and may need to account for that.
I know why your LinearSVC is giving 0 or 1 class results only:
I know it isn't much data, but the data-set is still well-balanced and won't be the primary reason for such low accuracy.
What you seem to want is to identify meaningful discrepancies between your blog posts in order to identify what category they fit in.
I would recommend to include n-grams (bigrams, trigrams etc.
The approach I have been following until now was a BOW approach with Tf-idf weighting.
I am trying to build a multi-label classifier for suggesting tags on blog posts.
I then decided to eliminate the noise and I applied TextRank on my data to obtain a more meaningful summary and then applied the same BOW approach which however resulted in further loss of accuracy.
I am looking specifically on how to create my features and what else can I try.
BOW approach with Tf-idf weighting seems like a good strategy however you need to improve your feature engineering strategy.
0.35 is a poor estimate than of a random accuracy (<=0.5).
However I could only get an accuracy of around 0.35 on the test set using OnevsRest approach and a SVC.
You must add class_weight=balanced to your estimator, because rest set is much bigger.
I think it's important for you to consider the classification problem in terms of human thinking:
The same thing happens when the data expresses too little variety.
when you are using one vs rest, you have unbalanced dataset.