I am finding best option for anomaly detection, doing some research.
However, in case that your feature is an entire logfile, you need to first summarize it to some feature of same dimension, and then apply Novealty detection.
https://blog.twitter.com/2015/introducing-practical-and-robust-anomaly-detection-in-a-time-series
What I have found is I think best matches your need and is better compare to what you have seen.
In case of algorithm, I found LOF or CBLOF  are good option.
Maybe  this helps  cause  you mentioned  about steady states:
It also have a very good community support and for you plus point is its open source & developed in python.
During testing, you test both normal and anomalous conditions to see how well the model tells them apart.
LSTM-RNNs, in particular, are an ideal choice when it comes to time series modelling simply because of their ability to keep memory of previous inputs, similar to a state space model in Control Theory (if you see the analogy).
This means that you train your model to learn what is "normal".
This network learns to estimate the signal(s) of interest given an arbitrary number of inputs, which you thereafter compare with the actual measured value.
Check the tutorial of one-class SVM and Novelty detection.
If so, Sklearn is your good friend and you can use it as a blackbox.
I assume the feature you use to detect abnormality is one row of data in a logfile.
I have found better is Numenta's NAB (Numenta Anomaly Benchmark).
In Python, it is almost trivial to implement an LSTM-RNN using Keras API (on top of Tensorflow backend).
An advantage of neural networks is that they "learn" the cross-correlations between input signals by themselves; you do not need to explore them manually.
Since you have multivariate time series, I would go for a LSTM-RNN implementation that models the dynamics of your system based on training data, which are usually semi-supervised (only normal class included).
If there is "big" deviation, you got an anomaly (given that the model is accurate enough)!