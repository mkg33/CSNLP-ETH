I want to compare strings and give them score based on how similar the content is in them just like comparing two arrays in scipy cosine similarity.
Or if you want to do it directly on your DataFrame, you can do it like that
Logically I would want a high score between the two strings.
For a faster method, you can use sci-kit learn's CountVectorizer or TfidfVectorizer to get frequencies of n-grams for each string.
This will produce a frequency matrix, which you can then use as the input for sklearn.metrics.pairwise_distances(), which will give you a pairwise distance matrix.
See this blogpost for a nice tutorial on how to go about this.
Then you can use this Python function to compute it yourself or just install a Python package that does it for you
I am comparing array of strings with another array in a single column in my dataframe.
Note that with a distance matrix, values closer to 0 are more similar pairs (while in a cosine similarity matrix, values closer to 0 are less similar pairs).
Levenshtein distance is computationally expensive and therefore slow for large datasets.