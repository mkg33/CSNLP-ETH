The real point I'm trying to make here is this: Don't try to re-engineer the database according to what you think would make it optimized, because you're not a database engineer.
So with that in mind, here's what would make this question a little more answerable:
welcome to the dba.StackExchange.com website, and it looks like you've got quite a pickle.
Now, having said all that, and having been a bit harsh, and having seemed to reject your request outright, I'ld like to ask for more details so I can really focus on answering the question you've asked, altho, if I can hazard a guess, you've gone and ignored everything I've had to say after the second paragraph.
But you have to understand that this is what it sounds to an experience DBA like what you're doing; this trying to optimize the database by theory rather than rational approach.
Of course, it's entirely possible I'm wrong here, but anytime anyone suggests 10k tables, this is the course they're taking.
The database will be the data store for several hundred small website front ends that might draw a modest load of around 150k unique viewers per month, but this might have to scale on short notice.
But the fact that you're asking about open files and other micro-optimizations leads me to think that
However, the data aggregate that outlines is enormous.
But if you'll notice, the only thing that changes on each one is the website ID.
But really a) you've already killed the database by suggesting 10k tables, and b) this is in no way different than what you're suggesting.
And if I may ask, what framework are you using for this database that it will have 10k tables?
If you had all of the Microsoft or IBM corporate databases on one server, 10k tables might be appropriate.
So we'll overlook the "it's possible to be right" and stick with the 99% of statistical non-outliers.
I'm going to hazard a guess that your tables look like: (I don't mean the exact structure, I mean the concept of the structure)
What this means for you is that the intent of SQL is to have one massive table of all blog posts (to pull a single example, that may or may not be appropriate) and to select the matching blog posts from the table by query.
I could instead normalize to include a website ID on each record and reduce the entire mess to four tables.
Will it be supported for updates in the future or do you need a prop-once and forget box?
Additionally, you ask about open files, but that's just it, by doing what I suggest above, you have at most four tables to worry about open files on.
I am looking at rolling out a CMS system that will require the creation of around 10,000 tables within the primary MySQL database of the system.
So before I answer the question that you posed, I'll mention some details to (hopefully) get you off to a good start:
And it's "how the big boys generally solve this problem" if you're really curious.
If you were a database engineer, or worked on a database core-development team, you would already know the answers to the questions.
For all intents and purposes if you suggest 10,000 tables to a dba, they will laugh at you.
which would (for this very simplistic example) yield me right at 1500 tables.
You should really consider that the power of SQL is in its ability to handle sets quickly and easily, and in the ability of the language to parse for the relevant matches to a set of query parameters.