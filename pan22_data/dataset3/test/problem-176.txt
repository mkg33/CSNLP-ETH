Weight of observation can be used in many clustering algorithms.
It simply means that you have 2 distributions from which you are drawing instances, and the variance of these distributions is essentially zero.
If your dataset contains repeated values this is not a problem.
However, distributions with high variance will have significant overlap and will thus cause many instances to be wrongfully classified as being a part of the other cluster.
Clustering is very well suited for very tight distributions because they are easily separable.
Each measurement of each individual will be exactly the same.
What I'd do is first apply grouping similar records and use unique observations with a weight being their frequency.
Thus they will all have exactly the same color and the same length in either group.
Technically, it is allowed to duplicate observations (records) to cluster, yet it is far from correct.
You will see that once you surpass 2, the average distance will not decrease in any further in this case, which means a single distribution is being split into 2 groups.
This value can be calculated by determining the average distance between each instance and its nearest cluster.
K-means attempts to group distributions into $k$ similar categories based on some metric of nearness.
However, the fish of each species are all clones (ignore other biology stuff i know nothing about like environmental factors).
For example, if you have a dataset from which you want to cluster two species of fish with 2 features: color and length.
But you can run k-means with duplicates, obviously.