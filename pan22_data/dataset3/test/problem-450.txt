But in the 1st case it will use less space on the hard disk.
The key point should be in the last sort passage when it will merge the 2 half just sorted.
To have a final answer to your doubt you should see the code downloading your version of sort from gnu  or looking from git.
Or it can proceed processing in parallel the two halves.
I'm afraid that you cannot know the size of output processed till the last passage.
But if it is a lot less you can deduce it still need you file.
If you try to sum  the size of all the tmp pieces that you find, you will obtain a value not necessary related to the percentage of work done.
If you have a recent version of sort (8.11+) you can speed up the process with sort --parallel=N option: you will share the work on N cores.
It can proceed creating the first half and after the second one.
For what if concerns sort algorithm you should see e.g.
It uses the a variation some Merge sorting: it means that it sorts separating in block the whole work, and after merge the sorted blocks.