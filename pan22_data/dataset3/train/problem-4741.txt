My first answer is yes , because for the definition the parameter terms are linear , but I'm not sure of it.
You would still be going through the process of performing linear regression, fitting a line through points via a linear combination of some regressors.
When you have terms like x^2 and x1x2 , you may end up having highly correlated parameters which will create problems such as driving significant coeffs insignificant because of huge increase in the variance of the coefficients of the correlated parameters.
Theoretically, you do indeed have a linear model, yes.
You have a linear relationship between the dependent variable and your parameters.
The definition of linear regression says that the dependent variable y should be a linear combination of the parameters w (but it is not necessary the same for the independent variable x )
Even if there is a quadratic term for the independent variable x2.
This is just a consequence of having correlated parameters in your linear model.
Starting from this assumption I know that this is a simple model for linear regression :
I read that to apply linear regression I need to use a linear model.
Also in this case, I should say that this is a linear regression model because for the definition, w0 , w1 and w2 are still linear in the expression.
Yes , all the models you mentioned are linear models.Linear models are linear in parameters.
One important assumption in linear regression is that your parameters are not correlated (note: your parameters can be dependent though).
This is enough to still call it a linear model generally speaking - see some useful answers in this thread.
I'm new in Machine Learning and of the first concept I would like to learn is linear regression.
However you have a non-linear equation due to the higher-order regressors you have manually inserted (x1x2 and x2^3).
So we can say that also this is a linear regression model :
In general I wouldn't say you have a linear model in the strictest sense at the end, as you are modelling linear relationship between your dependent variable y and non-linear combinations of your regressors: x, x2, and x3, but perhaps there could be an underlying feature to be observed which is exactly equal to x1x2, call it x4, and then you would have removed one of the non-linear covariates.