I work a lot with machine learning applications, so I am constantly moving huge datasets (~ 30-50 GB) of relatively small files.
On my Windows machine, opening similar image folders only takes about 2-3 seconds.
I am using our university network for my research work, and was given a new PC with Ubuntu 18.04, and an Intel i7-7700.
Note that I am using list layout, without any thumbnails that have to be displayed, or anything like that - just the filename, and that's it.
At the risk of incurring the wrath of the powers that be I would recommend you pursue alternative software for this task, rather than attempting to force Nautilus into a role it's ill-suited for.
to simply open the folder and display the contents!
In this case it's probably related to Nautilus checking every file to decide how to display information about it, so you're waiting for Nautilus to read the header of every file in that directory.
Am I doing something wrong, or is this a general Linux-specific problem?
With Linux, I run into severe performance problems when doing so, especially when using Nautilus.
For example, when working with the AVA-Dataset (255530 .jpg-images), Nautilus takes FOREVER (~3 Minutes??)
In its attempt to be user-friendly, Nautilus is sacrificing performance.