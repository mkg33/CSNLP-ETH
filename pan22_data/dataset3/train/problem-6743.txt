After you've generated the first primes that way, you can use the table of primes it produces in trial division to produce larger primes--instead of doing trial division by all odd numbers, you can do trial division only by the primes (from the table) up to the square root of the number being tested.
Not only does it slow the entire process (minor quibble), but it will produce incorrect results once the values pass the integral cutoff of the field width.
You've gotten a number of hints about how to speed up the code, but a few points seem to have been missed.
I think it took a little over an hour on an i3 laptop for this, and it would increase by multitudes for each factor of 10.
If you truly want to allow calculations approaching infinity (or what?
Anyways, using 128 bit numbers would be your best bet...
The first and biggest is that once you've determined that the number isn't divisible by 2, you've also determined that it can't possibly be a multiple of any other even number, so you can skip testing against any other even numbers.
you need to switch to BigInteger which can model "exact" integers of any size.
Although it departs from the nature of the code you posted, it's also worth considering using the sieve of Eratosthenes1 to generate the first several million primes or so.
This issue is so critical to the correctness of the solution that I'll leave it to stand on its own and leave any other review issues for others.
I did a similar project myself, and there's a few rules you can use (one of which was already mentioned by @orion:
The major problem here is using imprecise floating point values.
As I'm sure someone else has pointed out, there's no way even a double could go on forever printing out primes, as it would eventually overflow the mantissa, so it's irrelevant that my example only goes to 1,000,000,000 - You could increase it, but you start running into how long it takes to run.