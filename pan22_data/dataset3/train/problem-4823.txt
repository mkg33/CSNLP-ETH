It's a max, not a min (and never mind that min doesn't work that way either), and it isn't going to try to guess - before you've run enough queries - which tables / indexes it should load into buffer pool memory.
And remember too that max server memory doesn't just cover the buffer pool.
You can probably get much closer to the max values if you pump the buffer pool by issuing a bunch of SELECT * FROM dbo.BiggestTables; on each instance, but it is usually better to let SQL Server allocate the memory as it deems appropriate based on actual usage by your real application.
In short, SQL Server is pretty good at memory management; let it do its thing, and worry about adjusting max memory on your various instances when you have an actual performance issue.
The actual memory in use won't increase until you actually load data into memory.
It's not going to jump to 10GB combined allocated just because that's what you've set max memory to and because your databases are at least that large.
So yes, it is normal to see a gap in these values.