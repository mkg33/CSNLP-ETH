As to concepts it always has to be a case of talking to the person in terms they understand, so know your audience .
What non-technical people rarely want to know about are things like the South Bridge on a motherboard, or the LAMP stack, or the inner workings of a MySQL database.
"Bandwidth" is "the speed you're able to send information to and from the internet", "CPU" is "that one chip in the computer that does all the work - the calculations and data management", hard drives are places where information gets stored, and routers are "the boxes that separate and manage networks - and block malicious internet traffic".
And if I have to and I am sure they won't understand, I just talk in some sort of parable.
It's also fine to use rough approximations that might not be strictly true (something that we geeks are sticklers for), but explain it simply enough.
There are multiple ways that we can explain things to normal users and one of best way is to make simple and clear power point presentations / Movies with real world examples
For software I explain a basic abstraction of how the software sees things and how it processes input.
And concepts that they actually want to know about.
A few months back I tried to get a total technophobe to install something really really simple that just required you to double click on the file and click the finish button when done.
I got a long email response back explaining to me that it made about as much sense as how to perform a "uniform layered haircut".
You explain simple computing concepts to non-technical people.
Bandwidth and CPUs and routers are simple computing concepts.
Processes are described as people performing tasks.
There's no faster way of making anyone's eyes glaze over than using vocabulary that's unfamiliar to someone.
A fine example of this is when one day my boss tried to explain a tidbit of macroeconomics to me, and used no less than 5 unfamiliar terms in about 3 sentences.
That way I don't spend hours trying to do things, or offering suggestions for a problem that doesn't exist or a problem that has been badly described intially.
You don't explain advanced computing concepts to non-technical people.
My first approach is to question them rigourously to find out what it is they are trying to do, trying to understand, having problems with, and ideally show me the problem or explain in detail what they don't understand.
When explaining simple computing concepts, avoid using acronyms and technical terms.
The wider the band the bigger it is, and bigger is usually better right?
For hardware I often make traffic analogies where the architecture is a city.