The returned features you get from the PCA are not the original one!
I don't know how it is done using neural networks but would be glad if anyone has an hint.
Let's use the following notation : $(x_1, ...x_9)$ are the first 9 variables out of which you try to predict $y$, your tenth variable.
As to assert which variable $x_i$ explains $y$ the best, one might use different ways.
Moreover, it is done such that each $x_i$ explains a certain part of the training dataset variance.
But this $x'_i$ is a particular combinaison of $(x_1, ..., x_9)$.
Thus you end up having your first variable $x'_1$ explaining a lot your prediction $y$.
The PCA transforms $(x_1, ..., x_9)$ into $(x'_1, ..., x'_9)$ where each $x'_i$ is a particular combination of the $(x_1, ..., x_9)$ such that for any $i, i'$, $x_i$ and $x_i'$ are linearly uncorrelated (ie orthogonal).
In fact, most of the implementation sort the $x'_1, ..., x'_9$ such that the first one is the one explaining the variance the most, then the second, ...
Just to mention that the feature importance is not absolute ; it relies on the technique (or estimator) you use to address this question.
I will try to address what looks like a PCA misunderstanding, then give you some ways to predict which variables $ x_i $ matter most to predict $y$