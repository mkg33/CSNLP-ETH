Does a modern compiler generate different code for foo1 versus bar1?
I am unlikely to remember to account for the fact that other architectures could have a 16 or 64 bit int.
There's not much to review here, since it's only a single macro, but there's still room for improvement.
I would very much prefer a macro that took care of the type sizes for me and left the interface as passing the the natural array size.
You can get that and avoid the problems of macros, by defining a static function instead.
If I am in "trying my best mode" as a coder, late at night with a stressful customer deadline hanging over me, it'll be all I can manage to remember to clear memory.
I will inevitably try to clear an int array of 8 elements with ERASE_STATE(arr, 8).
If that's the motivation for using a macro, it's based on a misconception.
The issue that makes me most uneasy is the interface decision, specifically requiring calling code to calculate len in bytes.
It generates the exact same code without requiring any additional libraries or translation units, and without any runtime overhead for function calls.
It also does not sacrifice type safety and is easier to debug and maintain.
There is not much code so I won't write much review
If I am lucky I will remember to use 32 and add a comment about the 4x8 calculation.