The algorithm to use would be to square all values on the right-side of the array that are larger than the abs-value of the left-most value.
Since it is sorted, you could just loop through the array once, compare the absolute values of the first and last items in the array and then based on whichever is larger, square that item and place the value into the last item of a new array.
Note, don't use the above as an example of good C++ code, but it shows the algorithm to use.
The bones of a solution that addresses the while might look something like:
Sorting algorithms for an array are baked into most programming languages or can be found in a library [the kind with books if not the language's standard ones].
Shift all values left, insert the square, and move on.
Basically, you're doing a sort and square the value at the same time in a single loop.
Yes, it can be done more efficiently than bubbleSort's O(n^2).
That's the sort of hard problem that matters to a sensible interviewer.
On the other hand, if you must sort after changing each element, leverage other parts of the standard library, say std::lower_bound and std::rotate.
Be careful about the order you do things so you don't risk squaring any element twice.
Sure they don't handle arbitrary objects directly, but they all handle integers appropriately for the purposes to which the language is usually put.
If the standard library is out of bounds for the interview, run.
It is quite possible that if you just square all the numbers and then call a sorting algorithm provided by your implementation, that it will figure out that your array consists of a large number of integers in descending order, followed by a large number of integers in ascending order, and merge both sequences in an optimal way.
There's a whole chapter in Knuth for anyone needing to take seriousness up a notch.
Buy an Xtreme CPU, store everything in RAM - or even better the L1 cache and go drag racing.
Presenting an unreliable answer in O(n log n) is often worse than a reliable one in O(n^2) even if a reliable answer in O(n log n) is preferable.
Keeping the array sorted while changing it's values means concurrency semantics.
I believe you have missed a critical requirement, that you need to keep the array sorted.
There is a way to do it while keeping all the data sorted at all times.
It depends on the implementation of the sort algorithm.
But ultimate performance is tuning rather than problem solving.
Once you find a value that's smaller, you know the left-most value squared needs to be inserted at that point.
Since the case that an array is already mostly sorted, or sorted in descending order and so on, a good practical sorting algorithm will not be optimised for the case of random numbers, but for practical cases.
Note that, at some points, values are duplicated (during the shift), but, at no point is the array out-of-order.
Repeat this process by increasing the front index or decreasing the back index (depending on whichever value was larger), then placing the next largest item into the new array's second last item and so forth.
Your code is very C-like, and a C-like implementation would be:
If you are allowed to have the array unsorted after squaring, and sort it afterwards, at least use std::sort, or, for better time performance but more space usage, std::merge.
The negative values in the input start sorted, but as you square them, they reverse.
The limit of general comparison sorting algorithms is O(n log n).