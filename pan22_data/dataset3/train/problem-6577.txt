So the computer would then have to be able to implement a superposition of instructions in its instruction set.
As is mentioned in Peter Shor's answer, implementing a quantum superposition of gates is very difficult, and so the program is stored classically.
There is a recent article on implementing a quantum von Neumann architecture.
The circuit model is able to simulate the von Neumann architecture with only a polynomial slowdown, so quantum complexity classes are not changed by this change of model.
If the data and program are stored in the same memory device, this would imply that the program has to be quantum, as well.
In fact, even indirect memory retrieval, including RAM, pointers, and so forth, appears to be quite difficult to implement experimentally.
I'll use the Wikipedia definition, and say that it's a computer which keeps its program and its data in the same random-access memory.
In particular, for a quantum computer, the data has to be quantum.
This is orders of magnitude more difficult experimentally than just having the memory in superposition.
This works well as a theoretical model of a quantum computer, but there are severe drawbacks to implementing such a device.
This allows their quantum CPU to perform one-, two-, and three-qubit gates on qubits, and the memory allows (data) qubits to be written, read out, and zeroed.
This has resulted in the default model of a quantum computer being the uniform quantum circuit model, which is both easier to imagine implementing experimentally and tractable to deal with theoretically from a TCS perspective.
They do this via superconducting qubits, of course the implementation is very small, with only 7 quantum parts: two superconducting qubits, a quantum bus, two quantum memories, and two zeroing registers.