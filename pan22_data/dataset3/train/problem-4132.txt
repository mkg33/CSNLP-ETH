This has enabled us to specify times for each job to run which is great.
We currently use a fairly basic script we wrote to log ship our databases to our DR site (and back again) but want to move to a better solution.
I could see how the built-in log shipping set up might be undesireable given the setup on this many databases but it would give you the ability to schedule the when the copy jobs run for each shipped log.
Also, you don't mention the amount of latency that is tolerable.
This reads to me like your wish is to manage when the logs are copied, that you wish to minimize job collisions here.
Our current problem is that if the secondary server 'misses' a log it goes wrong and we have to transfer the whole database.
We have solved basic logshipping by just using sqlserver 2008s inbuilt logshipping.
it isn't all that hard to write custom log shipping scripts to account for this.
I guess my question is - are we on the wrong track here?
I'm not understanding the "...cannot get it to run in an order so they all take up bandwidth at the same time...".
i've posted some scripts up on searchsqlserver.com that you can use.
We dont have vast amounts of cash to burn on a solution only our own time and patience :-).
Not what you have asked for but in the absence of a bulletproof custom script or third party tool it is an option.
We initially discounted the inbuilt logshipping solution due to the fact we would have to set it up manually for each database (we have about 40 and will have 80 before the end of the year all about 2-5GB in size) and also cannot get it to run in an order so they all take up bandwidth at the same time.
We basically need to get to and from our DR site within 30 minutes and for a test we are worried about dataloss (but for a real disaster we dont mind).
I've only sampled it, but the interface and scheduling within it may be what you need.