If you need to find the player once for every entity in the world, this approach will kill you for all but the most trivial of games, and even then it's probably worth "optimizing" this lookup to be constant time (e.g.
In practice, games developers tend to tend towards low O algorithms but balanced against cost in time developing, or debugging.
In many cases, the best optimal solution is two step.
I think it applies to games more than most other industries, since the market is the one who would most notice speed problems.
Someone using a word processor won't care if there is a half-second delay for doing action X, but gamers will probably go 'omg omg game Y is so slow it takes ages to do action Z'.
Space complexity could be an issue, although that could be expressed in O in general as well.
However, what if you want to find a specific entity in the entity list?
store off the index of or a pointer to the player somewhere), giving you more time to do other things that actually are visible to the player.
Maximizing the amount of time that the processor is computing data that will be shown to the player is maximizing the WOW!
I have no references but Big O is at least handy to be aware of when analyzing a problem and discussion.
When you prototype a game function or an aspect of a game, you shouldn't worry about optimizing it at all.
You might not be so concerned about big-O when, well, I can't really think of a time but I'm sure there are some.
As with every other question regarding "what's the One True Path", these are all tools in your toolbox and there are cases where big-O trumps everything, and places where it doesn't matter(tm).
I guess that sums it up, though; any time the processor is doing something that isn't directly representable to the player, it's wasting time.
It'll take an amount of time linearly proportional to the file size (discounting the constant factor of seeking and possible ramifications of sector size).
In the course of prototyping it and learning about the idiosyncrasies of that functionality, the necessary optimizations will become obvious & will factor into the final design like 2nd nature... most of the time.
The problem with Big O is that it's a generic designation of complexity of the task and doesn't take into account the complexity of modern target hardware, nor does it offer any insight into the setup time overhead.
Simplicity over complexity, in my opinion, is relatively useless in game development as speed is almost always an issue, so unless the simplicity leads to to speedups (but then it means your complex case was wrong for the wrong reasons) simplicity will have to go out of the window in favour of speed.
http://seven-degrees-of-freedom.blogspot.com/2010/07/question-of-sorts.html
And as with everything, there's always a trade off.
:)  Thankfully, most of the things that we do in games scale linearly; you want to read a file off of disc?
You would "never" write a physics solver without being concerned about big-O.
Normal case analysis...less so, as you don't want outliers to spike either.
You find this all over the place in games development where the number of items in the operation is either so large that a very different algorithm is quicker, or so small that a dumber algorithm is sufficient (or fits in cache so well it overrides the efficiency of the better algorithm).
If you're writing a networked game, you're going to be concerned with the way performance and network traffic scales per user.
You wouldn't implement a sorting algorithm (for any but the smallest of datasets) without being concerned about it.
But Big O is definitely useful, as failing to grasp it will fail to help you analyze possible solutions and their impact.
Once you have a reasonable solution you always have to look at how the hardware is handling the task, and how to let the hardware get more done in less time.
But it does help sort out obvious issues which could cause performance hits; why use something in O(n^2) time, when you can do the same thing in O(log n) time?
On the other hand, of course, if the O(log n) version has a way more involved O than the O(n) version it's a moot comparison.
Big O matters most of the time, but sometimes an apparently "worse" algorithm in theory turns out to be much faster in practice.