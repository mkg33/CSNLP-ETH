If you're not using a pipeline, I still think it's helpful to think about these machine learning tools in this way because, even the simplest classifier is still performing a classification function.
So, transform is a way of transforming the data to meet the needs of the next stage in the pipeline.
Firstly, all estimators are trained (or "fit") on some training data.
It takes as input some data and produces an output.
In summary, fit performs the training, transform changes the data in the pipeline in order to pass it on to the next stage in the pipeline, and fit_transform does both the fitting and the transforming in one possibly optimized step.
Secondly, all of the scikit-learn estimators can be used in a pipeline and the idea with a pipeline is that data flows through the pipeline.
This isn't a technical answer but, hopefully, it is helpful to build up our intuition:
Once fit at a particular level in the pipeline, data is passed on to the next stage in the pipeline but obviously the data needs to be changed (transformed) in some way; otherwise, you wouldn't need that stage in the pipeline at all.