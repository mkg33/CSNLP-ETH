Whilst studying the subject at university, I had a similar thought on the matter; so, I posed the question of "why" to the lecturer and the response was: "compilers".
In other words, he did not propose a 'standard Turing Machine', with a standard set of symbol which we can use to write down our Mathematics.
I'd like to leave the historical and philosophical aspects on the side and address your main question, which I take to be this:
I think Lambda calculus is a formal language that is worth studying for its own sake.
de Morgan's work on Relational Algebra also was motivated by various projects of his; Peirce and Frege had their own motivations for creating modern logic.
I think $\lambda$-calculus has contributed in many ways to this field, and still contributes to it.
Indeed, it is probably not a core module for that reason, but (for the reasons I have stated) there will be the odd few - other than academics - who may find it integral to their chosen career path in computing.
Now, we could ask why treat LC as a primitive, rather than as a TM dialect?
He reified this in his Turing Machines, where symbols are recorded in cells on a tape and an automaton keeps track of the state.
Turing argued that Mathematics can be reduced to a combination of reading/writing symbols, chosen from a finite set, and switching between a finite number of mental 'states'.
In this sense, we can't cut out some section of tape and say "this is addition", because it is context-dependent.
This makes LC very well aligned with how (formal) Mathematics is practiced, which is why many (functional) algorithms are still presented directly in LC.
Leibniz, when erecting the foundations of Boolean Algebra, had a certain philosophical project in mind; Boole studied it for his own reasons.
Barendregt's The Lambda Calculus is the bible, so if you're hooked after Hindley & Seldin, there are lots of topics of both semantical and syntactical nature in there to explore.
However, there are still those out there who work with languages at a low level - and I imagine lambda calculus, object calculus and other related formalisations have helped them to understand and perhaps develop new theories and technologies from which the average programmer can then benefit.
how can we turn lambda calculus into a deductive system like FOL?)
You can learn the fact that in untyped lambda calculus we have these little beasts called 'Y-combinators', and how they help us define recursive functions and make the proof of undecidability so elegant and simple.
useful because we can relate them to the 'task' at hand; whereas lamdba calculus seems a bit too abstract.
Check out Hindley & Seldin's Introduction to Combinators and λ–Calculus for an introduction.
In my opinion, we often consider high level languages, patterns, automata, algorithm-complexity etc.
There are many other interesting topics to explore (e.g.
This is a horrendous way of working ("Nobody wants to program a Turing Machine"), which is why so many (imperative) algorithms are presented as pseudocode.
The point is: whatever reason Church may have had when creating lambda calculus, the point of lambda calculus varies from one practitioner to another.
how should we give the semantics of lambda calculus?
), I thought that perhaps my "penny's worth" may be of some use.
He argued that any 'effective procedure' can be implemented by some Turing Machine, and showed that a Universal Turing Machine can implement all of those other machines, but he didn't actually give a set of symbols, states and update rules which implement Mathematics in the way that he argued.
As soon as she mentioned it, the power behind reduction and the art of assessing how best to manipulate it suddenly made the whole purpose of why it was and still is a potentially useful tool.
Three examples follow, and this is not exhaustive.
The answer is that they have no inherent purpose to them, even if their designers created them for some purpose or another.
of the arguments, how much tape will be used for the result, whether any previous operation has corrupted that section of tape, etc.
Once it was shown that LC and TMs are equivalent, we could use LC as our 'standard Turing Machine' and everyone would be able to read our programs (well, in theory ;) ).
There are Church numerals, there are functions for addition, multiplication, recursion, etc.
I have just come across this post and despite my post being rather late in the day (year!
You can learn the amazing fact that there is an intimate correspondence between simply typed lambda calculus and a type of intuitionistic logic.
The machine's behaviour, when it hits that section of tape, depends on the machine's state, the lengths/offsets/etc.
On the other hand, the semantics of TM programs are operational: the meaning is defined as the behaviour of the machine.
The answer is that LC's semantics are denotational: LC terms have 'intrinsic' meaning.
Lambda Calculus, on the other hand, is precisely that.
What is the point of Boolean Algebra, or Relational Algebra, or First-Order Logic, or Type Theory, or some other mathematical formalism/theory?
Since I am not a specialist in $\lambda$-calculus, I certainly miss some important points.
Church was specifically trying to unify the notations used to write down our Mathematics.
However, Turing's machines are not a constructive proof of this reduction.