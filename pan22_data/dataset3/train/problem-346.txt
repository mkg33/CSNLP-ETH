All the same I'm hoping a little expertise might clear my confusion.
Suppose I have four EBS volumes, sdf1, sdf2, sdf3, sdf4.
In contrast, every single tutorial I can find on the web (and these are but a sampling) uses mdadm first, then manipulates the resulting device, usually something like this:
For my part, I tend to use both in our cloud; essentially, I create the raid device /dev/md0 and then manage it with lvm.
I use LVM to give me the ability to easily add capacity to the file system and snapshot data (amazon's snapshot feature doesn't help so much if my data spans more than one drive.)
I sort of understand -- albeit loosely and without the ability to comprehend details -- that mdadm creates software RAIDs, and that these are distinguishable from hardware RAIDs, but I can't seem to figure out what, if anything, the above script snippet creates.
I'm new to Linux device management, and filesystems generally, so the answer to this question might be "No, of course not.
The advantage is I can use whatever raid level I need to suit my performance or data security (raid 0 for high speed IO operations, raid 10 if the data is extremely valuable.)
Your first example is using the Logical Volume Manager to create a volume that is has properties somewhat like a RAID0.
I recently found a legacy script that creates and attaches volumes to EC2 instances.