If you have trained model properely, then you will notice no significant change(except better accuracy metric on previous test / validation data).
As test data supposed to come from similiar distribution to train data, you won't break your model.
But it's rareraly true that test data comes from precisely same distribution as train data, so in real application case scenario you may get better generalizability of your model.
For example, I have seen some approaches in ensemble classification where training and validation ( but not testing) sets are combined at the end.
The answer for this question depends on the training algorithm ( technology) that you use.
It is very important to know that even validation is used mainly to decide the hyper parameters some of these hyper parameters can be a function of the used data for training.
For example, in DNN validation used to know when to stop, because overfitting can happen as a result of keeping tuning the parameters ( weights) of the network, we need a way to know when to stop.
Testing set should not be touched at all, as indicated above without the testing set you will have no method to evaluate your model.
Without the validation set you will be walking blindly in the training process.
In the other hand, if you use exactly the same number of iterations as specified before, there is a high prob that you will not gain from these additional samples.
This is gambling, you CAN NOT deliver any model or solution without the estimation of its accuracy on the true data distribution ( which represented by the testing data) .