Use that cost/time/data to guide how long you can tolerate a rebuild, or how many hours the system can be down, or how much money you want to spend on hardware.
You'll need to figure out how much your data is worth, in real world dollars, and how annoying or costly a failure will be before you can think about storage strategies.
As this is to be used for backup storage, I don't see the need for raid 6.
If you want the added bit of safety, go for RAID6 which will give you the ability to survive two simultaneous disk failures.
It's unlikely that two drives on the backup raid will fail within a few days, at the same time as production data are damaged or lost.
You could also do raid 5+0 comprised of two 4-disk Raid 5's.
Raid 6 is slowest of all of the options, lets you lose 2 disks, and will still leave you with about 6TB usable.
On my filer I run a software raid 5 across eight 500 GB s-ata drives, which works great.
RAID5 will take a considerable amount of time to restore on 8x1TB SATA drives, but given the chances of something breaking at low IOPS that's probably not critical.
A hint is that the answer can't be "no loss ever," because that has infinite cost.
Read performance near 160 MB/s write performance around 90 MB/s.
I'd say go for Raid5 over 7 disks, and keep one as HS.
This would let you lose 2 disks, give you better IO, and leaves you with about 6TB usable, but there's a good possibility your controller doesn't support it (usually requires higher end stuff).
If it is purely for backup purposes and IO doesn't matter, raid 5 should be fine, raid 6 would be even better but you'd be losing storage space.
But everything really depends on the raid controller you're using, and on the type and quality of your drives.