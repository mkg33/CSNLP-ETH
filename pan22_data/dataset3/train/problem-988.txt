In a few cases we have defined columnstore indexes.
In this scenario, data file (.mdf), log file (.ldf) and tempdb are all stored on a large RAID 10 volume.
Which of the below physical designs of the server will result in better performance1 and db management2 overtime?
Scenario 1. create one (or more) filegroup per physical drive (we only have SSD NVMe drives), and spread the heavily used tables and indexes across different drives.
[2] by db management I mean add/remove/update data, keeping the performance, redundancy, availability ..
Also most of the tables have composite non-clustered indexes too (B-tree).
There are some quite large tables in the DB with more about 1010 .. 11 records.
Partition tables/indexes and store each partition on different physical drive.
I'm going to build a Microsoft SQL server database which could end up being more than 40 TB in size.
If you think none of the above are ideal solutions; I'd love to know what would you recommend.
[1] by performance I mean lower retrieval time and higher IOPs, for a given indexing architecture
Bundle all drives using RAID 10 and create a single large volume.
I should mention that it wold be close to impossible to distribute data uniformly across all partitions because of the type of data we are dealing with.