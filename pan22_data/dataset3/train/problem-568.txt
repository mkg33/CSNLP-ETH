Note these have higher hardware requirements, more nodes more total RAM etc.
PS2: Unfortunately I only have enough reputation for 2 links but all the keywowrds are googable rather easily.
If you are running a database, of course you can run the database clustered.
There are of course hybrid modes, and it all really boils down to make compromises within the CAP theorem.
Anybody, from anywhere, wherever kubernetes allocates, can access the lizardfs endpoint.
LizardFS  is sadly currently not included, however you can expose LizardFS as an NFS endpoint and use that from the Kubernetes Cluster (I haven't seen anybody doing that yet, if you see any links please share.)
You could create a Kubernetes Cluster so that you are basically able to schedule anything you want anywhere on the cluster.
When doing so they use local disk resources and make it available to the entire cluster.
Kubernetes will run any docker image, allocating intelligently, so the limit is the sky.
PS: and yes you could run an X server on a scheduled K8S container.... Now I don't want to think about it as I have enough on my mind with the server side.
Note that distribution in the case of storage can achieve two things:
it can use the distributed file storage itself (this might be slower, there are "two levels of indirection").
- HA the fact that you have multiple copies of the data means that if one copy is unavailable you continue churning.
In this category the only star seems to be LizardFS.
You could go about this in many, MANY different ways.
I am sure there are enough people out there who have nothing better to do who run x servers in Kubernetes...
A "what I want to run on my local network when I become a real man" list :-).
Note that the providers themselves can run as Kubernetes workloads, one per physical machine.
For HA/sharding all-in-one setups ala ArangoDB, well it's not that easy anymore.
Relational databases have their HA setups that you can run of course on K8S.
Basically data is sharded and allocated to different nodes.
Let's talk about server applications (and going back to my previous question, even something user oriented like emacs can be run with a server backend).
Where do the database instances forming the cluster ultimately save the data?
Let's keep pure GUI components out of the equation, because for those the resources involved are different from memory and cpu (Human-computer interfaces, GPU), and cannot really be distributed (of course you can distributed your GPU for big processing loads, but let's leave that use case out of the equation for now).
You should start by having a distributed file system (or distributed block storage).
So with this you have already distributed your CPU and RAM.