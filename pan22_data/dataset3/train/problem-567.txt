Why not use the same statistics to denormalize the results?
In fact doing so will most likely reduce the effectiveness of your model.
On the prediction values, I cannot the min and max real value.
If the test data is good enough to train a neural network then why would its statistics not be good enough to denormalize the results?
You do not need to calculate new normalisation constants for new data.
mean and sd per feature), treating them as part of your model.
I run several times the prediction model with the same inputs to get the average and standard deviation of it.
How do you solve this kind of problem and if you cannot, are there any other decent prediction techniques without the need of normalisation?
I wrote a Neural Networks prediction model in Python.
The same principle applies to interpreting output values if you need to scale those into range that your model produces.
Use the same values to normalise test data or new inputs as required.
I suggest using robust estimates of the mean and standard deviation to normalize.
Once you have used these values to transform input, they become fixed translate/scale factors in the model.
However, I would suggest not using min and max as the scale factors.
On the test data I knew the min and max, so I could denormalised them.
In order to make it work, I have to normalise every column on data for good prediction results.