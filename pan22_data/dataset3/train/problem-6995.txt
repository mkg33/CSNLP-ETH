I'm familiar with gradient descent algorithm which can find local minimum (maximum) of a given function.
Now virtually all gradient-based optimization methods suffer from this by design.
I presume you are talking about unconstrained minimization.
These can also be combined with local methods like gradient descent.
Your question is really about global optimization.
But you may want to look into simulated annealing algorithms, or other approaches that rely on Markov chain Monte Carlo (MCMC) methods.
Again, the answer is no, there are no general recipes to modify a method so as to guarantee that a global minimizer is identified.
The problem here is that some local minimizers are global maximizers!
But now imagine the function is $f(x,y) = x^2 - 10^{-16} y^2$.
it was shown by hajek in the mid-1980s that annealing a nonconvex problem under certain strict conditions is guaranteed to reach the global minimum: http://dx.doi.org/10.1287/moor.13.2.311
Consider for instance $f(x,y) = x^2 - y^2$ and the initial point $(x_0,y_0) := (1,0)$.
Depending on the particular function being minimized and the starting point, you may very well end up at a saddle point or even at a global maximizer!
In general, say you determine that the Hessian $\nabla^2 f(x^*,y^*)$ has an eigenvalue equal to $-10^{-16}$.
You would realize by examining the second-order optimality conditions.
Are there any general techniques, how to enhance an algorithm which can find local extremum, for finding absolute extremum?
It stops when it has found a first-order critical point, i.e., one where the gradient vanishes.
This function is perfectly smooth, but if your initial point is $x_0 = -2$, the algorithm stops at a global maximizer.
The classical gradient descent method (also called steepest descent method) is not even guaranteed to find a local minimizer.
Your question should specify if you are considering a specific problem structure.
There is probably no one-size-fits-all answer to your question.
Some exploit the structure of the problem, but those are for special cases.
The steepest descent direction is $-\nabla f(1,0) = (-2,0)$.
One step of the method with exact line search leaves you at $(0,0)$ where the gradient vanishes.
Just ask yourself: if the algorithm returns a value and says it is a global minimizer, how would you check that it's true?
Is there any modification of gradient descent which allows to find absolute minimum (maximum), where function has several local extrema?
Here, $(0,0)$ is still a saddle point, but numerically, the second-order conditions may not tell you.
There are classes of methods in global optimization.
And by checking the second-order optimality conditions, you wouldn't know!