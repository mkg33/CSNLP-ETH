Up-shot: noise variables can wreck that first split I mentioned above, and even useful variables can make the tree lose track of the XOR.
Note that you can choose > or >= to skew classification toward your preferred class when a point falls precisely on the boundary.
I have read online that decision trees can solve xOR type problems, as shown in images (xOR problem: 1) and (Possible solution as decision tree: 2).
In your example, we need to make a decision tree that considers the following:
when variables other than $x,y$ are available to the tree to split on.
Your image shows that a tree can easily represent the XOR function, but your question is how to learn such a tree structure.
Is it possible to solve the presented problem with a decision tree?
A neural network can perfectly sort a list of integers, but training one to do that would be quite hard.
Would using a random forest solve the problem in any way?
But, as long as your algorithm makes the plunge with one of those first splits, the next splits are obvious and your tree will make them.
A simple discrete decision tree could therefore be:
Like the discrete example, this can be solved using three decision nodes:
You can therefore implement XOR with three decision nodes.
I just don't see a way for any metric (Information gain, Gini Score, ...) to choose one of the splits in image 2 over any other random split.
Yes, it is possible to implement XOR with decision tree.
I have pasted your example image here for reference:
Here's a notebook (github/colab, suggestions welcome) demonstrating that yes, a (sklearn) decision tree can learn $\operatorname{sign}(x\cdot y)$ (perhaps with some errors when points are extremely close to 0); but it also goes on to show some of the difficulties, e.g.
Probably not the basic problem, but it looks like it helps with, e.g., the noise variables above.
Indeed, the first split is probably quite random, or due to noise (if you go for $\operatorname{sign}(x\cdot y)$ with continuous $x,y$ instead of the discrete $x,y$ and XOR).
My question is how can a decision tree learn to solve this problem in this scenario.