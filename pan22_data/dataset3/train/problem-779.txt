Feature selection is used to check the integrity/importance/value of individual features and how they affect the model.
There are very good suggestions made above regarding the problem.
In another approach, (somewhat similar but not same as PCA based menthods mentioned above) is to use an  compressional autoencoder network and train it classwise (or one autoencoder).
It is a very standard starting point for exploring data.
As opposed to PCA,  t-SNE learns a non-linear transformation which preserves the global data structure.
PCA is mostly a good first pass and helpful visualization.
Feature selection and cross-validation are the most direct ways of determining feature integrity.
PCA will work for make a generalization of the dataset as a whole.
model (this does require a little more work as the weightings are not necessarily an exact measurement of variable importance).
Since the autoencoder(s) would learn to represent different classes, if the features selected for the original dataset can partition the data space adequately, then in a 2D scatter plot the differences could be made out.
Does the above plan sound okay for testing to see if features are any good?
If the first 2 components don't show separation, that does not mean that the features are necessarily bad, it just means that the first two components do not explain the majority of the variability in the dataset.
This was going to be a comment but it grew to an answer.
I think t-SNE can be useful to visualize high dimensional data by 2D or 3D projection.
I want to check the integrity of the features, if they are good representation of the respective classes, i.e.
The compression can be from multi-dimension to 2 dimensions and can be easily plotted.
Sklearn provides an easy to use implementation of t-SNE in here.
You can use random forest gini importance to rank your features or lasso regularization to with cross-validation to find out how individual features are weighted in a log.
I think there should be some clarification because the question itself is not specifically about visualization but checking the "integrity" of the features.
If the first 2 components do show a clear separation, this is a pretty solid indication that at least some projection of your data can well represent your classes.