You could in principle estimate both strength of association and collinearity, but it probably is bad practice and would result in overfitting.
Now if there are other variables available, how would I test if the new variables would improve my accuracy without building new model.
Also in general I think it is best to not use accuracy to evaluate a logistic regression (see ref) but rather a proper scoring rule like Brier Score.
where one model contains a subset of the variables of the other model) I believe that best practice is to compare the AIC or BIC, or perform a likelihood ratio test.
Another thing to consider, if you are unable to refit the full model, but are able to access its fitted values (i.e.as score or probability values), you can try setting up a new logistic regression model with both the fitted values and the new variable as covariates for the same response variable.
Let's say I already have a logistic regression model (or other) with N number of explanatory variables and is 70% accurate.
In this way you will see, whether all of the newly provided information was already captured by the existing model, or will the new covariate add further out of sample accuracy.
I do not think you can estimate the effect of a variable without adding it to the model.
This is because the effect of a variable on the model's discriminatory power depends on