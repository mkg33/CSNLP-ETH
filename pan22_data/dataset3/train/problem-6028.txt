I have trained an ANN model for a regression problem which takes 10 parameters as input and gives 1 output.
This is how you create a pipeline containing the onehotencoder , fit your data on the pipeline.
Use sklearn.preprocessing.OneHotEncoder for example and transfer the one-hot encoding to your web-service ( i'm guessing that's how you're using the model for inference ) via sklearn.pipeline.Pipeline.
After training, I saved the model as json and weights as a .h5 file using keras.
Some of the machine learning algorithms did not require scaling(Standardization/Normalization) So I could load those models and used for making predictions.
The pipeline will save the state of your fit on your training data and apply the same function on your production data.
I have loaded the model and my question here is how do I scale this single row of input values, before feeding it to the model?
And here , the variable momo contains your production data with the pipeline ( containing the one-hot encoding operation ) applied to it.
All is left is dumping your pipeline in a file, loading it later in your production environment, and call the transform method on your loaded pipeline :
How do I do in an ANN model, since we scale the data for training?