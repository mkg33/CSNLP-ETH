There still is a large part of the negative group that we can correctly label.
If for example, the negative group has a very long tail that overlaps with the positives, that's different from two identical distributions.
If the model is not perfect, when there is overlap between the predictions of the two groups, there will be no threshold $t$ where the true positive rate is 1, and the false positive rate is 0.
If this curve is correct, instead of a possible misspecification like @Erwan commented, You might be dealing with a relatively widely spreaded group that partially overlaps with the other.
This means that the curve doesn't go through the left-top corner, but instead forms a curve.
Suppose the negative group has a long positive tail so that only the tail overlaps with the positive group.
In this case, there will be no false positives, while having all true positives.
This is a scenario that looks similar to your second curve (with the two labels swapped).
Suppose the model produces a prediction $\hat{y}_i \in \mathbb{R}$ for some data.
The area under this curve shows how good the model is, but that's not all.
We can also use the shape of the curve to read what the model struggles with.
Because of this assymetric distribution of classification errors, the ROC curve will be assymetrical as well.
Take for example a perfect model, which can fully separate the two group.
Similarly, we can catch 100% of the positive group, at the cost of an elevated false positive rate due to that tail.
Based on this prediction you should make a decision to label that data as positive or negative.
The terminology can apply to any two labels, but positive and negative are most commonly used.
From the ROC curve you can measure the ability of the model to tell the two groups apart.
The ROC curve shows the false- and true positive rates of the model, depending on where that threshold is put.
There is after all more than one way the data might overlap.
There will be a band of possible thresholds $t$ where all of the $\hat{y}_{i \in -} < t$ and $\hat{y}_{i\in+} > t$.
Some other answers alluded to a simplistic interpretation of the ROC curve: The higher the area under the curve, the better the model is at separating positive and negative groups.