An accuracy of 0.967 is a good score if you achieved it on the test set, so make sure that you are talking about the test set here.
If you still don't feel satisfied with the accuracy, its time to try a different algorithm, using more units in each layer and trying different activation functions.
This way you can actually see how your hyperparameters are behaving and you won't have to guess.
Once you calculate the test score this way, it means you have good values of the parameters.
Thirdly, adding more layers is not a very good idea, since you are already using a DNN classifier and could lead to overfitting.
In corss-validation you basically train your model on different chunks of your dataset, and validate on the chunk you leave out, then test it on a separate test set.
Secondly, increasing the number of iterations on the dataset won't do anything if your solution has already converged.
That being said, try to caculate a cross_validation score for your dataset, as then run it on a test set.