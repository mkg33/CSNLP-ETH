the rows contain sequence of 20 states for each of the 50 customers (dataset has 50 rows and 20 columns excluding the headers).
I am trying to determine the next state using markov chains and all the literature in the web is focused around examples of text strings.
You could also make a more complex model, like a 2-gram model or even an RNN.
That's a very simple model but it might do what you want.
The 'hidden' part implies a distinction between some sequence of unobservable states, and some observations that are related to them.
If you are going with HMM I would recommend a package called Pomegranate.
If you need more clarification about part of this, just ask.
The simplest way to proceed in your case would be to calculate a transition matrix, i.e.
To do this, just look at all state pairs, and count to get p(s2 | s1) = p(s1 & s2)/p(s1).
Because there is very little data HMM will probably overfit (depends on the number of states and letters).
It won't know the sequential dependencies, but you are essentially indexing the past states by time, so it may work pretty well.
Can somebody please help me come up with the initial probability matrix and then consider the 20 states to predict the next state?
I am looking something specific to the kind of example I have.
This is equivalent to a 1-gram model that you've probably read about.
I would go with a simple markov chain as it has less parameters and you dont need to tune things like hidden states.
I am new to Markov chains and HMM and I am looking for help in developing a program (in python) that predicts the next state based on 20 previous states (lets say 20 states in last 20 months).
I would also recommend try and using Multinomial model, which can be viewed as 0-memory markov model, maybe your data doesnt have past dependencies.
I have a sequential dataset with 50 customers i.e.
If you know what the state history is, you don't need a 'hidden' Markov model, you just need a Markov model (or some other mechanism).
In your case, you say you have observed the past states for each customer, so you don't necessarily need to infer anything 'hidden'.
Honestly, since you have a fixed amount of history, you can just throw your data into an scikit-learn model or xgboost or something, where each customer's history is the vector of predictors and the next state is the outcome.