With other types of models such as Logistic Regression, it's relatively easy to look at the coefficients and check that they have the expected plus or minus signs- even a mathematically illiterate MBA can understand that.
This brings out a distinction between models that are black boxes because of information that is truly secret (e.g.
They know how neural networks learn, but they do not know what any given neural network has learned.
Writing the test to fit the thing that is being tested, lowering the chances of actually finding anything.
The logic learned by neural networks is notoriously inscrutable.
For example, the min-conflicts algorithm was discovered by analyzing a neural network trained on the N-queens problem.
ML engineers don't know what goes on inside a neural net
Grey box models are mathematical models where part of the equations (mathematical function) comes from physical known laws but the remaining part is assumed general function to compensate for the unexplained part.
Rarely, someone does take the trouble to figure out what a neural network does.
I think the black box concept as used in this way originates from black box testing in software and hardware Quality Assurance.
It's analogous to a conventional computer program written with one letter variable names, no comments, no obvious structure, using obscure mathematics, and all by someone who is now dead.
See: https://en.wikipedia.org/wiki/Mathematical_model#A_priori_information
Black box methods are difficult to explain to the "uninitiated."
Anybody in finance or other fields can grasp the basics of regression or even decision trees.
The point of using machine learning is usually to learn the rules that a programmer or domain expert would not think of.
In the blog posting cited in the question, the discussion is about the fact that the experts who develop machine learning models in finance can't explain to their customers (financiers with no training in machine learning) how the model makes the decisions that it does.
White box models are mathematical models completely built on physical laws and understanding of the system, like for example mechanical motion laws (model of aircraft ..etc)
the coefficients are encoded in a tamper proof FPGA) and models that are open (in the sense that the coefficients are known) but not comprehensible to a particular audience.
It is when you either choose not to / or even can't look into and see the inner working of what you are testing.
Start talking about support vector machine hyperplanes and neural network sigmoid functions and you will lose most audiences
This latter kind of "black box" is problematic because customers want to reassure themselves that the model you've constructed has "face validity."
Black box models refer to any mathematical models whose equations are chosen to be as general and flexible as possible without relying on any physical/scientific laws.
You can step through it in a debugger, but it is still far from clear how it works.
It would be perfectly possible for a skilled signal engineer to peek into the inner workings of a neural network and check which features are being selected for in a particular training sequence.