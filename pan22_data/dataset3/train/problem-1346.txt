where $\sigma_i$ is the $i$-th largest singular value of $A$.
And indeed, one cannot do better than sharing their whole string to compute $f$.
The Hadamard matrix of dimension $2^n\times 2^n$ has $2^n$ singular values that are all equal to $2^{n/2}$.
For a function $f:X_1\times X_2\rightarrow \{-1,1\}$ that we want Alice and Bob to compute, where Alice receives some $x_1\in X_1$ and Bob receives $x_2\in X_2$, let the sign matrix representation of $f$, denoted $A_f$, be given by a $\lvert X_1\rvert \times\lvert X_2\rvert$ matrix where each row corresponds to some element of $X_1$ and each column corresponds to some element of $X_2$, with $f(x_1,x_2)$ in the entry where the row corresponding to $x_1$ intersects with the column corresponding to $x_2$.
There are many more involved arguments in proving lower bounds in deterministic communication complexity that rely on norms.
$$D(f)\geq \log\mathrm{rank}(A)\geq \log\frac{\|A_f\|_{tr}^2}{\lvert X_1\rvert\lvert X_2\rvert}$$
$$\|A\|_{tr}=\sum_{i=1}^{rank(A)}\lvert\sigma_i\rvert$$
Another useful technique you might consider picking up is discrepancy based approaches, although I have only seen this one used in proving lower bounds in randomized settings.
When $X_1$ and $X_2$ are $\mathbb{F}_2^n$ and $f(x,y)=(-1)^{x\cdot y}$, where $x\cdot y$ is the inner product of $x$ and $y$, you can verify that $A_f$ is a Hadamard matrix$^1 $ with dimensions $2^n\times 2^n$.
$^1$ A Hadamard matrix is one where all entries are $\pm 1$ and the rows are pairwise orthogonal.
In addition to the ones you mentioned, a lower bound method in deterministic communication complexity that you can possibly add to your toolkit is norm based approaches as described in chapter 2, section 2.3 of this survey.
Using the lower bound given by the trace norm, and using the fact that $\lvert\mathbb{F}_2^n\rvert=2^n$ tells us that $D(f)$ is lower bounded by
We define the trace norm of a $m\times n$ matrix $A$ as
We invoke a known result (theorem 18 in the linked survey) that