With a distributed representation framework, every little piece of information is simply like a binary indicator (the feature exists or not).
You could use some kind of attention models by chunking sentences into smaller pieces.
[a spherically shaped] [fruit] which [tastes sour] and [sweet] and gets [red] when matured well.
In a perfect setting, where you have infinite sentences (definitions).
At the end of the day if you have a smooth function and your input is continuous then any small change of the input will introduce small change at the output, yet how could we truly extract the knowledge exists in the data.
If you have a model trained on the sentences and learned to project similar sentences near to each other, and assume you learned the word classes by some word2vec like algorithm, you could generalize to new pair even if the sentence and that class target were never paired (never seen in your training data), their respective feature vectors have been related to each other by the mapping function.
To learn p(Y|X) where x consists of the sentence, y is the embedding of some class, so may similar classes share similar sentences.
Maybe each piece is vague by itself and it could not tell you anything about the target yet by combining them together they define useful information, see products of experts