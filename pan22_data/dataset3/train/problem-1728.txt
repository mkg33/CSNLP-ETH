Changing out the CFQ for the anticipatory or deadline I/O schedulers may increase performance, depending your usage.
I know my computer doesn't, but a coworker's does and it made a significant difference.
VMs running WinXP seemed to work fine, but the minute I powered on a Server2008 VM, the performance would noticably drop.
When running everything off my single boot disk, I'd see very noticable performance degradation when running particular VMs.
(I wouldn't bother with USB as the bandwidth just isn't there).
If the host OS and VMDKs are all on one half of the platter, you've cut your seek time in half for most operations (static files are read once and then held in memory - take advantage of this!
Some computers have a virutalization option in the BIOS.
For some reason my setup peaks at 100Mb/s when I know the drive natively is capable of at least 200Mb/s..
The other advantage of using eSATA is that you can get a full-size external enclosure which lowers the cost of the drive significantly and increases your options.
Since you're running on a laptop, you may have to look at getting an eSATA ExpressCard Controller.
For example, you could put a 10k rpm drive in there for some really decent IO, or simply have terrabytes of space which you just couldn't get with a standard laptop configuration.
I was having similar issues on my development laptop and after moving to an eSATA setup, I'm very pleased.
One good way to speed up VMs is to place them on a separate physical disk.
One thing to watch out for though is how your ExpressCard bus is actually implemented in the laptop.
Also, if you can, partition your drive so that the virtual machines will have their own partition as close to the beginning (physically towards the outside of the platter) of the drive as possible, next to parts of your OS that will be written to (/var, swap, /home).
Also, check out these kernel settings to optimize how your RAM is used:
After switching to an ExpressCard/eSATA setup, I was able to run all the VMs without issue.