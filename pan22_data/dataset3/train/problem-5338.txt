Estimating the volume of a convex polytope and the closely related task of sampling from it have applications in private data release.
heres another angle turned up on some online investigation.
the uncertainty (or "error") in the model/estimation is taken as proportional to the volume of the polytope(s).
In some range of parameters, the optimal algorithm for solving this problem has a geometric description, and implementing it involves sampling from a convex polytope.
Also, I don't think they need to analyze polyhedra of dimension 1000 or higher (though I'm not sure about that).
If there are a set of invariants of the program variables, each of which can be represented as a linear inequality on the variables, then conjoining all of these invariants yields a polyhedron.
the Birkoff polytope $B_n$ has many deep theoretical properties & relates to eg to perfect matchings on graphs, but volume calculations of it are very hard even for low $n$ eg as in this study by Beck and Pixton.
Hari Narayanan recentely posted a paper on the arXiv in which he uses estimating the volume of a convex polytope to prove certain results about the Littlewood-Richardson (LR) coefficients.
Roughly, the problem you want to solve is: given a collection of numeric valued queries on a database, come up with answers to those questions that are as close as possible to the real answers, while satisfying differential privacy.
If $s$ is a possible state of the program, then $s$ will be in the interior of the polyhedron (but not necessarily the reverse).
It requires methods to count the number of integer points inside the polyhedron, which isn't the same as the volume of the polyhedron.
The LR coefficients are certain integers in representation theory that have applications in geometric complexity theory, particle physics, and many other fields (see the introduction of the above paper for more references).
That said, this might not be exactly what you are looking for.
a more direct/remarkable TCS connection arises in that a relatively recent paper proposes a measure of graph complexity based on Birkoff polytope calculations.
Birkhoff polytopes, heat kernels and graph complexity by Francisco Escolano, Edwin R. Hancock, Miguel A. Lozano, 2008
: N-Dimensional Volume Estimation of Convex Bodies: Algorithms and Applications by Sharma, Prasanna, Aswal for an example/case study in economic forecasting, ie supply chain management.
In computer security, work on quantitative information flow has applied these methods to estimate the amount of confidential information that might be leaked by a particular program.
Here we build a polyhedron representing possible states of the program at a particular point in its execution, and then we want to estimate something about the number of possible states (this is related to the amount of information released).
basically the idea is that a polytope can model a "future scenario" of parameters of a supply chain management configuration.
Thus, at a certain point in the analysis, they end up trying to count the number of integer points contained inside the polyhedron.
Again, probably not exactly what you wanted, but an interesting connection nonetheless.
Polyhedra are widely used in program analysis as a means of representing (an overapproximation of) set of all possible states, where a state records the value of each variable in the program.