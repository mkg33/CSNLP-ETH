feature selection involves several approaches just like methods for machine learning.
Idea is to keep most relevant but not redundant feature for predictive model that can yield optimal accuracy.
This will tend to be more stable...and you should expect different ranking everytime.
It is also possible, but this will lead to more complex model.
If you actually need to have the fewer features possible while optimizing prediction accuracy, you can select the lowest number of features that achieves the lowest error... and, if you have different cases with very similar errors, then pick a threshold, observe the top cases whose pairwise difference of errors is lower than the threshold, and select one (for example the one with lower number of features - since the errors are marginally the same -).
Now, you want to select the best number of features.
When you calculate the variable importance of features, you are taking into account the contribution of all the the features at the same time.
The method you are using might not be the most stable approach.
Generally there are three classes of feature selection algorithms.
Once you select a subset of features and build a new model, you will get a different representation or modelling of the problem (which does not take into account the other features - informative or not -).
This will also depend from your problem and the characteristics or conditions you need to fulfill.
If the standard deviation is high, then the selected subset of features is not stable, and will tend to vary plenty when testing with unseen data.
You need to remove both redundant and irrelevant features from your data set.
Univariate feature selection does not necessarily get optimal model accuracy when features are inter-dependent and not mutually exclusive.
There is also a package called mRMRe to do feature selection based on maximum relevance, minimal redundancy.
I have applied the methodology described above and I found that adding more features decreased the accuracy up until a point after which it increases"
In your case, I can not see which method you are using for feature selection but assuming that you are not taking account of multivariate nature of feature dependency.
Beyond the actual error (or accuracy) the model is giving you with each subset, you should consider to build each model through a cross-validation procedure and take into account both the mean error of the folds, and the standard deviation of these errors.
I recommend you to look at the minimum Redundancy Maximum Relevance Feature Selection(MRMR) algorithm.
For optimal feature selection, I often is Caret package in R language where one may do feature selection using recursive feature elimination (RFE) among several other approaches.
From philosophical point of view, set of optimal features is analogous to a quote by Aristotle: "The whole is greater than the sum of its parts"!
You should not expect a specific behavior (increase and then decrease of accuracy) while you select subset of features, since this will be totally dependent on the problem (and each model)
It can be seen that there are irrelevant and redundant features in your data set.
Here is a great article in details of introduction to feature selection.
It is a very popular and powerful filter before your train the model.
You should consider trying something like recursive feature elimination (RFE), a wrapper method where you build the classifier, rank all the features, remove the worst and rebuild the model on the remaining features.
Say you have N features, likely reason that your model accuracy drops after n top feature(s) but improves by adding n+k (where n < k < N when features are in descending order based on information gain) is due to inter-dependency (more relevance and less redundancy) of top n and k features.
This is important to evaluate the expected generalization capabilities of the model, and could be helpful for deciding between models (built with different subsets).