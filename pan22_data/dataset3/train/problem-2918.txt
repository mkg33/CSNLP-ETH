My first step would be to do a memory test or check the bad memory log (if your server supports it).
Has that been consistent every time it's paniced and locked up?
If so I would ask if the problems started around the time you setup Nagios.
Google or Centos forums/list are likely to be you best bet.
Without a crsah dump it's going to be difficult to be sure, so you should look into getting that configured.
However, since the machine has crashed a few times in the same day, that suggests a faulty RAM chip.
Also, are the temperatures in the room nice and cool?
My first guess is that Nagios has a small memory leak and after months of running ran out of RAM or swap.
It doesn't work quite as well but may be able to pick up some memory errors if they are there.
I would recommend using memtest86 to do a thorough check of the ram.
If it does then you have found the culprit and need to look closer to see what's wrong with Nagios.
This looks a possibility based on the little you have from the screen shot.
Just a quick glance it looks like the process that paniced was Nagios.
If you cannot use memtest86 because the machine is remotely located, you may want to try a userspace tool - memtester, instead.
If that's the case then you might want to try shutting Nagios down and see if the server returns to be stable.