It doesn't say that at the end which value determines its importance(i.e mean of a feature for every training example.
If you can explain or give a useful resource I would be appreciated.
Most of websites deal with its framework application anyways.
In general I didn't understand anything about how does SHAP values helps and how it helps us determine importance of features from the first paper.
First the first article uses SHAP values which defined as "Shapley values of a conditional expectation function of the original model" at the second article it just uses shapley values.
At the second article he has a very simple decision tree and calculates shapely value for a feature for a specific training example.
I've read http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf and https://medium.com/@gabrieltseng/interpreting-complex-models-with-shap-values-1c187db6ec83 which is like a summary of the first link.
I read several academic papers and website articles but I couldn't address to my question.