The only advantage I can think of, though, is that partitioning the drive is a more standard way of setting this up.
I must emphasize though, that "standard" may differ from "supported".
I add lots of additional VMDK's to existing virtual machines, and even with the flexibility that comes with this type of storage, I use the standard partitioning arrangement for the sake of consistency and compatibility.
This is a general question to optimize performance, reliability, and consistency.
Even if you're planning to use the entire disk, make the device /dev/sdb1.
I know that both of these methods work, I'm just wondering if there are (dis)advantages to one over the other.
I'd strongly prefer that all drives be partitioned, and thus configured and used as "/dev/sdb1"
there is no real difference between partitioning drive vs un-partitioned as far as I know.
To use the "standard way" is the best thing to do.
So generally when using something new - take a close look at the "standard" way to use it.
i think now days a lot of people prefer to use some sort of volume managers such as LVM or similar which gives you a lot of flexibility in terms of adding disks almost seamlessly but the draw back is cpu cycles.
I can think of several applications that would not handle that gracefully.
An accident of decision making resulted in us having a number of systems with this setup using unpartioned "/dev/sdb"
The thing I'm interested in is partitioning the drive vs leaving it unpartitioned
Using non-standard-ways always gives you problems and/or headaches later on - I speak from over 10 years of experience here.
Suppose you have a third-party software package that expects /dev/sd[x][y]... Would it break by not having a partition number?
in terms of performance make sure to separate your databases vs your logs, that would give you a big boost for performance.