The best metric for that is Peak Commit Charge, but it's not exposed via Performance Counters.
If it's the disk, check the committed bytes to see whether the disk activity could have been due to a low RAM condition.
Before you do that, this is where a replica of your production (your testing environment) should be bench-marked,tortured,killed and then post-mortem'ed , so that you'll never have to experience that on production.
Performance can mean a bazillion different things.
Nagios) with some constant monitoring (e.g cacti,munin).
If you don't know what's causing your performance issues, you can start by isolating  your services and debugging them one by one.
Are you running a database, check your IOPS, and so on.
You set the bar to what bad or good performance is and that depends on your services and your SLA's.
Almost all of them , but you should probably start with CPU %,Private working sets and IOPS.
Unfortunately this won't detect transient large RAM demands unless you log with a very small interval.
MS has a very good document about performance counters
If the server is slow, check these values and see which one is the problem.
Performance counters do an excellent job but they only offer the latter.
Generally you need to have at least the following triplet: