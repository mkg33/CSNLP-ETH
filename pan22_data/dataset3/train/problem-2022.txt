All such libraries either have a function that counts solutions fast or, at least, they make it easy to write such a function.
You may also find a list of tools for approximate model counting and knowledge compilation (the task of transforming the CNF into a hopefully succinct data structure that often supports polynomial time model counting).
Here is one called tensorCSP and based on a tool called tensor networks.
One option is to use a BDD library, such as JavaBDD.
I imagine that most SAT solvers have this ability.
In case your input is in CNF, a simple heuristic that speeds up the construction of the BDD is the following.
You can do this with SAT4J, simply by iterating over all models: http://www.sat4j.org/howto.php#models.
The website BeyondNP contains a good inventory of the existing tools to solve #SAT (and other related hard problems on CNF formulas).
Second, pop two BDDs, compute AND between them and push the result to the priority queue.
The disadvantage, however, is that constructing the BDD will be slow in many cases and may require much memory.
First, build a small BDD for each clause and put them into a priority queue whose root is the smallest BDD.
You may also find a list of tools for preprocessing CNF formulas which may be useful to improve the performances of model counters and various benchmarks.
Here's the idea: Since computing AND between BDDs of size $m$ and $n$ takes $O(mn)$ in theory but $\sim m+n$ in practice, minimizing the runtime is the same as finding a Huffman code.