I think one of the first issues you have to address is whether you want the patrolling behavior to be "optimum" patrolling or "lifelike" patrolling.
The basic idea of steering behaviors is to use simple forces that combine to produce improvisational navigation around an environment.
In your case I think you'd want to combine the following steering behaviors:
For example, if an agent detects an invader, the separation weighting should drop down.
I think you'd want to play around with the relative weighting dynamically.
There are quite a few resources online about how to implement "boids" that follow the behavior patterns described.
Lifelike:  The agents move about and attempt to distribute themselves as equally as possible, but each only have access to data local to their perspective.
I'm just making up these words, but what I mean is:
(In other words, they only need to spread out when they're hunting, not when they find someone.)
I think if you played around with the weights for the above four patterns, you'd have something pretty close to what you're looking for.
I'm going to focus on the second approach, which I think you can solve using weighted blending of various steering patterns from Craig Reynolds' Steering Behaviors For Autonomous Characters.
I recommend the open-source implementation opensteer.
Optimum:  The agents move about in a manner that perfectly distributes their coverage area for the system as a whole.