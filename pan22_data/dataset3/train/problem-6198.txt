Alternatively, you can train a model with all the output classes you have in your label set and another output for "other".
What'd be the best strategy to train a CNN able to tell the missing labels on the dataset?
You can then use output nodes for the labels which you have available to you, and you can get the predictions for the other images from the pre-trained model which are usually trained for thousands of different classes.
I'm able to code python and managed to use keras to train on mnist dataset on gpu.
I have a large database of images that are only partially labeled for multiple, non-exclusive characteristics or objects present on them.
Start with a model that has already been trained with a wider dataset such as the ones presented here.
For instance, an underwater scene might feature the labels water, swimsuit and fish on it.
Problem is it's only partially labeled, meaning that the fact the label cat is absent doesn't mean there's no cat on the image.
From there you can train the model with your specific dataset.
Then when an output node is selected you can pass that same input to the pre-trained model which was trained with your data as well.
The image base has 230 thousand images on it, but given that multiple labels are possible, it's hard to tell the ratio of images that are fully labeled.