Besides the stuff that is mentioned you should use some kind of monitoring tool (Nagios or whatever floats your boat) to alert you of updates.
Generally speaking, updates are usually relatively painless for server distros.
If things do go wrong there are fewer candidates to inspect.
Although it's moderately rare, they do occasionally make mistakes and break compatibility between minor package versions.
Sometimes, libraries (lets call it libfoo for this example) change their API, which breaks programs that we wrote / installed ourselves.
I personally turn off automatic updates and do not regularly perform any sort of updating of packages on servers in my environments, unless: (a) there is an important CERT advisory for one of packages on my system; (b) I need to upgrade individual packages for specific reasons; (c) OS or packages are reaching end-of-cycle, they won't be supported any more and we need to continue having support.
If you only have two servers the process should be much simpler.
I do a dry run (first) to see what is going to be updated.
Although I do not think doing an "apt-get update/upgrade" is your best bet.
You may however have problems if people have done odd things to the system or you add additional package sources.
Updating regularly tends to be best though it can be a bit of a balancing act.
I would monitor patches for the software you are running, and make decisions based on the fixes in those releases on when to upgrade.
As far as how often goes: As soon as there's an update available!
However, for very large numbers of servers that might become impractical.
I also check to see that we're not jumping to an intermediate version of some public service, ie apache, etc.
Dry run is a standard practice, in fact, most package managers will ask you before proceeding.
If you are a system administrator, you should be pulling RSS feeds from sites like Secunia, which should let  you know way ahead of time if your distro is going to be pushing some patches.
Some of these can be overkill to varying degrees for small setups but should be kept in mind.
I'd rather stay a year behind and not encounter random breakage, unless the update is critical.
This is because they nearly always only stick to bug fixes and security updates.
If some critical library is updated, I grab the source and try rebuilding our stuff against it prior to updating.
Unfortunately, the task of knowing what is broken falls on you, not your distro package manager, especially if your systems support programmers.
Packages are also slightly better at updating in smaller steps, as generally when the programmer updates they're looking at going from the last version to the next, whether they'll give any attention beyond the last version can vary, though this tends to matter mostly for software that's rapidly evolving.
I've been doing things like this for going on 14 years and it works well.
Frequent updates means less in one go and less to go wrong at once.
Manual updates are best as mentioned here in the sense that you can see what's happening.
My reasoning is that upgrading without knowing what's being changed or why leaves too much room for something breaking.
Since you have a test server, obviously, always test the update before applying them.
Where I work we have a pretty extensive process that involves using software called PatchLink to notify us of the most important security related updates, and we apply them after testing, on a package by package basis.