The vertical axis is pitch and the horizontal axis is time.
GPU will make the project easier, but is not a requirement.
An sample X to be classified can be convolved, in a sense, with a known sample K. It can be transposed up or down (vertical shifting) or moved left or right in time (or stretched in time, or other alterations) and each transposition would be superimposed on the G or B sample.
There are two high level approaches (Approach 2 was a better fit for a music-classification problem that I worked on) :
This paper is a good intro to the approach : https://arxiv.org/ftp/arxiv/papers/1712/1712.02898.pdf
"Good" music is subjective of course, but this program would work with G and B samples that I hand-optimized according to my own tastes.
I'm not too familiar with convolution but I think that overlapping pixels are multiplied and the sum of all is taken.
The transposition with the brightest result pixel is a good indication of how similar X is to the K sample: it's magnitude becomes the measure of similarity.
Musical fragments can be represented by image-like matrices of pixels.
Can I get some idea whether there is a name for this kind of operation, and where to look for efficient implementations of it?
Couple of articles on this : https://www.codementor.io/vishnu_ks/audio-classification-using-image-classification-techniques-hx63anbx1 , https://medium.com/datadriveninvestor/audio-and-image-features-used-for-cnn-4f307defcc2f
The idea now is to take a fragment of music, X, and compare it to known good sample fragments G_1, G_2, ... etc.
Good music is then music that resembles at least one of the G's, while resembling none of the B's.
A bright match to a known bad fragment is what makes music bad.
If a note of pitch P_1 occurs between times T_beg and T_end, then that's like drawing a little line between (T_beg, P_1) and (T_end, P_1).
I'd like to perform these computations with NumPy or a similar language optimized for matrix or image computations.
This would be part of a larger program that searches for larger good phrases and whole pieces.
A fragment that has strong similarity to both G's and B's is probably bad: The B's have veto power.
I have in mind a program for analyzing short fragments of music, categorizing them as "good" or "bad".
Then compare it to known bad fragments B_1, B_2, B_3, .. etc.
Raw audio  + recurrent networks : https://deepmind.com/blog/wavenet-generative-model-raw-audio/  ,  https://arxiv.org/pdf/1606.04930.pdf , https://arxiv.org/pdf/1612.04928.pdf , https://gist.github.com/naotokui/12df40fa0ea315de53391ddc3e9dc0b9
It just means the real pattern isn't found in those locations.
A preponderance of dark pixels doesn't make music bad.