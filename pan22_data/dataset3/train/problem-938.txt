Time and environment would also have to be taken into account, as in a cold environment objects shed heat faster than in a warm environment.
Raytracers work because beams of light either pass through, are reflected by, or is absorbed by surfaces with immediate identifiable effects, and what the eye sees is the conglomeration of these effects.
Effectively you would have to program and simulate an entire environment and then "pick a time" that you wanted to take a picture of.
It appears that this kind of question has been asked before for Blender, LuxRender and you can apparently "simulate" fake infra red using Photoshop but all seem to reply with the response of "we designed it to work with visible light".
There is also the fact that creatures  actually generate heat and objects generate heat through friction when they move and heat can be conducted between objects.
A raytracer takes advantage of the fact that the effects within the visible spectrum are rather simple, an object either reflects or absorbs light in particular wavelengths and what you see is the remaining colour spectrum.
I would expect something similar to be the case with ultraviolet light.
They cause the object to warm up and thus appear slightly "warmer" in the infra-red spectrum.
Infra-red on the other hand can work in a similar fashion, some is absorbed and reflected by certain surfaces, but those absorptions have a physical effect.
To realistically render in infrared would require a massive amount of work as it would require accurate simulation of a physical object at the material level, along with internal and external heat sources.
I'm not saying an infra-red raytracer/renderer is impossible, just that it would require a lot or work.