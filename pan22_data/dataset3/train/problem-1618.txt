So if you have a 100MB Word file where a couple of pages get changed, it will only copy across the changes not the full 100MB so saving bandwidth.
At any later date, you can also then decide to expand the backup to CrashPlan's own servers at a very low cost.
You can then designate some of those machines as "hosts" that others can backup to.
So far the only idea I've come up with is use FTP and assign each user their own FTP account per computer.
For example CrashPlan has a free, basic, offering that allows you to install it on as many machines as you like.
I have a few offices of businesses I need to backup remotely and I was wondering what would be my best options as far as doing that to ensure no one can access each other files.
So lets say you have 10 PC's that you want to back up.
It is also able to de-duplicate files to save space.
If you are not experienced with this kind of thing, I strongly recommend the use of a utility that will automate everything.
Each of those three are then set up to receive backups from ALL 10 PC's (yes, including the local PC) - now you have 3 lots of secure backups for all PC's, the minimum you should be looking for.
The first thing to understand is what kind of backup you want - just some data on a server, data on a set of workstations or a total backup of everything so that you can restore whole machines direct from the backups.
Crashplan also maintains old versions of files, users can restore their own files if needed and, importantly, it only backs up changes to files not the whole file.
The backups can be fully encrypted and the whole application password protected.
Three of them have either plenty of spare disk space or you buy an external drive for them.
Using FTP is not a good idea for backup since it is neither secure nor robust.