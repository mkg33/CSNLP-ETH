I would tend to characterize this phenomena in something like a HDDT to mean the most efficient tree that makes no spurious decision based on available data, and avoiding all instances of decisions that may otherwise have been made on multiple data points without understanding that they were correlated.
Of course, if the features that are correlated are not super informative in the first place, the algorithm may not suffer much.
There are three main reasons why you would remove correlated features:
Correlated features in general don't improve models (although it depends on the specifics of the problem like the number of variables and the degree of correlation), but they affect specific models in different ways and to varying extents:
If you sample out of the 3 features, you have 2/3 chance to get a "good" feature, whereas if you remove B for instance, this chance drops to 1/2
Due to the curse of dimensionality, less features usually mean high improvement in terms of speed.
If your model is not "that much" worse with less features, then you should probably use less features.
Some algorithms like Naive Bayes actually directly benefit from "positive" correlated features.
Imagine having 3 features A, B, and C. A and B are highly correlated to the target and to each other, and C isn't at all.
Making a decision should be done on the minimum necessary variables to do so.
The concept of minimum description length makes this more precise.
(Though remember that wrapper methods are expensive and may lead to overfitting)
And others like random forest may indirectly benefit from them.
It will remove redundant features only if they do not contribute directly to the performance.
This is, as mentioned above, the formalization of Occam's razor with minimum description length above.
If your model needs to be interpretable, you might be forced to make it simpler.
Also, some algorithms like decision trees have feature selection embedded in them.
If speed is not an issue, perhaps don't remove these features right away (see next point)
So moral of the story, removing these features might be necessary due to speed, but remember that you might make your algorithm worse in the process.
If they are useful like in naive bayes, they will be kept.
More generally, this can be viewed as a special case of Occam's razor.
If you have correlated features but they are also correlated to the target, you want to keep them.
A simpler model is preferable, and, in some sense, a model with fewer features is simpler.
(Assuming you are talking about supervised learning)
Correlated features will not always worsen your model, but they will not always improve it either.
A good way to deal with this is to use a wrapper method for feature selection.
You can view features as hints to make a good guess, if you have two hints that are essentially the same, but they are good hints, it may be wise to keep them.