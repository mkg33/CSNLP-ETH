I myself just installed for a smaller customer a data center solution involving a few Cisco UCS C220 M3 servers with a Netapp FAS2240, and I used a stack of 3750s to provide multi-chassis etherchannel redundancy to each new device as well as all their old servers during the transition.
Mounting the switches where the switch ports face the back of the servers creates a situation where the switch fans blow in the wrong direction.
The same customer has two other 3750 stacks in the same DC for other networks and these are all clean.
However I very often see these switches sitting in DCs.
This overheats the switch which makes it more likely to fail / need replacement.
The 6500 had it's problems early on in it's lifecycle, and now that it's been out for years and years it's not so bad.
TL;DR: It really depends on the type of traffic you are going to be putting through the stack and where your bottlenecks are.
Lots of folks tend to use them as they are generally 1Gb and L3 capable.
I recommend looking at what you're going to be throwing at it, and if the performance metrics hold up, then make sure you monitor their performance with vigilance.
Unless you can put a dollar value on the problems caused by having 3560's/3750's in a DC, I doubt you'd be able to convince management to replace them outside of a regular product refresh cycle.
In small data centers, the 3750 stack represents a relatively low-cost option to get the port density without the cost of a chassis-based switch.
Honestly, the most common way that I've seen the 3750's hit the curb, was when the core switches were upgraded to Nexus 7k's.
3560/3750s have small buffers and make good wiring closet switches.
The power supplies / fans within 3560 / 3750 are not hot swappable / once the switch is mounted and the inevitable failure of these devices occurs all servers must be unplugged from the 3560/3750 while it is unmounted and replaced with the RMA.
Also the fan direction on the 3560s / 3750s become a problem with hot aisle / cold aisle and other cooling setups.
Combine that with the fact that upgrading a stack was not the most intuitive process (it's improved since then), the 3750 really got a bad reputation that has stuck ever since.
I quite often hear people saying they removed their 3750s as soon as they could, but I've yet to hear an actual failure scenario that could be used to let management know to get them out.
Even though the 3750's don't have the largest buffers, in most people's minds, they work "well enough" in most enterprise DC environments.
Probably the same as any other switch that's been around for this long.
Usually (but not always) part of that refresh is to move TOR to Nexus 2000 FEXs or Nexus 5000s.
I've got a customer that has deployed them as a SAN switch stack (using 3750X's) with the SAN connected at 10Gbit and then their ESX hosts connected at Gbit (or multiple Gbit's using LAG) and the amount of output drops is astronomical no matter how you try and tune the buffers.
In the early days of the 3750, especially the stacking technology that was released right before 2010 or so, there were a lot of problems with switch failures causing the stack to fail in a not-so-graceful fashion.
Is there a way to prove just how bad they are in DC deployments?