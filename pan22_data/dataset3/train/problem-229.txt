if you buy western digitals, make sure to get TLER-enabled drives)
Will the Thecus N8800 or the QNAP TS-809U provide sufficient enough performance to host multiple Virtual Machines?
Should you use Thecus NAS, you should also upgrade firmware with the latest version, as current one still has some issues with RAM consumption.
Don't buy a cheap WSS2003 NAS, they suck horribly too and perform quite poorly.
I'm looking for a low-cost NAS/SAN/iSCSI target shelf to host VM's in a production real-world environment.
From personal experience so far, I can report over 1gbit/s effective bandwidth.
Dual PSUs and NICs, decent amount of storage space, reasonable processing ability.
Outside of that, performance-wise, they will probably meet your needs.
With respect to how many VM's you can run from a single NAS, there is no magic answer to this question.
It will depend upon a number of factors, including the NAS configuration and your client workload profile, both of which can vary significantly from deployment to deployement.
With 30 to 40 VMs, as good as they are they're quite overloaded with only eight 1TB drives.
Frankly these NAS are nice to share and store office documents, but forget them for anything performance related.
SATA disks are not ideal for longevity, but throughput-wise they should be fine (just make sure to buy enterprise-grade drives designed to work with your intended workloads (i.e.
Or am I better off spending more on a DAS Fiberchannel shelf and plugging it into a DL380 with Openfiler?
I have also just installed a Thecus n16000V NAS with 11 3TB SAS disks in a RAID 6 configuration.
I myself built some NASes for Xen storage (building NAS is my job).
The best way to determine the best configuration is via workload profiling determined via performance testing, upon which you can make reasonable sizing and capacity planning estimates.
If you want a NAS with good performance, go for a well built server platform with a NAS OS like Openfiler, a good RAID card and fast drives.
Other NAS devices from Qnap and Synology are also good.
We are serving more than 100 VMs on the HP EVA FC SAN.
For the specific models you've listed, I cannot find any information about the presence of read and write caches, or even the model names for the array controllers that are used in those devices.
Which is quite good for this kind of storage device.
The latter is price wise much cheaper than a real FC based SAN, but performance seems to be quite good so far.
Currently I have some Samba shares and some iSCSI volumes.
The NAS machines are dual CPU Opteron, 8GB RAM, 3Ware9650, 8x1TB RAID 6+ spare, specially optimized Debian system, iscsi enterprise target, DRBD for High Availability.
You can install this storage OS on any x86 hardware, which will keep your costs low.
If you are looking to build some low cost, reliable storage for your XenServer cluster, take a look at NexentaStor.
An iSCSI storage solution with no read/write cache will suffer severe performance penalties when serving VM disks.
Think, like 1/10th the throughput you would otherwise be getting with a 512Mb battery-backed cache or flash cache.