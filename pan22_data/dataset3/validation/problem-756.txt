For example, it may be difficult to do a partial restore, and extra steps are required to migrate to a different file system type.
These tools are designed to detect changes to file metadata and contents, so they create an index of this information.
You could use a system integrity tool like tripwire, AIDE, etc.
After the restore I learned, that the file creation date, ownership and permissions are also crucial to keep track of.
That way the metadata, and all related configuration would be saved.
I had a data backup and a recovered btrfs filesystem and needed to decide whether to restore the backup or to keep the recovered data.
File metadata preserved includes timestamps and UNIX permissions.
For critical server please use a solution that do a entire machine backup, not just a file copy.
I've looked into git-annex which looks promising and I've seen people use updatedb to keep track of files (also metdadata?)
Restored objects should not only have correct metadata, but contain good data.
Having onsite and offsite backups is one pillar of such a concept.
I am advocating to implement a solid backup concept before facing data loss.
For any of these, you can additionally compute and store your favorite hash.
As I was lacking checksums of the files, I decided to restore from offsite backup.
However I learned that the metadata is sometimes as valueable as the actual file contents.
However to improve my backup plan, I want to store the metadata of my files.
Whatever backup software used, define the recovery point objective then test restores.
tar archives contain permission and timestamp metadata, but the sha256 checksum you want.
A repository can be checked to verify its consistency.
If a virtual machine, some software just plain copy the whole hypervisor data file.
However, this possibly has operational challenges.
The first action was to sha256sum and stat the data and save it to disk.
Luckily, my data is structured and I could set defaults per script.
An image of the entire block device contains the original file metadata.
How could you index and store the metadata of the files on Linux in an easier and more efficient way?