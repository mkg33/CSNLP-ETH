Is there any guarantee that they would arrive at the web server in 3s intervals?
The only thing that would cause a delay is congestion on the network, although those delays would be in the milliseconds.
On the other hand if some resource (client CPU, server CPU, server storage, network bandwidth, server maxclients etc) is saturated then the delays may be much larger and more variable.
How much things actually get delayed will depend heavilly on system load.
Your Web server is actually an application running on a server, so it's more complicated than just the Ethernet and/or IP networking layer.
This will help avoid piling additional load onto an already overloaded server.
Unless you are doing other data intensive things on your private network, you are unlikely to notice any delays.
There are lots of opportunities for things to get delayed both within the client and server machines and in the network.
A better architecture would be to use Comet, or XHR long polling.
My program sends requests to a web server once every 3s.
You might want to redesign your client application so that instead of sending a request every 3 seconds it sends a request 3 seconds after the last request completed.
If load is light then delays are likely to be negligable.
The servers CPU/memory utilization may also be a factor.
The web server is running on a machine on the same private network as the program (they are in the same room).
Is it normal for, say, 1 in 100 requests to arrive within under 0.5s of each other?
Practically speaking probably but not necessarily.
It's possible that congestion will cause packet drops, and the retransmission would  cause noticeable delays.