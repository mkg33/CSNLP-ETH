This gives me around 96%  - 97% accuracy based on random sampling.
What is happening is the model got trained looking at class 8 samples most of the time and it will blindly predict class 8 as outcome.
You need to definitely follow undersampling of class 8 or oversampling of other classes (SMOTE).
Based on the histogram, you have 16500 samples of class 8 and 500 of other classes.
I am sorry to ask for partial opinion based question.
It is hard to answer this question without more information about your model, dataset and the affects of its outcome.
Now getting an accuracy of 95% using ML model doesnt give additional confidence.
Do I have to rework by resample and balance the skewness and train & test again?
I have incidents VS normal operation of my working environment.
The first question is very broad, 95% accuracy doesn't say a lot, there are tasks where 99% is standard and there are tasks where an accuracy of 60% is amazing.
For optimal performance, you should retrain your model from scratch.
So without any model, it is safe to always blindly predict the output as class 8.
Basically you should ask yourself if it is good enough for your task.
Note for future reference, it is better to present the results in a confusion matrix, than just the final classification (gives more data, especially when we talk about a skewed dataset).
Is it common practice among data scientist to accept this prediction?
Regarding the second question, I would suggest to use a weighted loss function, where mistakes on the rarer classes have a higher price (it encourages the model to classify them correctly).