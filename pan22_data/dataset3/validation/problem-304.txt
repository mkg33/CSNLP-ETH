Values chosen at the node level to split the data are determined to minimize the Gini Impurity index which represents the entropy or the chaos in your data.
After doing some EDA , you notice that between 20-40 , both your classes , again let's assume its binary classification , are similarly present.
Meanwhile, below the 56, you have equally distributed classes across that range.
It chooses the value that separates your classes best.
In simpler terms, you tree when splitting a population in a node, will try to make the leaves the purest they can be, and by purest, i mean containing only one class.
and Exactly at the age 56 and going up, you get 4 ones and zero.
You tree when considering which value to split the node on will calculate the Information Gain or Gini Impurity, and then splits your population across 2 leafs, where the entropy is minimized in those 2 leafs as much as possible.
Again you will have a leaf with 4 ones a zero and the other will have, lets say, 3 zeros and 2 ones.
You're predicting if the person has a certain disease.