It's highly optimised for Intel CPU architecture and supports distributed computations.
Again, C/C++ is useful to implement time critical algorithms as python extensions.
From personal experience, there are so many tools out there for data scientist that you will always feel like you constantly need to be learning.
Wether you need them or will need them depend on the type of job or projects you have.
If you prefer the more functional-programming side of R, learn Scala before you get into too many procedural bad habits coding with C.
If you want to go beyond R, I'd recommend learning python.
The best way to learn is to take on a work project using other tools that you are not comfortable with.
Do the opposite: learn C/C++ to write R extensions.
If I were you, I would learn Python before C.  It is more used in the community than C.  But learning C is not a waste of your time.
Use C/C++ only for the performance critical sections of your new algorithms, use R to build your analysis, import data, make plots etc.
I would be keen to understand why you would need another language (apart form Python) if your goal is " but what about advanced regression, Machine Learning, text mining and other more advanced statistical operations".
You can add Python or Matlab to things to learn if you want and keep adding.
It's a good tool to have but in the ~20 years since Java came out, I've rarely coded C.
R is one of the key tool for data scientist, what ever you do don't stop using it.
Lastly learn to use Hadley Wickham's libraries - they'll save you a lot of time doing data manipulation.
There are many libraries available such as scikit-learn for machine learning algorithms or PyBrain for building Neural Networks etc.
(and use pylab/matplotlib for plotting and iPython notebooks to develop your analyses).
There are some C++ tools for statistics and data science like ROOT https://root.cern.ch/drupal/ , BAT https://www.mppmu.mpg.de/bat/ , boost  , or OpenCV