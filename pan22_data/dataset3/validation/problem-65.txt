If you load up a single core on this machine, it will boost the clock speed of that core, thereby increasing the power consumption of the CPU, so that will make for a huge difference.
One could go on and on about the different types of loads, and anyone who tries to benchmark to get an answer will end up (probably inadvertently) making apples-to-oranges comparisons which don't apply in other use cases.
If you've got an energy bill over $1000 / month for your computers then it MIGHT be worth a worry or two.
This might still generate less heat, but it will definitely take longer to complete your task compared to running it on a single core.
On the other hand, if your code is not parallelizable, then running it on multiple cores is less efficient because of the number of cache misses that will occur due to dependencies across the code.
Since the time to process the loads will necessarily be different depending on how the loads are balanced, you must integrate the result over time to find the net amount of energy used to complete the jobs in order to arrive at a credible result.
Most people will probably quote efficiency in terms of power.
Anyway, the problem has too many variables to really answer.
On my desk I have one of these new-fangled Core i7-980x 6-core TurboBoost enabled CPUs.
Keep in mind that the work that you have to do with one core will necessarily be different than the work you do with multiple cores.
Fun to talk about - but if you've got a serious problem the best answer is : try some different things and see what works.
IMO this question is simply unanswerable in the general case.
Otherwise you can't save enough to make the problem worth solving.
The cores will run at lower loads releasing less heat than a single core that is pushed to it's limit.
Are you asking about time efficiency or energy efficiency?
This CPU as well as other, more modern CPUs can partially de-power inactive cores, increasing the power savings.
If it's the case that you can spread the load out onto multiple cores, you'll find that a lot of extra time will be spent on the single core performing expensive context switches, and your performance will suffer.
The answer to your question is twofold: If you are running highly vectorizable, parallel code, then balancing the load over multiple cores is always more efficient.