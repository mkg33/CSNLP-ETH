Only when I looked at the size of the files did I realize it was a Unicode Vs ASCII problem;  the powershell CSV was twice as large.
You can define a bunch of arguments in a Hashtable, and then use it as the parameters of a function.
PS C:> get-service | where {$_.status -eq "running"}
I was using output redirection:   Script.ps1 > outfile.csv
My powershell-created CSV file didn't work, where my hand-written test CSV file worked fine, even though the two files diff'ed  identically.
Force Powershell functions to really return an array, even an empty array.
Due to the way the @() syntax is implemented, functions may not always return an array as expected, e.g.
Moving mine to an answer so I don't feel bad making this a commwiki.
Access any .net classes by using Add-Type -Assembly with the assembly name, or Add-Type -Path with the dll path, and then using syntax like [Namespace.Dotted.ClassName+NestedClass]::StaticMethod() to create a New-Object Namespace.Dotted.ClassName or invoke static methods/fields on types.
If you are testing code with set-StrictMode -On set, you'll get an PropertyNotFoundStrict error instead when trying to reference the .count property:
the following code will return a $null and NOT an empty array.
Simply prepending a , to the @() will bypass the "syntactic sugar" and you'll have an actual array returned, even if it's empty:
Piping my output to | Out-File -format ASCII -name outfile.csv  instead of the cheap & cheerful STDOUT redirection solved the problem.
This is more of a non-obvious hassle, but I once wrote a script to produce a CSV file as input for an older executable, ofiller.exe, which is used with Checkpoint firewalls.