But I am unsure of how efficiently would that perform with the indexes and scans..
To tackle the situation, there are a few possibilities I am experimenting, but my doubt is on which architecture should I use to perform a very efficient "approximated join" - these tables are partitioned, sub-partitioned and each sub part may contain billions of records... (although I have a reasonable amount of resources).
This is just an example, I am not stuck to any sort of architecture.
For once, I thought of storing the unique sencond of the event (i.e.
Thus the join has to behave sort of table_a.id1 = table_b.id1 and table_a.id2 = table_b.id2 and table_a.evnt_time ~ table_b.evnt_time, where:
I have to perform a join between table_a and table_b, using three fields as key being one of them the date of the event, say, both tables have id1, id2 and evnt_time for eache record.
second it happened since julian calendar) on both sides so the real join (give a "~(2)") could simply look like:
As it happens though, the evnt_time can be displaced in a few seconds between these tables.