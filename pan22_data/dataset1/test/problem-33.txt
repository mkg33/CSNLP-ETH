Big, constantly changing files as the one backing relational databases are not good candidate for this kind of continuous backup. I strongly advise you to dump your databases (with the relevant utility) and then to upload the dumps on Google Drive.
Also, pay attention that Google Drive does not automatically empty the trash folder. This means that if you rotate your local dumps, deleting the old ones, they will continue to use space on your Google Drive account (in the Trash). So you will need to periodically empty your Trash folder, in a manual or programmatical manner.
I am currently trying to define my backup strategy for my AWS EC2 server. I already use Google Drive to backup my apache root folder. This also automatically doubles as a deployment strategy since the drive folder is linked to my local repo on my home PC.
I was wondering if I could also include the database data directory and have it synced with Google Drive? Or should I rather stick with conventional SQL dumps for backup?