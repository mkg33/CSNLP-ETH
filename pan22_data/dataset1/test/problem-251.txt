The number of channels in your RAID card and how fast they run sets the upper limit for how fast you can access your storage.
How many disks per channel you need to provide that storage depends on what kind of I/O this server will be providing. If you're going to be storing things like workstation disk-images, you'll hit the performance ceiling a lot faster than if you were storing massive amounts of itty bitty files accessed randomly.
For significantly random I/O, disk rotational speed has an impact on your disk:channel ratio. You'll need to provide  more 7.2K RPM disks than 10K RPM disks yield to the same performance.
As for SATA-600 (or 6gb SAS), if this RAID server will be connected to the network with 1Gb Ethernet, the different doesn't matter much at all. The network will saturate before the storage channels will. So take into account how your storage consumers will access this storage. It may be that a single channel with 72 drives is all you need. Or, if you have 10GbE, four channels with 24 disks each may be needed. 
When it comes to buying your disks, take a look at the warranty period. Drives marketed for enterprise use are rated for 24/7/365 operation, where desktop class drives aren't. This matters most in the cheap 7.2K RPM market segment; drives at 10K or 15K RPM are almost always "enterprise" drives.
When building your RAID sets, keep RAID5 rebuild times in mind. 6TB takes a long time to rebuild, days sometimes, and performance will be degraded during the rebuild. It's better to have more, smaller R5 arrays in a stripe-set than fewer, larger R5 arrays in a stripe set.
Doesn't matter, in my opinion anyway. SAS has a few points going for it that make it better to work with for large storage systems (>48 drives, for instance). A 7.2K RPM SAS drive will perform nearly identically to a 7.2K RPM SATA drive. The market forces an artificial segmentation, where anything 10K or 15K RPM is almost always SAS and 7.2K is mostly SATA. This is where most "SAS vs SATA" arguments are actually focusing on, drive rotational speeds.
Running raid arrays on the same controller isn't a problem, you will just have a performance impact. See it as if it was a road, you have multiple cars (arrays) they are not always driving at the same time, but if they drive at the same time, there will only fit so many cars  on the road with getting a congestion.
Now SATA vs SAS, what do you need ? Storage or fast access times ? if storage then SATA if fast access times then SAS. 
The question 3 vs 6 is easy to answer, what do you need ? Will you have a lot of reading and writing of your different array's ? 
The 3 vs 6 question is with the road anagram like doubling the lanes, you will fit a lot more cars. It depends all on your personal needs.