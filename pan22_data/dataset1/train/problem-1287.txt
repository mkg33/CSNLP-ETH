Supposing that you refer to the performance of tuning algorithms as the improvement in algorithm performance (accuracy, error, etc.). The effectiveness of parameter optimization (or tuning) is different for different algorithms. Many papers have discussed it, and Olson et al. have shown how much performance may vary for several algorithms. SVM and LR (those that you mentioned in your question) were not improved so much after tuning.
If you have bad performance in several algorithms you tried, the problem may not be in the tuning algorithms, but in your features-target set. I suggest you take a look at the Domingos paper, it's a nice read to build a successful model.
In Weka, I used the Grid and Random search parameters tuning algorithms but unfortunately, their performance (in terms of better prediction accuracy) is observed worst when we use the ML algorithms (Support Vector Regression, Linear Regression etc) without any optimization algorithms. 
I wonder how it is possible? I mean one algorithm (Grid or Random search) should perform better or worst when compared with each other but they have worst performance compared to without any parameter optimization algorithms. I even tried the hybrid of both in Weka with MultiSearch option, but even the hybrid of these two have worst performance. 
Kindly if someone could provide comments based on their experience in this regard.