Ethernet doesn't have a shared bit-clock (none of the pins/conductors carries a clock signal), so the receiver has to synchronize its bit clock to the sender's clock with every packet. The preamble allows the receiver's PLLs (phase-locked loops, a specialized circuit for synchronizing bit clocks) enough time to reliably lock into synchronization with the sender before the real data bits were transmitted.
It's possible that in the decades since Ethernet was first designed, PLLs have become better that it could be done reliably in fewer bit-times. But there was never a time when the win of saving a few bit-times was deemed worth the hassle of breaking backward compatibility.
In the context of Ethernets, what is the purpose of the synchronization preamble field from the beginning of an IEEE 802.3 frame? I'd take a guess that it was meant to distinguish packets from noise in the early days of the Internet. But why was it assigned a length of 7 bytes(more than the source/destination address fields)? Was the aim reliability?