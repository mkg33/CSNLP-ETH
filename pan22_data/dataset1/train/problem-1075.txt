In Valve's Alpha Tested Magnification paper, it mentions using "per-pixel screen-space derivatives" for doing anti-aliasing. My understanding is that this is the ddx and ddy intrinsic functions in HLSL?
I'm trying to draw parametric shapes (for example a circle: x² + y² < 1) in a shader, and I don't know how to use this technique to correctly anti-alias the edge pixels of my shape. Can someone provide an example?
For completeness, here is an example of the kind of pixel shader I'm making:
Taking your example, you have a step function of the distance, which produces a perfectly hard (aliased) edge.  A simple way to antialias the circle would be to turn that into a soft threshold, like:
Here I used a clamped linear ramp  for a soft threshold function, but you could also use smoothstep or something else.  The + 0.5 is to center the ramp on the mathematical location of the edge.  Anyway, the point is that this function smoothly changes from outsideColor to insideColor over some range of distances, so if you pick thresholdWidth appropriately you'll get an antialiased-looking edge.
But how should you choose thresholdWidth?  If it's too small, you'll get aliasing again, and if it's too large the edge will be overly blurry.  Moreover, it'll generally depend on camera position: if dist is measured in world-space or texture-space units, then a thresholdWidth that works for one camera position will be wrong for another.
Here's where the screen-space derivatives come in (yes, they're the ddx and ddy functions as you guessed).  By calculating the length of the gradient of dist you can get an idea how rapidly it's changing in screen space and use that to estimate the thresholdWidth, like:
You still have a value you can tune to get the desired level of softness, but now you should get consistent results regardless of camera position.