mean that no matter what guarantees the filesystem makes there is a race condition here.
That is: you can't count count on the order in which process B detects the changes.
I have a diskless host 'A', that has a directory NFS mounted on server 'B'. A process on A writes to two files F1 and F2 in that directory, and a process on B monitors these files for changes.  Assume that B polls for changes faster than A is expected to make them. Process A seeks the head of the files, writes data, and flushes.  Process B seeks the head of the files and does reads.
Are there any guarantees about how the order of the changes performed by A will be detected at B?
Specifically, if A alternately writes to one file, and then the other, is it reasonable to expect that B will notice alternating changes to F1 and F2?  Or could B conceivably detect a series of changes on F1 and then a series on F2?
I know there are a lot of assumptions embedded in the question. For instance, I am virtually certain that, even operating on just one file, if A performs 100 operations on the file, B may see a smaller number of changes that give the same result, due to NFS caching some of the actions on A before they are communicated to B.   And of course there would be issues with concurrent file access even if NFS weren't involved and both the reading and the writing process were running on the same real file system.
The reason I'm even putting the question up here is that it seems like most of the time, the setup described above does detect the changes at B in the same order they are made at A, but that occasionally some events come through in transposed order.  So, is it worth trying to make this work? Is there some way to tune NFS to make it work, perhaps cache settings or something?  Or is fine-grained behavior like this just too much expect from NFS?