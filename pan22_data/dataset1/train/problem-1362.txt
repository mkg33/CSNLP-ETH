Recently we [finally] migrated all of our production hardware from the deprecated default networking into VPCs including EC2 and RDS nodes.  Everything went pretty well except when we started to run performance tests in production and noticed quite significant degradation compared to the old configuration: at least 30-40% penalty.
After scratching our heads a good bit, comparing software versions and configuration, we decided to try to regenerate our RDS instances.  Initially the goal was to migrate our primary databases into a different AZ to compare apples to apples.  When the migration finished we found that performance returned to normal however I seriously doubt that AZ was the source of our pain.  I just can't believe that a couple milliseconds (at most) of latency caused that many problems, especially since different query client AZs seems to have no effect on performance.
I suspect that we either got some bad m3.large RDS hardware or were on an instance with a particularly noisy neighbor.
You use the classic IT solution - turn it off then on again. This almost certainly moves you to new hardware. If you're concerned about downtime you may have to set up a mirror or read replica first.