So you have directly correlated WiFi signal with wind direction. Yet you also correctly pointed out that wind should affect EM waves. While there may be a correlation, if it does exist it is likely indirect at best.
Let me start by mentioning you don't provide how you are determining "nice strong Wi Fi signal". Often wireless clients represent a signal using some sort of iconography. Five bars is good and one is bad, right? But just what does that little icon represent? Is it actual signal strength or signal quality or something else? For example, on my cell phone, I know that one bar of "LTE" is better than three bars of "4G". So three bars isn't always better than one bar. But back to the question.
As Ron already mentioned in his post, the frequencies used by WiFi are subject to higher absorption by water. So his suggestion that plants shifting could be part of the answer. Wind also tends to move in certain directions based on weather conditions, which may include humidity.
But you point out that your "signal improves when it rains or is cloudy" so this can't be the case. This statement of course runs contrary to physics, but taking it at face value may be a clue to what is taking place on a larger scale. But back to that in a minute.
If wind direction is truly a factor, then water (plant, humidity, etc) is certainly one thing that could be different. Another thing could be is the geometry at play. Buildings and structures can/will flex or shift with different prevailing winds. These changes may be negligible when both the client and the AP are in the same building, however you mention that you are "next to a university campus" rather than in the same building as the AP. 
While these changes are often relatively small, modern 802.11 traffic (802.11n or newer) takes advantage of a phenomenon known as multipath propogation through the use of more than one radio chain and/or spatial stream simultaneously. Without getting into too much detail, ultimately as conditions change, the best "paths" between to RF endpoints will change as well. These subtle changes can result in big differences to signal strength/quality and with multipath the coverage pattern is often far from intuitive.
So, end result is that the path the signal gets from the AP to your client could change based on things like wind direction.
Getting back to your comment that "signal improves when it rains or is cloudy",  and you wonder if this could have anything to do with cloud cover bouncing signal back. Physics tells us that this is impossible (the signal strength of an 802.11 device is not strong enough to be usable at the level of clouds, much less to the cloud cover and back) and further that rain/water will absorb RF signal in the frequencies in question.
So why does your signal improve? My best guess would be that you are measuring signal quality rather than signal strength. While it may seem counter-intuitive, you may actually have better signal quality when conditions are less than ideal.
Under "better" conditions, your wireless client may be seeing more interference on the channel (i.e. other devices) or other sources of RF noise. This may reduce the signal quality. Less ideal conditions (such as raining, changes in the RF path) may be absorbing or masking a portion of that other interference or noise, allowing your signal to be better.
Of course, this is all just speculation on my part. Without knowing a lot more about your particular situation, no one could say for certain why things are working as you report. There may be other factors of which we aren't aware; for instance, university buildings near you may be more heavily occupied (more people/devices) under certain circumstances and less occupied under others.
Water is a Wi-Fi killer. Plants (trees, etc.) are full of water. The wind moving the plants a certain direction, or bringing in moisture can greatly affect Wi-Fi signals.
One of the worst plants for Wi-Fi is alfalfa, but I assume you do not live next to alfalfa fields.